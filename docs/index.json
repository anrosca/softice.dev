[{"categories":["DynamoDB","Spring Boot"],"content":"Introduction In this post, we’ll try to familiarize ourselves with Amazon’s DynamoDB database and the famous single table design. Coming from the relational world, DynamoDB looks like a strange beast at first (it’s a NoSQL database after all) and definitely has a steep learning curve, hopefully this introduction will make things easier. We’ll try to write a simple Spring Boot rest api which uses DynamoDB under the hood, so that we’ll get a chance to see how everything looks in practice. ","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:1:0","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"What is DynamoDB? DynamoDB is a managed NoSQL, key-value database offered by AWS, designed to run high-performance applications at any scale. DynamoDB offers an HTTP api, and it integrates seamlessly with AWS lambda for example. DynamoDB offers consistent performance, regardless of scale. You can expect the same latency when you have 5GB of data and nothing will change when you have 1TB of data. In DynamoDB, data is stored in tables, but it looks nothing like a relational database. The biggest difference from a relational database is that AWS recommends using a single DynamoDB table for all your data, also known as the single table design. Yes, you’ve read that right. When using DynamoDB your application/microservice will store all its data in a single table. Sounds shocking but that’s the most performant and cost-effective approach. This effectively means that data modeling in DynamoDB is way trickier that in a relational database. Data modeling in DynamoDB is tied to the data’s access patterns. In order to design a DynamoDB table, first you need to know how that data will be fetched by an application. The idea is that in DynamoDB, you can’t write arbitrary queries which will do any projections, aggregations and filtering you like. This makes DynamoDB unusable for analytics, but it’s not an issue since DynamoDB was designed to be an OLTP database. DynamoDB doesn’t support joins (like relational databases do). So there’s no point in scattering the data around multiple tables, since you won’t be able to join them. Also you can forget about data normalization (because now you’re dealing with a single table after all). That’s the rationale of single-table-desing. ","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:2:0","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"DynamoDB table anatomy A DynamoDB table is basically a collection of items. An item is pretty much the same thing as a row in a relational database. An item consists of a primary key and a bunch of attributes. Coming back to our relational database analogy, an attribute is a column. The difference is that every item can have its own list of attributes. Not only the number of attributes for a given item can vary, also do their types (as opposed to a relational database where every row has exactly the same number of columns.) The primary key is the most interesting part of a DynamoDB table. A primary key uniquely identifies an item in a table, and it must be defined at the creation of the table. There are two types of primary key: a simple primary key made up of just a partition key, and a composite primary key made up of a partition key and a sort key. Designing a good DynamoDB table is basically picking the right partition and sort keys. Let’s look more closely at the 2 types of primary keys: Simple primary key: as mentioned before, this is when we have a table with a partition key, but no sort key. Is this case, the only option to fetch an item is by knowing the exact value of the partition key (well, another option is to do a table scan, where we scan the entire table item-by-item, but this is not very cost-effective). When using just the partition key, DynamoDB basically looks like a plain key-value NoSQL database like redis and a good use-case for this approach is when we use DynamoDB as a session store for example. Composite primary key: the primary key is composed of both a partition key and a sort key. This is where the DynamoDB shines. Using this approach it’s possible to pretty much model any OLTP use-case. The idea here is that there are more options to fetch an item. With this approach now it’s possible to fetch an entire collection of items. To fetch a single item we still need to know the exact values of a partition key and a sort key. The nice part is that when we want to fetch a collection of items, we need to know the exact value of a partition key, but only a substring of the sort key. Sounds confusing but this will make sense in a bit. Also it’s worth mentioning that good partition and sort keys should have high cardinality. DynamoDB looks like a hash map after all, so same principles apply here as well. An odd piece of advice is that when using the single-table-design, good partition and sort key types are strings. These are the most versatile types our there. Though it sounds confusing, it’ll make sense in a bit. Look here for strategies on picking a good partition key. ","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:2:1","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"Read capacity units \u0026 write capacity units While creating the DynamoDB table, we’ll need to configure the read \u0026 write capacity units (sometimes they’re called read request units and write request units). That’s basically a way to provision the maximum throughput of our database. Here’s what these capacity units mean: One read capacity unit gives us: A strongly consistent read request of an item up to 4 KB. Two eventually consistent reads of an item up to 4 KB. One write capacity units gives us: One write per second for an item up to 1 KB in size. Strongly and eventually consistent reads basically mean the read-your-own-writes semantics. For example if we write something to DynamoDB and instantly try to fetch the item we just wrote can produce different results depending on the read type we use. A strongly consistent read will guarantee that we’ll see the item we’ve just wrote. A eventually consistent read will not (well, after a small delay we will see the item). If we do a bit of math, a table with 5 read capacity units (RCUs) can handle either 5 strongly consistent reads per second (with 4KB of data each) or for example a single strongly consistent read which fetches 20KB of data. For eventually consistent reads, 5 RCUs give us 10 reads per second (with 4KB of data each). Pretty much the same thing for writes. 5 Write capacity units (WCUs) give us 5 writes per second (with 1KB of data each) or a single write per second (with 5KB of data). RCUs and WCUs are also intertwined with transactions, but in this post we won’t discuss them. Exceeding these limits will result in an HTTP 400 code (Bad Request) and a ProvisionedThroughputExceededException. ","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:2:2","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"The application we’re going to build Since we’ve familiarized ourselves with a bit of theory about DynamoDB, let’s try to build a simple application with it. We’re going to build a Spring Boot rest API, for a simple online forum, using single-table-design. To make things more clear, here’s an example of a entity-relationship diagram for our database: If we were to use a relational database, every entity from the above diagram would’ve had its own table, but since we’re using DynamoDB we’re going to store all that data into a single table. ","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:2:3","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"Creating the project Let’s create the project skeleton. For that we’ll go to https://start.spring.io and we’ll select the following dependencies: We’ll also add the AWS DynamoDB SDK. For that we’ll edit our pom.xml and add the following additional dependencies: \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003c!-- Omitted for brevity --\u003e \u003cproperties\u003e \u003cjava.version\u003e17\u003c/java.version\u003e \u003cawssdk.version\u003e2.20.2\u003c/awssdk.version\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003c!-- Omitted for brevity --\u003e \u003cdependency\u003e \u003cgroupId\u003esoftware.amazon.awssdk\u003c/groupId\u003e \u003cartifactId\u003edynamodb\u003c/artifactId\u003e \u003cversion\u003e${awssdk.version}\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003esoftware.amazon.awssdk\u003c/groupId\u003e \u003cartifactId\u003edynamodb-enhanced\u003c/artifactId\u003e \u003cversion\u003e${awssdk.version}\u003c/version\u003e \u003c/dependency\u003e \u003c!-- Omitted for brevity --\u003e \u003c/dependencies\u003e \u003c/project\u003e ","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:3:0","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"Local env setup In order to get a chance to fiddle with DynamoDB, we need a database instance. There are many approaches we can use, like the real thing from AWS (which costs a bit of money), or using Localstack or even embedded DynamoDB. In this post we’re going to stick with Localstack. Given that, we’ll run Localstack as a docker container, let’s take a look at our docker-compose.yaml file, shown below: version:'3.8'services:localstack:container_name:\"${LOCALSTACK_DOCKER_NAME-localstack_main}\"image:localstack/localstack:1.4ports:- \"127.0.0.1:4566:4566\"# LocalStack Gateway- \"127.0.0.1:4510-4559:4510-4559\"# external services port rangeenvironment:- DEBUG=${DEBUG-}- LAMBDA_EXECUTOR=${LAMBDA_EXECUTOR-}- DOCKER_HOST=unix:///var/run/docker.sockvolumes:- \"${LOCALSTACK_VOLUME_DIR:-./volume}:/var/lib/localstack\"- \"/var/run/docker.sock:/var/run/docker.sock\"- ./dynamodb:/etc/localstack/init/ready.d We have a single docker container using the localstack/localstack:1.4 docker image. Let’s also note that there’s a volume called ./dynamodb:/etc/localstack/init/ready.d. In the ./dynamodb directory (located in the same folder as our docker-compose.yaml), we have a bunch of shell scripts which are called at initialization phase of Localstack, which gives us a chance to create the resources we’re going to use. In our case that’ll be our DynamoDB table. Specifically, we have a create-table.sh shell script which looks like the following: #!/bin/bash awslocal dynamodb create-table \\ --table-name forum \\ --attribute-definitions \\ AttributeName=PK,AttributeType=S \\ AttributeName=SK,AttributeType=S \\ --key-schema \\ AttributeName=PK,KeyType=HASH \\ AttributeName=SK,KeyType=RANGE \\ --provisioned-throughput \\ ReadCapacityUnits=5,WriteCapacityUnits=5 \\ --region eu-west-1 The above shell script creates a DynamoDB table, named forum with a partition key named PK of type string, and a sort key named SK, also of type string. The table is located in the eu-west-1 region and has 5 read and write capacity units. Good stuff. Now let’s try to run our docker-compose.yaml file with the following command: $ docker-compose up We expect that not only localstack will start, but also that our single DynamoDB table will be created. We can check that the table was indeed created either by looking at the localstack's logs, or by listing the DynamoDb tables using the AWS cli, like shown below: $ aws dynamodb list-tables --endpoint-url http://localhost:4566 --region eu-west-1 If the table was indeed created, we should get the following output: { \"TableNames\": [ \"forum\" ] } ","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:4:0","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"Designing the DynamoDB table around our access patterns We’ve mentioned that the recommended way to use DynamoDB is via the single-table-design and that the best way is to model our data around our access patterns. So let’s do that. Since we’re writing a simple rest api for an online forum, our access patterns will look something like this: ","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:5:0","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"Categories access patterns ### Create a category POST {{host}}/api/v1/categories Content-Type: application/json { \"name\": \"Anime\" } HTTP/1.1 200 Content-Type: application/json { \"id\": \"ba97318-8688-46bc-a945-87c187fc20c2\", \"name\": \"Anime\" } ### Get all categories GET {{host}}/api/v1/categories HTTP/1.1 200 Content-Type: application/json [ { \"id\": \"ba97318-8688-46bc-a945-87c187fc20c2\", \"name\": \"Anime\" }, { \"id\": \"0f8aacc6-dce1-4df2-1529-d9f3fec10dc2\", \"name\": \"Software development\" } ] ### Get category by id GET {{host}}/api/v1/categories/{{sofwareCategoryId}} Content-Type: application/json { \"id\": \"0f8aacc6-dce1-4df2-1529-d9f3fec10dc2\", \"name\": \"Software development\" } ","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:5:1","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"Topics access patterns ### Create topic for category POST {{host}}/api/v1/categories/{{sofwareCategoryId}}/topics Content-Type: application/json { \"name\": \"Java 19 released\", \"userName\": \"mike\", \"tags\": [\"NSFW\"] } HTTP/1.1 200 Content-Type: application/json { \"id\": \"9c62e3fa-7fdb-4a01-854a-a629d78f4859\", \"name\": \"Java 19 released\", \"createdAt\": \"2023-04-24T13:27:08.975920875Z\", \"categoryId\": \"51753a6-d5d0-47a2-8d73-e901367d6d37\", \"userName\": \"mike\", \"tags\": [ \"NSFW\" ] } ### Get topics of a category GET {{host}}/api/v1/categories/{{sofwareCategoryId}}/topics Content-Type: application/json HTTP/1.1 200 Content-Type: application/json [ { \"id\": \"9c62e3fa-7fdb-4a01-854a-a629d78f4859\", \"name\": \"Java 19 released\", \"createdAt\": \"2023-04-24T13:27:08.975920875Z\", \"categoryId\": \"51753a6-d5d0-47a2-8d73-e901367d6d37\", \"userName\": \"mike\", \"tags\": [ \"NSFW\" ] } ] ### Get a particular topic GET {{host}}/api/v1/categories/{{sofwareCategoryId}}/topics/{{topicId}} Content-Type: application/json HTTP/1.1 200 Content-Type: application/json { \"id\": \"9c62e3fa-7fdb-4a01-854a-a629d78f4859\", \"name\": \"Java 19 released\", \"createdAt\": \"2023-04-24T13:27:08.975920875Z\", \"categoryId\": \"51753a6-d5d0-47a2-8d73-e901367d6d37\", \"userName\": \"mike\", \"tags\": [ \"NSFW\" ] } ### Add tags for a topic POST {{host}}/api/v1/categories/{{sofwareCategoryId}}/topics/{{topicId}}/tags Content-Type: application/json [ \"NSFW\", \"TRIGGER_WARNING\" ] HTTP/1.1 200 Content-Type: application/json { \"id\": \"9c62e3fa-7fdb-4a01-854a-a629d78f4859\", \"name\": \"Java 19 released\", \"createdAt\": \"2023-04-24T13:27:08.975920875Z\", \"categoryId\": \"51753a6-d5d0-47a2-8d73-e901367d6d37\", \"userName\": \"mike\", \"tags\": [ \"NSFW\", \"TRIGGER_WARNING\" ] } ","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:5:2","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"Comments access patterns ### Get comments for a topic GET {{host}}/api/v1/categories/{{sofwareCategoryId}}/topics/{{topicId}}/comments Content-Type: application/json HTTP/1.1 200 Content-Type: application/json [ { \"author\": \"2e0c8f82-88d3-20cf-2112-a0678be9c201\", \"createdAt\": \"2023-04-24T13:29:40.229672539Z\", \"text\": \"Yay! Finally\", \"topicId\": \"9c62e3fa-7fdb-4a01-854a-a629d78f4859\", \"commentId\": \"7c6db813-059d-4daa-a4b3-669ec640f135\", \"likeCount\": 0 } ] ### Create a comment for a topic POST {{host}}/api/v1/categories/{{sofwareCategoryId}}/topics/{{topicId}}/comments Content-Type: application/json { \"userId\": \"2e0c8f82-88d3-20cf-2112-a0678be9c201\", \"text\": \"Yay\" } HTTP/1.1 200 Content-Type: application/json { \"author\": \"john\", \"createdAt\": \"2023-04-24T13:30:12.493868905Z\", \"text\": \"Yay\", \"topicId\": \"9c62e3fa-7fdb-4a01-854a-a629d78f4859\", \"commentId\": \"02a31913-0cc2-44f0-a90d-2d317433e4d3\", \"likeCount\": 0 } ### Like comment POST {{host}}/api/v1/categories/{{sofwareCategoryId}}/topics/{{topicId}}/comments/{{commentId}}/likes Content-Type: application/json HTTP/1.1 200 Content-Type: application/json { \"author\": \"john\", \"createdAt\": \"2023-04-24T13:30:12.493868905Z\", \"text\": \"Yay\", \"topicId\": \"9c62e3fa-7fdb-4a01-854a-a629d78f4859\", \"commentId\": \"02a31913-0cc2-44f0-a90d-2d317433e4d3\", \"likeCount\": 1 } ","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:5:3","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"The single table design Given our access patterns, our single DynamoDB table can look like this: Let’s take a closer look at our single table design and our access patterns. Get category by id ### Get category by id GET {{host}}/api/v1/categories/{{sofwareCategoryId}} We get the sofwareCategoryId as a path parameter and we can use it to make our partition and sort keys, which in this particular case are equal. In order to actually fetch the category, we’ll use the GetItem operation and we’ll need to prefix the partition and the sort key with the Category# string, like shown below: $ aws dynamodb get-item --table-name forum --key '{\"PK\": {\"S\": \"Category#4f0a4c06-6c11-4df2-9529-a993fec005c1\"}, \"SK\": {\"S\": \"Category#4f0a4c06-6c11-4df2-9529-a993fec005c1\"}}'\\ --endpoint-url http://localhost:4566 --region eu-west-1 And we’ll get the following response: { \"Item\": { \"name\": { \"S\": \"Software development\" }, \"SK\": { \"S\": \"Category#4f0a4c06-6c11-4df2-9529-a993fec005c1\" }, \"PK\": { \"S\": \"Category#4f0a4c06-6c11-4df2-9529-a993fec005c1\" } } } We’ll get to the Java version of this operation in a bit. Get all categories GET {{host}}/api/v1/categories This request is a bit more difficult since we don’t have any data from which we can construct the partition and the sort key, and as we remember we need at least the exact value of the partition key and a substring of the sort key in order to fetch anything. In this case one option would be to do a table scan, an operation which usually should be avoided like a plague. This is because the table scan actually scans the whole table, item-by-item and since we have all the data into a single table, the amount of the data scanned would be pretty significant. That’s one downside of DynamoDB is that operations like findAll() are difficult to implement, so it’s worth considering if this operation is actually needed. In our case it is. When scanning the table, we actually need to do a bit of filtering as well since we’re interested only in categories, so we’ll have to look at the sort keys and check if they have the Category# prefix. Here’s how a table scan looks like: $ aws dynamodb scan --table-name forum --filter-expression 'begins_with(SK, :value)'\\ --expression-attribute-values '{\":value\": {\"S\": \"Category#\"}}' --endpoint-url http://localhost:4566 --region eu-west-1 We’ll get the following response: { \"Items\": [ { \"name\": { \"S\": \"Anime\" }, \"SK\": { \"S\": \"Category#91d17128-324a-42b2-b749-e6b7df091df9\" }, \"PK\": { \"S\": \"Category#91d17128-324a-42b2-b749-e6b7df091df9\" } }, { \"name\": { \"S\": \"Software development\" }, \"SK\": { \"S\": \"Category#4f0a4c06-6c11-4df2-9529-a993fec005c1\" }, \"PK\": { \"S\": \"Category#4f0a4c06-6c11-4df2-9529-a993fec005c1\" } } ], \"Count\": 5, \"ScannedCount\": 12, \"ConsumedCapacity\": null } We’ll also see at the Java version in the next section. Get topics of a category ### Get topics of a category GET {{host}}/api/v1/categories/{{sofwareCategoryId}}/topics This is an interesting one. Effectively this is a one-to-many relationship, since a category has many topics. The idea is that our REST endpoint receives only the categoryId and somehow using it we need to fetch all topics for that category. Here’s the data we’re interested in, highlighted in red: The idea here is that we can use the query operation of DynamoDB, and here we can specify the exact value of the partition key (Category#4f0a4c06-6c11-4df2-9529-a993fec005c1) and we know the sort key prefix (Topic# in our case). $ aws dynamodb query \\ --table-name forum \\ --key-condition-expression \"PK = :partition_key_value and begins_with(SK, :sort_key_prefix)\" \\ --expression-attribute-values '{\":partition_key_value\": {\"S\": \"Category#4f0a4c06-6c11-4df2-9529-a993fec005c1\"}, \":sort_key_prefix\": {\"S\": \"Topic#\"}}'\\ --endpoint-url http://localhost:4566 --region eu-west-1 And we’ll get the following response: { \"Items\": [ { \"createdAt\": { \"S\": \"2023-04-24T13:27:08.975920875Z\" }, \"SK\": { \"S\": \"Topic#0f8aacc6-dce1-4df2-1529-d9f3fec10dc2\" }, \"PK\": { \"S\": \"Ca","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:5:4","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"Writing the application Now let’s get to the business. For our rest api we’ll need to configure a bunch of custom properties, so that the AWS SDK will connect to our localstack docker container. Here’s our properties: #AWS properties aws.endpoint-override=http://localhost:4566 aws.region=eu-west-1 aws.dynamo-db-table-name=forum aws.credentials.secret-key=localstack aws.credentials.access-key=localstack We’ll bind these properties to a couple of Java classes using the @ConfigurationProperties annotation, like shown below: @ConfigurationProperties(\"aws\") public record AwsProperties(String endpointOverride, String region, String dynamoDbTableName, AwsCredentials credentials) { @ConstructorBinding public AwsProperties { } } public record AwsCredentials(String accessKey, String secretKey) { @ConstructorBinding public AwsCredentials { } } Now we can get to the part where we configure the AWS DynamoDbClient and DynamoDbEnhancedClient, which we’ll use to communicate with DynamoDB. @Configuration(proxyBeanMethods = false) @EnableConfigurationProperties(AwsProperties.class) public class DynamoDbConfig { @Bean public DynamoDbClient dynamoDbClient(AwsProperties properties, AwsBasicCredentials awsCredentials) { var builder = DynamoDbClient.builder() .region(Region.of(properties.region())); if (properties.endpointOverride() != null) { builder.endpointOverride(URI.create(properties.endpointOverride())); } return builder.credentialsProvider(() -\u003e awsCredentials).build(); } @Bean public AwsBasicCredentials awsCredentials(AwsProperties properties) { return AwsBasicCredentials.create(properties.credentials().accessKey(), properties.credentials().secretKey()); } @Bean public DynamoDbEnhancedClient dynamoDbEnhancedClient(DynamoDbClient dynamoDbClient) { return DynamoDbEnhancedClient.builder() .dynamoDbClient(dynamoDbClient) .build(); } } The most interesting part here probably is the usage of the aws.endpoint-override property, which makes our DynamoDB clients actually connect to localstack and not to the AWS endpoints. If we indend to actually connect to AWS, the aws.endpoint-override should be removed or commented out. ","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:6:0","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"Creating the Category entity As we saw in the data modelling section, we’re using composite primary keys, so all of our items will have a partition and a sort key. It can be helpful to create a superclass of all of our entities, which will declare the partition and the sort keys, like shown below: @Data public class DynamoDbBase { protected String partitionKey; protected String sortKey; @DynamoDbPartitionKey @DynamoDbAttribute(\"PK\") public String getPartitionKey() { return partitionKey; } @DynamoDbSortKey @DynamoDbAttribute(\"SK\") public String getSortKey() { return sortKey; } } Now coming back to our Category entity, we just need to inherit from our DynamoDbBase class and add the needed properties, like shown below: @DynamoDbBean @EqualsAndHashCode(callSuper = true) public class Category extends DynamoDbBase { public static final String CATEGORY_PK_PREFIX = \"Category#\"; public static final String CATEGORY_SK_PREFIX = \"Category#\"; private String name; public Category() { } public Category(CategoryBuilder builder) { this.name = builder.name; this.partitionKey = builder.partitionKey; this.sortKey = builder.sortKey; } public void setId(String id) { setPartitionKey(CategoryKeyBuilder.makePartitionKey(id)); setSortKey(CategoryKeyBuilder.makeSortKey(id)); } @DynamoDbIgnore public String getId() { return getSortKey().substring(CATEGORY_PK_PREFIX.length() + 1); } public String getName() { return this.name; } public void setName(String name) { this.name = name; } public static CategoryBuilder builder() { return new CategoryBuilder(); } public static class CategoryKeyBuilder { public static String makePartitionKey(String id) { return CATEGORY_PK_PREFIX + id; } public static String makeSortKey(String id) { return CATEGORY_SK_PREFIX + id; } } public static class CategoryBuilder { private String name; private String partitionKey; private String sortKey; public CategoryBuilder name(String name) { this.name = name; return this; } public CategoryBuilder partitionKey(String partitionKey) { this.partitionKey = partitionKey; return this; } public CategoryBuilder sortKey(String sortKey) { this.sortKey = sortKey; return this; } public Category build() { return new Category(this); } } } Notice the nested CategoryKeyBuilder class. It’s a little helper class which will come in handy when we’ll need to set the partition and the sort key, with the right prefixes. We’ll also need to adjust a bit our DynamoDbConfig class, so that we declare our newly-created entity there as a table, like shown below: @Configuration(proxyBeanMethods = false) @EnableConfigurationProperties(AwsProperties.class) public class DynamoDbConfig { //Omitted for brevity @Bean public DynamoDbTable\u003cCategory\u003e categoryTable(DynamoDbEnhancedClient dynamoDbEnhancedClient, AwsProperties properties) { return dynamoDbEnhancedClient.table(properties.dynamoDbTableName(), TableSchema.fromBean(Category.class)); } } Now we’re finally ready to implement our DynamoDBCategoryRepository, which is presented below: @Repository public class DynamoDBCategoryRepository implements CategoryRepository { private final DynamoDbTable\u003cCategory\u003e categoryTable; public DynamoDBCategoryRepository(DynamoDbTable\u003cCategory\u003e categoryTable) { this.categoryTable = categoryTable; } @Override public List\u003cCategory\u003e findAll() { Expression expression = Expression.builder() .expression(\"begins_with(SK, :skPrefix)\") .expressionValues(Map.of(\":skPrefix\", AttributeValue.builder().s(Category.CATEGORY_SK_PREFIX).build())) .build(); ScanEnhancedRequest scanEnhancedRequest = ScanEnhancedRequest.builder() .filterExpression(expression) .build(); return categoryTable.scan(scanEnhancedRequest) .stream() .flatMap(page -\u003e page.items().stream()) .toList(); } @Override public Category create(Category categoryToCreate) { categoryTable.putItem(categoryToCreate); return categoryToCreate; } @Override public Optional\u003cCategory\u003e findById(String id) { Key key = Key.builder() .partitionValue(Category.CategoryKeyBuilder.makePartitionKey(id)) .sortValue(","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:7:0","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"Creating the Topic entity Here’s how our Topic entity looks like: public enum TopicTag { NSFW, VIOLENCE, GAMBLING, TRIGGER_WARNING } @DynamoDbBean @EqualsAndHashCode(callSuper = true) public class Topic extends DynamoDbBase { public static final String TOPIC_PK_PREFIX = \"Category#\"; public static final String TOPIC_SK_PREFIX = \"Topic#\"; private String title; private String userName; private Instant createdAt; private List\u003cTopicTag\u003e tags; public Topic() { } public Topic(TopicBuilder builder) { this.title = builder.title; this.userName = builder.userName; this.createdAt = builder.createdAt; this.tags = builder.tags; this.partitionKey = builder.partitionKey; this.sortKey = builder.sortKey; } @DynamoDbIgnore public String getId() { return getSortKey().substring(TOPIC_SK_PREFIX.length()); } public void setId(String id) { this.sortKey = TopicKeyBuilder.makeSortKey(id); } public String getCategoryId() { return getPartitionKey().substring(TOPIC_PK_PREFIX.length()); } //the rest of the getters \u0026 setters public static TopicBuilder builder() { return new TopicBuilder(); } public static class TopicBuilder { private String title; private String userName; private Instant createdAt; private String partitionKey; private String sortKey; private List\u003cTopicTag\u003e tags; public TopicBuilder title(String title) { this.title = title; return this; } public TopicBuilder userName(String userName) { this.userName = userName; return this; } public TopicBuilder createdAt(Instant createdAt) { this.createdAt = createdAt; return this; } public TopicBuilder tags(List\u003cTopicTag\u003e tags) { this.tags = tags; return this; } public TopicBuilder partitionKey(String partitionKey) { this.partitionKey = partitionKey; return this; } public TopicBuilder sortKey(String sortKey) { this.sortKey = sortKey; this.gsi1SortKey = sortKey; return this; } public TopicBuilder categoryId(String categoryId) { this.partitionKey = TopicKeyBuilder.makePartitionKey(categoryId); return this; } public Topic build() { return new Topic(this); } } public static class TopicKeyBuilder { public static String makePartitionKey(String id) { return TOPIC_PK_PREFIX + id; } public static String makeSortKey(String id) { return TOPIC_SK_PREFIX + id; } } } Apart from this, we’ll need to adjust our DynamoDbConfig class again and register the Topic entity as a table, as shown below: @Configuration(proxyBeanMethods = false) @EnableConfigurationProperties(AwsProperties.class) public class DynamoDbConfig { //Ommitted for brevity @Bean public DynamoDbTable\u003cCategory\u003e categoryTable(DynamoDbEnhancedClient dynamoDbEnhancedClient, AwsProperties properties) { return dynamoDbEnhancedClient.table(properties.dynamoDbTableName(), TableSchema.fromBean(Category.class)); } @Bean public DynamoDbTable\u003cTopic\u003e topicTable(DynamoDbEnhancedClient dynamoDbEnhancedClient, AwsProperties properties) { return dynamoDbEnhancedClient.table(properties.dynamoDbTableName(), TableSchema.fromBean(Topic.class)); } } It looks kind of strange, the code presented above looks like we have 2 DynamoDB tables, right? That’s not true though. We have a single table because we’ve used the same table name for both of them and this is just a way to tell the AWS SDK the schema of the entities we’re using, so that it can do the mapping of the DynamoDB API responses. And finally, here’s how our TopicRepository looks like: @Repository public class DynamoDbTopicRepository implements TopicRepository { private final DynamoDbTable\u003cTopic\u003e topicTable; public DynamoDbTopicRepository(DynamoDbTable\u003cTopic\u003e topicTable) { this.topicTable = topicTable; } @Override public List\u003cTopic\u003e findByCategory(String categoryId) { QueryConditional skBeginsWithQuery = QueryConditional.sortBeginsWith( Key.builder() .partitionValue(Topic.TopicKeyBuilder.makePartitionKey(categoryId)) .sortValue(Topic.TOPIC_SK_PREFIX) .build() ); return topicTable.query(skBeginsWithQuery) .items() .stream() .toList(); } @Override public Topic create(Topic topicToCreate) { topicTable.putItem(topicToCreate); ret","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:8:0","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"Creating the Comment entity The Comment entity looks similar to the Topic entity. Let’s take a look: @DynamoDbBean public class Comment extends DynamoDbBase { public static final String COMMENT_PK_PREFIX = \"Topic#\"; public static final String COMMENT_SK_PREFIX = \"Comment#\"; private String userName; private Instant createdAt; private String text; private long likeCount; public Comment() { } private Comment(CommentBuilder builder) { this.userId = builder.userId; this.createdAt = builder.createdAt; this.text = builder.text; this.likeCount = builder.likeCount; this.partitionKey = CommentKeyBuilder.makePartitionKey(builder.topicId); this.sortKey = builder.id != null ? CommentKeyBuilder.makeSortKey(builder.id) : null; } @DynamoDbIgnore public String getId() { return sortKey.substring(COMMENT_SK_PREFIX.length()); } public void setId(String id) { this.sortKey = CommentKeyBuilder.makeSortKey(id); } //other getters \u0026 setters public static CommentBuilder builder() { return new CommentBuilder(); } public String getTopicId() { return partitionKey.substring(COMMENT_PK_PREFIX.length()); } public static class CommentBuilder { private String userName; private Instant createdAt; private String text; private String topicId; private String id; private long likeCount; public CommentBuilder userName(String userName) { this.userName = userName; return this; } public CommentBuilder createdAt(Instant createdAt) { this.createdAt = createdAt; return this; } public CommentBuilder text(String text) { this.text = text; return this; } public CommentBuilder likeCount(long likeCount) { this.likeCount = likeCount; return this; } public CommentBuilder topicId(String topicId) { this.topicId = topicId; return this; } public Comment build() { return new Comment(this); } public CommentBuilder id(String id) { this.id = id; return this; } } public static class CommentKeyBuilder { public static String makePartitionKey(String id) { return COMMENT_PK_PREFIX + id; } public static String makeSortKey(String id) { return COMMENT_SK_PREFIX + id; } } } Basically we have comment-specific attributes along with the helper CommentKeyBuilder. Apart from this, we’ll need to adjust one more time the DynamoDbConfig so that we declare the Comment entity, like shown below: @Configuration(proxyBeanMethods = false) @EnableConfigurationProperties(AwsProperties.class) public class DynamoDbConfig { //same as in previous examples @Bean public DynamoDbTable\u003cCategory\u003e categoryTable(DynamoDbEnhancedClient dynamoDbEnhancedClient, AwsProperties properties) { return dynamoDbEnhancedClient.table(properties.dynamoDbTableName(), TableSchema.fromBean(Category.class)); } @Bean public DynamoDbTable\u003cTopic\u003e topicTable(DynamoDbEnhancedClient dynamoDbEnhancedClient, AwsProperties properties) { return dynamoDbEnhancedClient.table(properties.dynamoDbTableName(), TableSchema.fromBean(Topic.class)); } @Bean public DynamoDbTable\u003cComment\u003e commentTable(DynamoDbEnhancedClient dynamoDbEnhancedClient, AwsProperties properties) { return dynamoDbEnhancedClient.table(properties.dynamoDbTableName(), TableSchema.fromBean(Comment.class)); } } And finally, the CommentRepository looks like this: @Repository public class DynamoDbCommentRepository implements CommentRepository { private final DynamoDbTable\u003cComment\u003e commentTable; private final DynamoDbClient dynamoDbClient; private final AwsProperties awsProperties; public DynamoDbCommentRepository(DynamoDbTable\u003cComment\u003e commentTable, DynamoDbClient dynamoDbClient, AwsProperties awsProperties) { this.commentTable = commentTable; this.dynamoDbClient = dynamoDbClient; this.awsProperties = awsProperties; } @Override public List\u003cComment\u003e findByTopic(String topicId) { QueryConditional skBeginsWithQuery = buildSkBeginsWithKeyQuery(topicId); QueryEnhancedRequest reverseOrderQuery = QueryEnhancedRequest .builder() .queryConditional(skBeginsWithQuery) .scanIndexForward(Boolean.FALSE) .build(); return commentTable.query(reverseOrderQuery) .items() .stream() .toList(); } @Override public C","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:9:0","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"Implementing additional access patterns with Global secondary indexes So far we’ve implemented quite a lot of access patterns. We can list all categories, get a category by its id, list the topics for a given category, we can also get the topic by its id or even add tags to an existing topic. We can get the comments for a particular topic and we can like a comment. What if we’d like to find all the topics which were created by a particular user? Given our current database model, the only option to achieve that is by doing a table scan, which we mentioned that it’s a terrible idea. A better option to do that is via Global secondary indexes. A global secondary index is an index which allows us to use a completely different set of partition and sort keys to access our data. Also an important thing to point out is that the global secondary index needs to be provisioned separately (meaning it has its own RCUs and WCUs). Also compared to the DynamoDB table, the global secondary index allows only eventually consistent reads. In order to create the global secondary index at table creation time, we’ll need to adjust our localstack initialization shell-script like this: #!/bin/bash awslocal dynamodb create-table \\ --table-name forum \\ --attribute-definitions \\ AttributeName=PK,AttributeType=S \\ AttributeName=SK,AttributeType=S \\ AttributeName=GSI1PK,AttributeType=S \\ AttributeName=GSI1SK,AttributeType=S \\ --key-schema \\ AttributeName=PK,KeyType=HASH \\ AttributeName=SK,KeyType=RANGE \\ --global-secondary-indexes 'IndexName=forum-gsi,KeySchema=[{AttributeName=GSI1PK,KeyType=HASH},\\ {AttributeName=GSI1SK,KeyType=RANGE}],Projection={ProjectionType=ALL},ProvisionedThroughput={ReadCapacityUnits=10,WriteCapacityUnits=10}' \\ --provisioned-throughput \\ ReadCapacityUnits=5,WriteCapacityUnits=5 \\ --region eu-west-1 The above command created a global secondary index named forum-gsi with the partition key named GSI1PK and the sort key GSI1SK, and the provisioned throughput of 10 RCUs and 10 WCUs. Now we can adjust a bit our DynamoDbBase superclass, so that the new set of partition and sort key is added. It will look something like this: @Data public class DynamoDbBase { protected String partitionKey; protected String sortKey; protected String gsi1PartitionKey; protected String gsi1SortKey; @DynamoDbPartitionKey @DynamoDbAttribute(\"PK\") public String getPartitionKey() { return partitionKey; } @DynamoDbSortKey @DynamoDbAttribute(\"SK\") public String getSortKey() { return sortKey; } @DynamoDbAttribute(\"GSI1PK\") @DynamoDbSecondaryPartitionKey(indexNames = IndexNames.GS1_INDEX_NAME) public String getGsi1PartitionKey() { return gsi1PartitionKey; } @DynamoDbAttribute(\"GSI1SK\") @DynamoDbSecondarySortKey(indexNames = IndexNames.GS1_INDEX_NAME) public String getGsi1SortKey() { return gsi1SortKey; } } This effectively means that every item from our DynamoDB table will have 2 sets of primary keys: The PK partition key and a sort key named SK The GSI1PK partition key and a sort key named GSI1SK, both of which come from the global secondary index (or GSI). We can query items either using the main primary key (the PK partition key and the SK sort key) or the one from the GSI (the GSI1PK partition key and the GSI1SK sort key). ","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:10:0","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"Revisiting the single table design Let’s take another look at our DynamoDB table, after the global secondary index was added. It will look something like this: Notice the values of GSI1PK and GSI1SK, which form our new primary key. So, in order to fetch all topics created by the user mike for example, we’ll need to query our global secondary index and use the User#mike as the partition key and the Topic# prefix as the sort key. Here’s how it will look like using the AWS CLI: $ aws dynamodb query --table-name forum --index-name forum-gsi\\ --key-condition-expression \"GSI1PK = :partition_key_value and begins_with(GSI1SK, :sort_key_prefix)\"\\ --expression-attribute-values '{\":partition_key_value\": {\"S\": \"User#mike\"}, \":sort_key_prefix\": {\"S\": \"Topic#\"}}'\\ --endpoint-url http://localhost:4566 --region eu-west-1 We should get the following response: { \"Items\": [ { \"createdAt\": { \"S\": \"2023-04-24T13:27:08.975920875Z2023-04-24T13:27:08.975920875Z\" }, \"GSI1PK\": { \"S\": \"User#mike\" }, \"GSI1SK\": { \"S\": \"Topic#0f8aacc6-dce1-4df2-1529-d9f3fec10dc2\" }, \"SK\": { \"S\": \"Topic#0f8aacc6-dce1-4df2-1529-d9f3fec10dc2\" }, \"PK\": { \"S\": \"Category#4f0a4c06-6c11-4df2-9529-a993fec005c1\" }, \"title\": { \"S\": \"Java 19 released\" }, \"userName\": { \"S\": \"mike\" }, \"tags\": { \"L\": [ { \"S\": \"NSFW\" } ] } } ], \"Count\": 1, \"ScannedCount\": 1, \"ConsumedCapacity\": null } Or in other words, we just fetched the data highlighted in red: In order to implement this operation in Java, we’ll need to adjust our Topic entity a bit, so that it sets proper values for the GSI1PK partition key and the GSI1SK sort key, like shown here: @DynamoDbBean @EqualsAndHashCode(callSuper = true) public class Topic extends DynamoDbBase { public static final String TOPIC_PK_PREFIX = \"Category#\"; public static final String TOPIC_SK_PREFIX = \"Topic#\"; public static final String USER_GSI1_PK_PREFIX = \"User#\"; private String title; private String userName; private Instant createdAt; private List\u003cTopicTag\u003e tags; public Topic() { } public Topic(TopicBuilder builder) { this.title = builder.title; this.userName = builder.userName; this.createdAt = builder.createdAt; this.tags = builder.tags; this.partitionKey = builder.partitionKey; this.sortKey = builder.sortKey; this.gsi1SortKey = builder.gsi1SortKey; this.gsi1PartitionKey = builder.gsi1PartitionKey; } @DynamoDbIgnore public String getId() { return getSortKey().substring(TOPIC_SK_PREFIX.length()); } public void setId(String id) { this.sortKey = TopicKeyBuilder.makeSortKey(id); this.gsi1SortKey = TopicKeyBuilder.makeSortKey(id); } public String getCategoryId() { return getPartitionKey().substring(TOPIC_PK_PREFIX.length()); } //the rest o the getters \u0026 setters public static TopicBuilder builder() { return new TopicBuilder(); } public static class TopicBuilder { private String title; private String userName; private Instant createdAt; private String partitionKey; private String sortKey; private String gsi1PartitionKey; private String gsi1SortKey; private List\u003cTopicTag\u003e tags; public TopicBuilder title(String title) { this.title = title; return this; } public TopicBuilder userName(String userName) { this.userName = userName; this.gsi1PartitionKey = USER_GSI1_PK_PREFIX + userName; return this; } public TopicBuilder createdAt(Instant createdAt) { this.createdAt = createdAt; return this; } public TopicBuilder tags(List\u003cTopicTag\u003e tags) { this.tags = tags; return this; } public TopicBuilder gsi1PartitionKey(String gsi1PartitionKey) { this.gsi1PartitionKey = gsi1PartitionKey; return this; } public TopicBuilder gsi1SortKey(String gsi1SortKey) { this.gsi1SortKey = gsi1SortKey; return this; } public TopicBuilder partitionKey(String partitionKey) { this.partitionKey = partitionKey; return this; } public TopicBuilder sortKey(String sortKey) { this.sortKey = sortKey; this.gsi1SortKey = sortKey; return this; } public TopicBuilder categoryId(String categoryId) { this.partitionKey = TopicKeyBuilder.makePartitionKey(categoryId); return this; } public Topic build() { return new","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:10:1","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["DynamoDB","Spring Boot"],"content":"Conclusion In this blog post we’ve made a gentle introduction to DynamoDB, which is a NoSQL key-value managed database, designed for OLTP workloads and which offers consistent performance, regardless of scale. We took a glance at the AWS's recommended approach to using DynamoDB - the single table design, and we saw that data modelling in DynamoDB is way trickier than in traditional relational databases. The single table’s data model is done after collecting the data’s access patterns, and we saw that the global secondary indexes are a handy tool to accommodate more access patterns. It’s also worth mentioning that a big disadvantage is that after the table was designed, it can be quite difficult to add or change new access patterns, so some careful design upfront is definitely needed. The example code we used in this article can be found on GitHub. ","date":"2023-04-24","objectID":"/posts/introduction_to_dynamodb_and_single_table_design/:11:0","tags":["DynamoDB","Spring Boot","Localstack"],"title":"Introduction to DynamoDB and single table design","uri":"/posts/introduction_to_dynamodb_and_single_table_design/"},{"categories":["Spring Boot","Apache kafka"],"content":"Introduction In this blog post we’re going to explore how to expose Apache kafka's producer and consumer metrics to Spring Boots's actuator, and then importing them into prometheus and displaying them as a Grafana dashboard. Doing this will help us keep track of kafka’s producer and consumer performance and also will help us to see the impact of specific producer or consumer configuration properties. ","date":"2023-04-09","objectID":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/:1:0","tags":["Spring Boot","Apache kafka","metrics","prometheus","grafana"],"title":"Exposing Kafka producer \u0026 consumer metrics to actuator","uri":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/"},{"categories":["Spring Boot","Apache kafka"],"content":"Creating a simple Kafka producer application with spring boot Let’s go to https://start.spring.io/ and create a simple Spring boot project which will publish messages to Apache kafka. Let’s also create a docker-compose.yaml file, where we’ll declare all the docker containers we’re going to run locally. For now we’ll need Zookeeper, Apache kafka, and Redpanda console (for visualizing what’s inside our kafka). version:'3'services:#Zookeeper for Kafkazookeeper:image:confluentinc/cp-zookeeper:7.3.2container_name:zookeeperenvironment:ZOOKEEPER_CLIENT_PORT:2181ZOOKEEPER_TICK_TIME:2000#Kafka brokerbroker:image:confluentinc/cp-kafka:7.3.2container_name:brokerdepends_on:- zookeeperports:- \"9092:9092\"- \"49999:49999\"environment:KAFKA_BROKER_ID:1KAFKA_ZOOKEEPER_CONNECT:zookeeper:2181KAFKA_LISTENER_SECURITY_PROTOCOL_MAP:PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXTKAFKA_INTER_BROKER_LISTENER_NAME:PLAINTEXTKAFKA_ADVERTISED_LISTENERS:PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092KAFKA_AUTO_CREATE_TOPICS_ENABLE:\"true\"KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:1KAFKA_TRANSACTION_STATE_LOG_MIN_ISR:1KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR:1KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS:100KAFKA_JMX_PORT:49999KAFKA_MESSAGE_MAX_BYTES:10000#Redpanda console (kafka visualization tool)redpanda-console:image:docker.redpanda.com/vectorized/console:v2.2.0container_name:redpanda-consoleports:- \"7070:8080\"environment:KAFKA_BROKERS:broker:29092depends_on:- brokerrestart:on-failure We can start the infrastructure now using the following command: $ docker-compose up We can check if the Kafka cluster is up \u0026 running by checking the following url: http://localhost:7070/overview ","date":"2023-04-09","objectID":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/:2:0","tags":["Spring Boot","Apache kafka","metrics","prometheus","grafana"],"title":"Exposing Kafka producer \u0026 consumer metrics to actuator","uri":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/"},{"categories":["Spring Boot","Apache kafka"],"content":"Configuring the application.properties Now let’s edit our application.properties file so that it points to our kafka cluster, like shown below: #Kafka properties spring.kafka.producer.bootstrap-servers=localhost:9092 spring.kafka.producer.acks=all spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer #Actuator properties management.endpoints.web.exposure.include=* spring.jmx.enabled=true ","date":"2023-04-09","objectID":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/:2:1","tags":["Spring Boot","Apache kafka","metrics","prometheus","grafana"],"title":"Exposing Kafka producer \u0026 consumer metrics to actuator","uri":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/"},{"categories":["Spring Boot","Apache kafka"],"content":"Creating a simple kafka producer Now let’s try to create our Kafka producer. First we need to think about what kind of messages we’re going to publish to kafka. In our example we’ll use the so-called stock-quotes, which represent a price update for a given public company’s stock. We’ll use a StockQuote record for that: @Builder public record StockQuote(String id, String symbol, String exchange, String currency, String tradeValue) { } The Kafka publisher itself will look something like this: @Component @Slf4j public class StockQuotePublisher { private final KafkaTemplate\u003cString, StockQuote\u003e stockQuotePublisher; public StockQuotePublisher(KafkaTemplate\u003cString, StockQuote\u003e stockQuotePublisher) { this.stockQuotePublisher = stockQuotePublisher; } public void publish(StockQuote stockQuote) { log.info(\"Publishing stock quote: {}\", stockQuote); stockQuotePublisher.send(KafkaTopics.STOCK_QUOTES_TOPIC, stockQuote.id(), stockQuote); } } Since we want to look at metrics, let also write a generator class which will publish messages quite frequently to kafka, so that we’ll have more data to look at. @Component public class StockQuoteGenerator { private static final String[] EXCHANGES = {\"NYSE\", \"NSDQ\"}; private static final String[] STOCK_SYMBOLS = {\"DAVA\", \"AAPL\", \"NFLX\", \"META\", \"GOGL\", \"TSLA\", \"AMZN\"}; public StockQuote generate() { ThreadLocalRandom random = ThreadLocalRandom.current(); return StockQuote.builder() .id(UUID.randomUUID().toString()) .currency(\"EUR\") .exchange(EXCHANGES[random.nextInt(EXCHANGES.length)]) .symbol(STOCK_SYMBOLS[random.nextInt(STOCK_SYMBOLS.length)]) .tradeValue(BigDecimal.valueOf(random.nextInt(60, 1000)).toString()) .build(); } } Here’s out scheduler: @Component public class StockQuoteScheduler { private final StockQuotePublisher quotePublisher; private final StockQuoteGenerator stockQuoteGenerator; public StockQuoteScheduler(StockQuotePublisher quotePublisher, StockQuoteGenerator stockQuoteGenerator) { this.quotePublisher = quotePublisher; this.stockQuoteGenerator = stockQuoteGenerator; } @Scheduled(fixedRate = 500) public void tick() { StockQuote stockQuote = stockQuoteGenerator.generate(); quotePublisher.publish(stockQuote); } } If we’ll run our application, it should start publishing messages to kafka. We can check out the published messages in redpanda console: ","date":"2023-04-09","objectID":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/:2:2","tags":["Spring Boot","Apache kafka","metrics","prometheus","grafana"],"title":"Exposing Kafka producer \u0026 consumer metrics to actuator","uri":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/"},{"categories":["Spring Boot","Apache kafka"],"content":"Exposing the metrics to actuator Now let’s try to expose the Kafka producer metrics to Spring Boot's actuator endpoint, so that we observe what’s the performance of our producer. We’ll modify our kafka java configuration like this: @Configuration(proxyBeanMethods = false) public class KafkaConfig { @Bean public ProducerFactory\u003cString, StockQuote\u003e producerFactory(KafkaProperties properties, MeterRegistry meterRegistry) { ProducerFactory\u003cString, StockQuote\u003e producerFactory = new DefaultKafkaProducerFactory\u003c\u003e(properties.buildProducerProperties()); producerFactory.addListener(new MicrometerProducerListener\u003c\u003e(meterRegistry)); //\u003c--- expose metrics to actuator return producerFactory; } @Bean public KafkaTemplate\u003cString, StockQuote\u003e kafkaTemplate(ProducerFactory\u003cString, StockQuote\u003e producerFactory) { KafkaTemplate\u003cString, StockQuote\u003e kafkaTemplate = new KafkaTemplate\u003c\u003e(producerFactory); return new KafkaTemplate\u003c\u003e(producerFactory); } } Also we’ve configured our spring boot app so that it exposes all actuator endpoints, like this #Actuator properties management.endpoints.web.exposure.include=* If we’ll try to access out actuator metrics endpoint (http://localhost:8080/actuator/metrics), we should see the following: { \"names\": [ //... \"kafka.app.info.start.time.ms\", \"kafka.producer.batch.size.avg\", \"kafka.producer.batch.size.max\", \"kafka.producer.batch.split.rate\", \"kafka.producer.batch.split.total\", \"kafka.producer.buffer.available.bytes\", \"kafka.producer.buffer.exhausted.rate\", \"kafka.producer.buffer.exhausted.total\", \"kafka.producer.buffer.total.bytes\", \"kafka.producer.bufferpool.wait.ratio\", \"kafka.producer.bufferpool.wait.time.ns.total\", \"kafka.producer.bufferpool.wait.time.total\", \"kafka.producer.compression.rate.avg\", \"kafka.producer.connection.close.rate\", \"kafka.producer.connection.close.total\", \"kafka.producer.connection.count\", \"kafka.producer.connection.creation.rate\", \"kafka.producer.connection.creation.total\", \"kafka.producer.failed.authentication.rate\", \"kafka.producer.failed.authentication.total\", \"kafka.producer.failed.reauthentication.rate\", \"kafka.producer.failed.reauthentication.total\", \"kafka.producer.flush.time.ns.total\", \"kafka.producer.incoming.byte.rate\", \"kafka.producer.incoming.byte.total\", \"kafka.producer.io.ratio\", \"kafka.producer.io.time.ns.avg\", \"kafka.producer.io.time.ns.total\", \"kafka.producer.io.wait.ratio\", \"kafka.producer.io.wait.time.ns.avg\", \"kafka.producer.io.wait.time.ns.total\", \"kafka.producer.io.waittime.total\", \"kafka.producer.iotime.total\", \"kafka.producer.metadata.age\", \"kafka.producer.metadata.wait.time.ns.total\", \"kafka.producer.network.io.rate\", \"kafka.producer.network.io.total\", \"kafka.producer.outgoing.byte.rate\", \"kafka.producer.outgoing.byte.total\", \"kafka.producer.produce.throttle.time.avg\", \"kafka.producer.produce.throttle.time.max\", \"kafka.producer.reauthentication.latency.avg\", \"kafka.producer.reauthentication.latency.max\", \"kafka.producer.record.error.rate\", \"kafka.producer.record.error.total\", \"kafka.producer.record.queue.time.avg\", \"kafka.producer.record.queue.time.max\", \"kafka.producer.record.retry.rate\", \"kafka.producer.record.retry.total\", \"kafka.producer.record.send.rate\", \"kafka.producer.record.send.total\", \"kafka.producer.record.size.avg\", \"kafka.producer.record.size.max\", \"kafka.producer.records.per.request.avg\", \"kafka.producer.request.latency.avg\", \"kafka.producer.request.latency.max\", \"kafka.producer.request.rate\", \"kafka.producer.request.size.avg\", \"kafka.producer.request.size.max\", \"kafka.producer.request.total\", \"kafka.producer.requests.in.flight\", \"kafka.producer.response.rate\", \"kafka.producer.response.total\", \"kafka.producer.select.rate\", \"kafka.producer.select.total\", \"kafka.producer.successful.authentication.no.reauth.total\", \"kafka.producer.successful.authentication.rate\", \"kafka.producer.successful.authentication.total\", \"kafka.producer.successful.reauthentication.rate\", \"kafka.producer.successful.reauthentication.total\", \"kafka.producer.txn.abort.time.ns.tot","date":"2023-04-09","objectID":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/:3:0","tags":["Spring Boot","Apache kafka","metrics","prometheus","grafana"],"title":"Exposing Kafka producer \u0026 consumer metrics to actuator","uri":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/"},{"categories":["Spring Boot","Apache kafka"],"content":"Exporting the metrics to Prometheus and Grafana As we remember, when we’ve created the project we’ve added the following maven dependency: \u003cdependencies\u003e \u003c!-- ... --\u003e \u003cdependency\u003e \u003cgroupId\u003eio.micrometer\u003c/groupId\u003e \u003cartifactId\u003emicrometer-registry-prometheus\u003c/artifactId\u003e \u003cscope\u003eruntime\u003c/scope\u003e \u003c/dependency\u003e \u003c!-- ... --\u003e \u003c/dependencies\u003e What this did is that our Actuator now has a new endpoint called http://localhost:8080/actuator/prometheus. Basically it provides exactly the same information as http://localhost:8080/actuator/metrics, the difference being that it’s in an Prometheus-specific format. We can now configure a Prometheus instance to poll this endpoint periodically. The idea is that Prometheus is a time-series database tailored specifically for metrics. Whenever Prometheus will hit the http://localhost:8080/actuator/prometheus, it will store all the metrics information and associate every metric with a timestamp. By doing that, we can observe how a specific metric evolves over time. Let’s add Prometheus to our docker-compose.yaml file, like shown below: version:'3'services:#Previously defined containers like zookeeper, kafka \u0026 redpanda#...#Prometheusprometheus:image:prom/prometheus:v2.28.1container_name:prometheusports:- \"9090:9090\"volumes:- ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml The prometheus.yml file from above is a simple configuration file which looks like this: global:scrape_interval:30sscrape_configs:- job_name:'spring_micrometer'metrics_path:'/actuator/prometheus'scrape_interval:35sscrape_timeout:30sstatic_configs:- targets:['stock-quote-producer:8080']basic_auth:username:'admin'password:'admin' What’s worth pointing out is that Prometheus will invoke the http://stock-quote-producer:8080/actuator/prometheus endpoint periodically (every 35 seconds). The request timeout for a single call is 30 seconds. Now the catch is that since we’ve run Prometheus as a docker container (which is isolated from our local machine), our application should be run also as a docker container, so that Prometheus can call it. At the moment the above prometheus.yml expects our app to be running on http://stock-quote-producer:8080. So we need now to create a docker image out of our spring boot app and use stock-quote-producer as the container name. Let’s do this. FROMopenjdk:17-alpineCOPY target/kafka-producer-consumer-metrics-0.0.1-SNAPSHOT.jar /evil/kafka-producer-consumer-metrics.jarRUN addgroup -S -g 2023 evil \u0026\u0026 \\ adduser -S -g evil -u 2023 evilRUN mkdir -p /evil/RUN mkdir -p /evil/logsRUN chown -R evil:evil /evilRUN find /evil/ -type f -exec chmod 644 {} \\; \u0026\u0026 chmod 775 /evil/logsUSERevil:evilEXPOSE8080WORKDIR/evilENTRYPOINT [ \"java\",\\ \"-jar\",\\ \"./kafka-producer-consumer-metrics.jar\"] Nothing fancy so far. We’ve just copied the target/kafka-producer-consumer-metrics-0.0.1-SNAPSHOT.jar file into a directory called evil and we’ve also created a new group called evil, with a user named evil as well. Now we’ll modify our docker-compose.yaml file once more so that it includes our spring boot application, like this: version:'3'services:#Previously defined containers like zookeeper, kafka \u0026 redpanda#...stock-quote-producer:build:dockerfile:./infra/docker/Dockerfilecontext:\"../../\"container_name:stock-quote-producerports:- \"8080:8080\"environment:SPRING_KAFKA_PRODUCER_BOOTSTRAP_SERVERS:broker:29092restart:on-failuredepends_on:- broker- prometheus Now if we’ll run the new docker-compose.yaml file, all of our metrics data should be stored in prometheus, and we should be able to check how specific metrics evolve over time. To access the Prometheus dashboard, we just need to access the following endpoint: http://localhost:9090/. Now Prometheus is a great tool to store metrics, but it doesn’t have fancy graph-plotting abilities. To fix that we can use Grafana ","date":"2023-04-09","objectID":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/:4:0","tags":["Spring Boot","Apache kafka","metrics","prometheus","grafana"],"title":"Exposing Kafka producer \u0026 consumer metrics to actuator","uri":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/"},{"categories":["Spring Boot","Apache kafka"],"content":"Configuring Grafana In order to use Grafana, we’ll need to add yet another docker container to our docker-compose.yaml file, like shown below: version:'3'services:#Previously defined containers like zookeeper, kafka \u0026 redpanda#...#Grafana dashboardgrafana:image:grafana/grafana:8.0.6container_name:grafanaports:- \"3000:3000\"depends_on:- prometheus The Grafana will be accessible at http://localhost:3000/. The default credentials are admin for the username and admin for the password. First, we’ll need to configure a Prometheus datasource. Here we just need to specify the Prometheus's address, which in our case will be http://prometheus:9090/ Nice. Now let’s try to create a basic Grafana dashboard displaying the kafka_producer_record_send_rate metric, like shown below: In order to see the maximum throughput of our spring boot app, let’s modify out StockQuoteScheduler like shown below, so that it doesn’t publish only 2 messages per second, but much more. @Component public class StockQuoteScheduler { //... @PostConstruct private void init() { new Thread(() -\u003e { try { while (true) { quotePublisher.publish(stockQuoteGenerator.generate()); } } catch (Exception e) { log.error(\"Kafka producer error\", e); } }).start(); } } Now, if we’ll try to run our app in this configuration, we’ll see that our application produces about 80K messages per second. ","date":"2023-04-09","objectID":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/:4:1","tags":["Spring Boot","Apache kafka","metrics","prometheus","grafana"],"title":"Exposing Kafka producer \u0026 consumer metrics to actuator","uri":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/"},{"categories":["Spring Boot","Apache kafka"],"content":"Conclusion In this blog post we saw how to expose Apache Kafka's metrics to actuator, how to then export these metrics to Prometheus and then how to create a Grafana dashboard out of them. The example code we used in this article can be found on GitHub. ","date":"2023-04-09","objectID":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/:5:0","tags":["Spring Boot","Apache kafka","metrics","prometheus","grafana"],"title":"Exposing Kafka producer \u0026 consumer metrics to actuator","uri":"/posts/exposing_kafka_producer_and_consumer_metrics_to_actuator/"},{"categories":["Spring Boot","DynamoDB"],"content":"Introduction In Spring Boot, when writing tests there’s a way to slice up the test’s application context, so that it contains only the beans which are appropriate for the given test. Some examples are @WebMvcTest, @DataJpaTest, @RestClientTest and many others. For example, when testing a jpa repository, we’re not interested in the web-related components (like controllers), so using the @DataJpaTest will reduce the size of the application context, so that it contains only the repositories and other infrastructure related to that (like DataSources, EntityManagerFactory and others). ","date":"2023-03-26","objectID":"/posts/creating_a_custom_spring_boot_test_slice/:1:0","tags":["Spring Boot","Testing","Localstack","DynamoDB"],"title":"Creating a custom Spring Boot test slice","uri":"/posts/creating_a_custom_spring_boot_test_slice/"},{"categories":["Spring Boot","DynamoDB"],"content":"When custom test-sliced are needed Let’s say we are working on an application which uses DynamoDB. It is a simple REST API for a simple anonymous forum, having categories, topics and comments. Let’s have a look more closely at the categories part of the application. The Category entity will look something like this: @Data public class DynamoDbBase { protected String partitionKey; protected String sortKey; @DynamoDbPartitionKey @DynamoDbAttribute(\"PK\") public String getPartitionKey() { return partitionKey; } @DynamoDbSortKey @DynamoDbAttribute(\"SK\") public String getSortKey() { return sortKey; } } The DynamoDbBase will act as the base-class for all entities. It has a generic partition and sort key, because we plan to use a single DynamoDB table for all entities (also known as Single table design). Now the Category entity finally looks like the following: @DynamoDbBean @EqualsAndHashCode(callSuper = true) public class Category extends DynamoDbBase { public static final String CATEGORY_PK = \"Category\"; public static final String CATEGORY_SK_PREFIX = \"Category#\"; private String name; public Category() { } public Category(CategoryBuilder builder) { this.name = builder.name; this.partitionKey = builder.partitionKey; this.sortKey = builder.sortKey; } public void setId(String id) { setPartitionKey(CATEGORY_PK); setSortKey(CategoryKeyBuilder.makeSortKey(id)); } public String getId() { return getSortKey().substring(CATEGORY_SK_PREFIX.length()); } public String getName() { return this.name; } public void setName(String name) { this.name = name; } public static CategoryBuilder builder() { return new CategoryBuilder(); } public static class CategoryKeyBuilder { public static String makePartitionKey(String id) { return CATEGORY_PK; } public static String makeSortKey(String id) { return CATEGORY_SK_PREFIX + id; } } public static class CategoryBuilder { private String name; private String partitionKey; private String sortKey; public CategoryBuilder name(String name) { this.name = name; return this; } public CategoryBuilder partitionKey(String partitionKey) { this.partitionKey = partitionKey; return this; } public CategoryBuilder sortKey(String sortKey) { this.sortKey = sortKey; return this; } public Category build() { return new Category(this); } } } It is quite simple, it just has a name attribute, getters \u0026 setters and a builder. Also we’ll need to add a bit of configuration, by providing the DynamoDbEnhancedClient and DynamoDbTable beans, like shown below: @Configuration(proxyBeanMethods = false) @EnableConfigurationProperties(AwsProperties.class) public class DynamoDbConfig { @Bean public DynamoDbClient dynamoDbClient(AwsProperties properties, AwsBasicCredentials awsCredentials) { var builder = DynamoDbClient.builder() .region(Region.of(properties.region())); if (properties.endpointOverride() != null) { builder.endpointOverride(URI.create(properties.endpointOverride())); } return builder.credentialsProvider(() -\u003e awsCredentials).build(); } @Bean public AwsBasicCredentials awsCredentials(AwsProperties properties) { return AwsBasicCredentials.create(properties.credentials().accessKey(), properties.credentials().secretKey()); } @Bean public DynamoDbEnhancedClient dynamoDbEnhancedClient(DynamoDbClient dynamoDbClient) { return DynamoDbEnhancedClient.builder() .dynamoDbClient(dynamoDbClient) .build(); } @Bean public DynamoDbTable\u003cCategory\u003e categoryTable(DynamoDbEnhancedClient dynamoDbEnhancedClient, AwsProperties properties) { return dynamoDbEnhancedClient.table(properties.dynamoDbTableName(), TableSchema.fromBean(Category.class)); } } Let’s try to write a repository for the Category entity: public interface CategoryRepository { List\u003cCategory\u003e findAll(); Category create(Category categoryToCreate); Optional\u003cCategory\u003e findById(String id); } The CategoryRepository interface specifies the repository contract, at the moment having the findAll(), findById() and create() operations. The implementation can look something like this: @Repository public c","date":"2023-03-26","objectID":"/posts/creating_a_custom_spring_boot_test_slice/:1:1","tags":["Spring Boot","Testing","Localstack","DynamoDB"],"title":"Creating a custom Spring Boot test slice","uri":"/posts/creating_a_custom_spring_boot_test_slice/"},{"categories":["Spring Boot","DynamoDB"],"content":"Testing time Now let’s try to write a test for it. We’ll end up with something like this: @SpringBootTest public class DynamoDBCategoryRepositoryTest extends AbstractDatabaseTest { @Autowired private DynamoDbTable\u003cCategory\u003e categoryTable; @Autowired private DynamoDBCategoryRepository categoryRepository; @BeforeEach public void setUp() { categoryTable.deleteTable(); categoryTable.createTable(); categoryTable.putItem(Category.builder() .name(\"Software development\") .partitionKey(\"Category\") .sortKey(\"Category#501735c3-5da7-4684-82d3-37af5d5dc44f\") .build()); categoryTable.putItem(Category.builder() .name(\"Anime\") .partitionKey(\"Category\") .sortKey(\"Category#601735c3-6da7-4684-62d3-47af5d5dc44e\") .build()); } @Test public void shouldBeAbleToFindAllCategories() { List\u003cCategory\u003e expectedCategories = List.of( Category.builder() .name(\"Software development\") .partitionKey(\"Category\") .sortKey(\"Category#501735c3-5da7-4684-82d3-37af5d5dc44f\") .build(), Category.builder() .name(\"Anime\") .partitionKey(\"Category\") .sortKey(\"Category#601735c3-6da7-4684-62d3-47af5d5dc44e\") .build() ); List\u003cCategory\u003e actualCategories = categoryRepository.findAll(); assertThat(actualCategories).isEqualTo(expectedCategories); } @Test public void shouldBeAbleToFindCategoriesById() { Category expectedCategory = Category.builder() .name(\"Software development\") .partitionKey(\"Category\") .sortKey(\"Category#501735c3-5da7-4684-82d3-37af5d5dc44f\") .build(); Optional\u003cCategory\u003e actualCategory = categoryRepository.findById(\"501735c3-5da7-4684-82d3-37af5d5dc44f\"); assertThat(actualCategory).isEqualTo(Optional.of(expectedCategory)); } } The DynamoDBCategoryRepositoryTest is quite simple. What’s worth noting is that before each test we try to clean up the table, by deleting the table and re-creating it. We also insert some test data so that we have something to work with. Also it’s worth pointing out that this test uses Localstack to simulate the real DynamoDB service. We spin-up Localstack using Testcontainers, and the AbstractDatabaseTest contains all the guts related to that: public class AbstractDatabaseTest { private static final String TABLE_NAME = \"forum\"; public static final LocalStackContainer localstack = new LocalStackContainer(DockerImageName.parse(\"localstack/localstack:1.4\")) .withServices(LocalStackContainer.Service.DYNAMODB); @DynamicPropertySource public static void replaceProperties(DynamicPropertyRegistry registry) { registry.add(\"aws.endpoint-override\", () -\u003e localstack.getEndpointOverride(LocalStackContainer.Service.DYNAMODB)); registry.add(\"aws.credentials.secret-key\", localstack::getSecretKey); registry.add(\"aws.credentials.access-key\", localstack::getAccessKey); registry.add(\"aws.region\", localstack::getRegion); } static { localstack.start(); createResources(); } private static void createResources() { try { localstack.execInContainer(\"awslocal\", \"dynamodb\", \"create-table\", \"--table-name\", TABLE_NAME, \"--attribute-definitions\", \"AttributeName=PK,AttributeType=S\", \"AttributeName=SK,AttributeType=S\", \"--key-schema\", \"AttributeName=PK,KeyType=HASH\", \"AttributeName=SK,KeyType=RANGE\", \"--provisioned-throughput\", \"ReadCapacityUnits=5,WriteCapacityUnits=5\"); } catch (IOException | InterruptedException e) { throw new RuntimeException(e); } } } A slight problem with this test is that it uses the @SpringBootTest which pretty much spins up the whole application context, containing not only repository-specific classes, but also web related ones for example. This can increase the test’s startup time and it’s a shame, since we don’t care about the web layer for this particular test. Let’s try to fix this, by writing a custom test slice. ","date":"2023-03-26","objectID":"/posts/creating_a_custom_spring_boot_test_slice/:1:2","tags":["Spring Boot","Testing","Localstack","DynamoDB"],"title":"Creating a custom Spring Boot test slice","uri":"/posts/creating_a_custom_spring_boot_test_slice/"},{"categories":["Spring Boot","DynamoDB"],"content":"Creating a custom test-slice It’ll be nice to create a custom test-slice. We want something like @DataJpaTest, which allows us to either spin up only the repository layer. Let’s take a look at the @DataJpaTest annotation, so that we find some inspiration: @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @BootstrapWith(DataJdbcTestContextBootstrapper.class) @ExtendWith({SpringExtension.class}) @OverrideAutoConfiguration( enabled = false ) @TypeExcludeFilters({DataJdbcTypeExcludeFilter.class}) @Transactional @AutoConfigureCache @AutoConfigureDataJdbc @AutoConfigureTestDatabase @ImportAutoConfiguration public @interface DataJdbcTest { //... } The most interesting parts are the following: @OverrideAutoConfiguration(enabled = false): disables auto-configuration @BootstrapWith(DataJdbcTestContextBootstrapper.class): specifies how to bootstrap the application context. DataJdbcTestContextBootstrapper is a small specialization of SpringBootTestContextBootstrapper @ImportAutoConfiguration: allows to import some auto-configurations. It’s useful since all auto-configurations were disabled by @OverrideAutoConfiguration(enabled = false) @TypeExcludeFilters({DataJdbcTypeExcludeFilter.class}): this is the most interesting one, this is the actual filter of the beans which we want to include/exclude from the application context Everything else just configures the repository infrastructure, like enabling caching (via @AutoConfigureCache) and transactions (via @Transactional). Now let’s try to create a similar thing for DynamoDB. We’ll create a custom annotation named @DynamoDbTest, which initially will look like the following: @ExtendWith(SpringExtension.class) @OverrideAutoConfiguration(enabled = false) @BootstrapWith(SpringBootTestContextBootstrapper.class) @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) public @interface DynamoDbTest { Class\u003c?\u003e[] repositories() default {}; } Since we didn’t add yet the @TypeExcludeFilters annotation, with a custom implementation of the TypeExcludeFilter, we’ll still end up with the whole application context. But let’s try to annotate our DynamoDBCategoryRepositoryTest with the @DynamoDbTest annotation, just to make sure everything still works: @DynamoDbTest public class DynamoDBCategoryRepositoryTest extends AbstractDatabaseTest { @Autowired private DynamoDbTable\u003cCategory\u003e categoryTable; @Autowired private DynamoDBCategoryRepository categoryRepository; @BeforeEach public void setUp() { categoryTable.deleteTable(); categoryTable.createTable(); categoryTable.putItem(Category.builder() .name(\"Software development\") .partitionKey(\"Category\") .sortKey(\"Category#501735c3-5da7-4684-82d3-37af5d5dc44f\") .build()); categoryTable.putItem(Category.builder() .name(\"Anime\") .partitionKey(\"Category\") .sortKey(\"Category#601735c3-6da7-4684-62d3-47af5d5dc44e\") .build()); } @Test public void shouldBeAbleToFindAllCategories() { List\u003cCategory\u003e expectedCategories = List.of( Category.builder() .name(\"Software development\") .partitionKey(\"Category\") .sortKey(\"Category#501735c3-5da7-4684-82d3-37af5d5dc44f\") .build(), Category.builder() .name(\"Anime\") .partitionKey(\"Category\") .sortKey(\"Category#601735c3-6da7-4684-62d3-47af5d5dc44e\") .build() ); List\u003cCategory\u003e actualCategories = categoryRepository.findAll(); assertThat(actualCategories).isEqualTo(expectedCategories); } } If we try to run the tests, they pass, which means that we didn’t broke anything yet. If we try to inject the ApplicationContext into our DynamoDBCategoryRepositoryTest and inspect it in the debugger, we’ll see something like this: We can observe that our ApplicationContext contains all the beans, including the ones from the web-layer which we’re not interested in for this particular test. In order to fix that, we’ll implement a custom TypeExcludeFilter. It will look something like this: public class DynamoDbTypeExcludeFilter extends AnnotationCustomizableTypeExcludeFilter { private static final Set\u003cClass\u003c?\u003e\u003e DEFAULT","date":"2023-03-26","objectID":"/posts/creating_a_custom_spring_boot_test_slice/:2:0","tags":["Spring Boot","Testing","Localstack","DynamoDB"],"title":"Creating a custom Spring Boot test slice","uri":"/posts/creating_a_custom_spring_boot_test_slice/"},{"categories":["Spring Boot","DynamoDB"],"content":"Conclusion In this blog post we saw how to create a custom Spring Boot test slice for DynamoDB. We saw that it’s pretty easy, we just need a custom annotation annotated with: @OverrideAutoConfiguration(enabled = false): disables auto-configuration @ImportAutoConfiguration(dev.softice.slice.config.DynamoDbConfig.class): import a specific auto-configuration class @BootstrapWith(SpringBootTestContextBootstrapper.class): specifies the application-context bootstrapper @TypeExcludeFilters(DynamoDbTypeExcludeFilter.class): registers a TypeExcludeFilter which filters out beans we’re not interested in The example code we used in this article can be found on GitHub. ","date":"2023-03-26","objectID":"/posts/creating_a_custom_spring_boot_test_slice/:3:0","tags":["Spring Boot","Testing","Localstack","DynamoDB"],"title":"Creating a custom Spring Boot test slice","uri":"/posts/creating_a_custom_spring_boot_test_slice/"},{"categories":["Spring Boot"],"content":"Introduction Today we’re going to look at how to return pretty error responses for our REST APIs, using Spring Boot's controller advices. Even though controller advices are a well-known mechanism, no many projects use them to their full potential. In this article we’ll try to fix that. ","date":"2022-06-04","objectID":"/posts/bootiful_error_handling_with_controller_advices/:1:0","tags":["Spring Boot"],"title":"Bootiful error handling with @ControllerAdvices","uri":"/posts/bootiful_error_handling_with_controller_advices/"},{"categories":["Spring Boot"],"content":"The REST api Initially, we’ll need a couple of HTTP endpoints, so that we can simulate some errors and see if we as users of that REST api can understand what went wrong. We’ll use a simple HTTP api, exposing CRUD operations for movies. Let’s say we have the following controller: @RestController @RequestMapping(\"/api/v1/movies\") public class MovieController { private final MovieService movieService; public MovieController(MovieService movieService) { this.movieService = movieService; } @GetMapping public List\u003cMovieResponse\u003e getAll() { return movieService.getAll(); } @GetMapping(\"{id}\") public MovieResponse getById(@PathVariable(\"id\") Long id) { return movieService.getById(id); } @PostMapping public ResponseEntity\u003cMovieResponse\u003e create(@RequestBody @Validated CreateMovieRequest request) { MovieResponse createdMovie = movieService.create(request.toMovie()); URI location = MvcUriComponentsBuilder.fromMethodCall(MvcUriComponentsBuilder.on(getClass()) .getById(createdMovie.id())) .build() .toUri(); return ResponseEntity.created(location) .body(createdMovie); } } As we can see, the controller does not have any sophisticated logic (and it should be like this stop putting business logic in controllers), it just delegates to the service. To make things clearer, let’s take a look at the service as well. @Service public class MovieService { private final MovieRepository movieRepository; public MovieService(MovieRepository movieRepository) { this.movieRepository = movieRepository; } @Transactional(readOnly = true) public List\u003cMovieResponse\u003e getAll() { return movieRepository.findAll() .stream() .map(MovieResponse::from) .toList(); } @Transactional(readOnly = true) public MovieResponse getById(Long id) { Movie movie = movieRepository.findById(id) .orElseThrow(() -\u003e new EntityNotFoundException(\"No movie with id:' \" + id + \"' was found.\")); return MovieResponse.from(movie); } @Transactional public MovieResponse create(Movie movieToCreate) { Movie createdMovie = movieRepository.save(movieToCreate); return MovieResponse.from(createdMovie); } } The service is also not that complicated, it has some basic operations like create and get movie by id and it just uses a simple Spring-Data-JPA repository. Using this simple REST api, let’s try to simulate some errors to see how the default error responses will look like. The simplest endpoint to call can be finding a movie by id. Let’s see the successful scenario: GET http://localhost:8081/api/v1/movies/1 And we get the following response: HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Mon, 27 Jun 2022 20:00:48 GMT Keep-Alive: timeout=60 Connection: keep-alive { \"id\": 1, \"name\": \"Pulp Fiction\", \"publishYear\": 1994 } Now let’s try to simulate an error. If we look at our endpoint, we can see that the movie id has the type java.lang.Long. What will happen if the user will pass something that cannot be parsed as a Long? @RestController @RequestMapping(\"/api/v1/movies\") public class MovieController { //... @GetMapping(\"{id}\") public MovieResponse getById(@PathVariable(\"id\") Long id) { return movieService.getById(id); } //... } Let’s find out. We’ll use the string 'a' as an invalid id. GET http://localhost:8081/api/v1/movies/a And we get back the following response: HTTP/1.1 400 Content-Type: application/json Transfer-Encoding: chunked Date: Mon, 27 Jun 2022 20:08:57 GMT Connection: close { \"timestamp\": \"2022-06-27T20:08:57.459+00:00\", \"status\": 400, \"error\": \"Bad Request\", \"path\": \"/api/v1/movies/a\" } We got back an HTTP response with the status code 400 Bad request with a json payload describing the error, all of that was done by Spring Boot, without any configuration. Pretty good for a default, but the problem with that response is that it communicates almost nothing. Something’s wrong with our request, but what exactly? In our case, the request is quite simple and it’s easy to figure out the problem, but in cases where the endpoint which we’re calling has a lot of path and qu","date":"2022-06-04","objectID":"/posts/bootiful_error_handling_with_controller_advices/:1:1","tags":["Spring Boot"],"title":"Bootiful error handling with @ControllerAdvices","uri":"/posts/bootiful_error_handling_with_controller_advices/"},{"categories":["Spring Boot"],"content":"The GlobalExceptionHandler Since the MethodArgumentTypeMismatchException can be thrown from any controller, we’ll add a default @RestControllerAdvice which will return an error response, describing in more details what went wrong. We’ll call it GlobalExceptionHandler and it will look like this: @Slf4j @RestControllerAdvice @Order(Ordered.LOWEST_PRECEDENCE) public class GlobalExceptionHandler { } Notice the @Order(Ordered.LOWEST_PRECEDENCE) annotation. It is needed because we want our GlobalExceptionHandler to be the last one called, when a controller didn’t handle an exception. Sometimes there are exceptions specific for a particular controller. In that case we want to allow the possibility of having controller-specific controller-advices. Or in other words, we want the GlobalExceptionHandler to be the last controller-advice which is called, and allow controller-specific controller-advices to be executed first. Now, in order to return a pretty error response, we need a DTO class containing information about the error. We’ll call it ErrorResponse, and it will look something like this: public record ErrorResponse(String statusCode, String path, List\u003cString\u003e messages) { @Builder public ErrorResponse { } } It has just 3 fields: statusCode: represents the error status code. Can be the HTTP status code or something similar to that. path: represents the request path of the called endpoint messages: an array of strings describing the error ","date":"2022-06-04","objectID":"/posts/bootiful_error_handling_with_controller_advices/:1:2","tags":["Spring Boot"],"title":"Bootiful error handling with @ControllerAdvices","uri":"/posts/bootiful_error_handling_with_controller_advices/"},{"categories":["Spring Boot"],"content":"MethodArgumentTypeMismatchException Let’s handle our MethodArgumentTypeMismatchException. For that, we’ll need to add an @ExceptionHandler in our GlobalExceptionHandler. It will look something like this: @Slf4j @RestControllerAdvice @Order(Ordered.LOWEST_PRECEDENCE) public class GlobalExceptionHandler { @ExceptionHandler(MethodArgumentTypeMismatchException.class) public ResponseEntity\u003cErrorResponse\u003e onMethodArgumentTypeMismatchException(MethodArgumentTypeMismatchException e, HttpServletRequest request) { MethodParameter parameter = e.getParameter(); String message = \"Parameter: '\" + parameter.getParameterName() + \"' is not valid. \" + \"Value '\" + e.getValue() + \"' could not be bound to type: '\" + parameter.getParameterType() .getSimpleName() .toLowerCase() + \"'\"; log.error(\"Exception while handling request: \" + message, e); ErrorResponse errorResponse = ErrorResponse.builder() .statusCode(HttpStatus.BAD_REQUEST.name()) .messages(List.of(message)) .path(request.getServletPath()) .build(); return ResponseEntity.badRequest() .body(errorResponse); } } Basically we’ve extracted all the useful information (like the expected type and the invalid value) from the MethodArgumentTypeMismatchException and constructed an ErrorResponse, which will be returned to the user. Now, if we try to execute our invalid request again: GET http://localhost:8081/api/v1/movies/a We should get the following response: HTTP/1.1 400 Content-Type: application/json Transfer-Encoding: chunked Date: Mon, 27 Jun 2022 20:16:30 GMT Connection: close { \"statusCode\": \"BAD_REQUEST\", \"path\": \"/api/v1/movies/a\", \"messages\": [ \"Parameter: 'id' is not valid. Value 'a' could not be bound to type: 'long'\" ] } Now it’s way more clear what’s wrong. The value a is not a numeric value. There are some downsides though. One could argue that our error message is too revealing, and that communicating to the user that we expect a long value can give a hint to a malicious user in what language our REST api was written in. We can argue that this is not a huge problem, we can easily change the error message to not include the expected type. Everything is up to us. ","date":"2022-06-04","objectID":"/posts/bootiful_error_handling_with_controller_advices/:2:0","tags":["Spring Boot"],"title":"Bootiful error handling with @ControllerAdvices","uri":"/posts/bootiful_error_handling_with_controller_advices/"},{"categories":["Spring Boot"],"content":"Missing query parameters Let’s modify our getMovieById endpoint and use a query parameter for the movie id instead of a path parameter. @RestController @RequestMapping(\"/api/v1/movies\") public class MovieController { private final MovieService movieService; public MovieController(MovieService movieService) { this.movieService = movieService; } @GetMapping public MovieResponse getById(@RequestParam(\"id\") Long id) { return movieService.getById(id); } } A successful requst will look like this: GET http://localhost:8081/api/v1/movies?id=1 We should get the following response: HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Mon, 27 Jun 2022 20:52:26 GMT Keep-Alive: timeout=60 Connection: keep-alive { \"id\": 1, \"name\": \"Pulp Fiction\", \"publishYear\": 1994 } Looking good. What will happen if we’ll pass an invalid value for the id query parameter? After all, the movie id is still a long. Let’s find out: GET http://localhost:8081/api/v1/movies?id=a We passed the value 'a' as the movie id, which clearly there’s no way it is a valid long value. We’ll get back the following response: HTTP/1.1 400 Content-Type: application/json Transfer-Encoding: chunked Date: Mon, 27 Jun 2022 20:53:44 GMT Connection: close { \"statusCode\": \"BAD_REQUEST\", \"path\": \"/api/v1/movies\", \"messages\": [ \"Parameter: 'id' is not valid. Value 'a' could not be bound to type: 'long'\" ] } Pretty nice, we got a MethodArgumentTypeMismatchException again, so our GlobalExceptionHandler did it’s magic. Now the question is, what will happen if we were to omit the id query parameter? Let’s try it out: GET http://localhost:8081/api/v1/movies We’ll get the following HTTP response: HTTP/1.1 400 Content-Type: application/json Transfer-Encoding: chunked Date: Mon, 27 Jun 2022 20:54:32 GMT Connection: close { \"timestamp\": \"2022-06-27T20:54:32.038+00:00\", \"status\": 400, \"error\": \"Bad Request\", \"path\": \"/api/v1/movies\" } Not so great, we know our request is bad, but what exactly? If we look at the logs, we can see the following error: 2022-06-28 00:03:39.197 WARN 819720 --- [nio-8081-exec-1] .w.s.m.s.DefaultHandlerExceptionResolver : Resolved [org.springframework.web.bind.MissingServletRequestParameterException: Required request parameter 'id' for method parameter type Long is not present] A MissingServletRequestParameterException was thrown, and we should handle it if we want a prettier error response. It will look something like this: @Slf4j @RestControllerAdvice @Order(Ordered.LOWEST_PRECEDENCE) public class GlobalExceptionHandler { @ExceptionHandler(MissingServletRequestParameterException.class) public ResponseEntity\u003cErrorResponse\u003e onMissingServletRequestParameterException(MissingServletRequestParameterException e, HttpServletRequest request) { String message = \"Parameter: '\" + e.getParameterName() + \"' of type \" + e.getParameterType().toLowerCase(Locale.ROOT) + \" is required but is missing\"; log.error(\"Exception while handling request: \" + message, e); ErrorResponse errorResponse = ErrorResponse.builder() .statusCode(HttpStatus.BAD_REQUEST.name()) .messages(List.of(message)) .path(request.getServletPath()) .build(); return ResponseEntity.badRequest() .body(errorResponse); } } If we’ll try to execute again our erroneous http request with the id query parameter missing, like shown below: GET http://localhost:8081/api/v1/movies We should get the following error response: HTTP/1.1 400 Content-Type: application/json Transfer-Encoding: chunked Date: Mon, 27 Jun 2022 21:05:52 GMT Connection: close { \"statusCode\": \"BAD_REQUEST\", \"path\": \"/api/v1/movies\", \"messages\": [ \"Parameter: 'id' of type long is required but is missing\" ] } Way better. From the response payload we can deduce what’s wrong with our request. ","date":"2022-06-04","objectID":"/posts/bootiful_error_handling_with_controller_advices/:3:0","tags":["Spring Boot"],"title":"Bootiful error handling with @ControllerAdvices","uri":"/posts/bootiful_error_handling_with_controller_advices/"},{"categories":["Spring Boot"],"content":"MethodArgumentNotValidException Let’s try to create a movie, to see what happens when its validation fails. Just to recap, the endpoint which allows users to create new movies looks like this: @RestController @RequestMapping(\"/api/v1/movies\") public class MovieController { //... @PostMapping public ResponseEntity\u003cMovieResponse\u003e create(@RequestBody @Validated CreateMovieRequest request) { MovieResponse createdMovie = movieService.create(request.toMovie()); URI location = MvcUriComponentsBuilder.fromMethodCall(MvcUriComponentsBuilder.on(getClass()) .getById(createdMovie.id())) .build() .toUri(); return ResponseEntity.created(location) .body(createdMovie); } //... } The request payload, is represented by a record called CreateMovieRequest, which can be seen below: public record CreateMovieRequest(@NotEmpty String name, @NotNull Integer publishYear) { public Movie toMovie() { return Movie.builder() .name(name) .publishYear(publishYear) .build(); } } Basically in order to create a movie, the request payload has to have 2 fields, both of them are mandatory - name and publishYear. But what will happen if one of them is missing? How will the error response look like? Let’s try it out! POST http://localhost:8081/api/v1/movies Content-Type: application/json { \"publishYear\": 1994 } And we get back the following response: HTTP/1.1 400 Content-Type: application/json Transfer-Encoding: chunked Date: Wed, 29 Jun 2022 19:58:40 GMT Connection: close { \"timestamp\": \"2022-06-29T19:58:40.521+00:00\", \"status\": 400, \"error\": \"Bad Request\", \"path\": \"/api/v1/movies\" } Not very descriptive. We’ve received a HTTP 400 bad request, but we have no clue what’s actually wrong with our request. Let’s try to improve it a bit by adding the following property in the application.properties: server.error.include-binding-errors=always Now, if we re-execute our invalid request: POST http://localhost:8081/api/v1/movies Content-Type: application/json { \"publishYear\": 1994 } We’ll get back the following response: HTTP/1.1 400 Content-Type: application/json Transfer-Encoding: chunked Date: Wed, 29 Jun 2022 20:08:07 GMT Connection: close { \"timestamp\": \"2022-06-29T20:08:07.841+00:00\", \"status\": 400, \"error\": \"Bad Request\", \"errors\": [ { \"codes\": [ \"NotEmpty.createMovieRequest.name\", \"NotEmpty.name\", \"NotEmpty.java.lang.String\", \"NotEmpty\" ], \"arguments\": [ { \"codes\": [ \"createMovieRequest.name\", \"name\" ], \"arguments\": null, \"defaultMessage\": \"name\", \"code\": \"name\" } ], \"defaultMessage\": \"must not be empty\", \"objectName\": \"createMovieRequest\", \"field\": \"name\", \"rejectedValue\": null, \"bindingFailure\": false, \"code\": \"NotEmpty\" } ], \"path\": \"/api/v1/movies\" } On one hand, this is definitely an improvement, since if we squint a bit, we can deduce that the validation of the field name from the request payload failed. It shouldn’t be empty. But still, this is an awfully bad error response. Imagine if the request contained not a single invalid field but a bunch of them. This error response will quickly start to look like a real mess, so let’s try to improve it. @Slf4j @RestControllerAdvice @Order(Ordered.LOWEST_PRECEDENCE) public class GlobalExceptionHandler { private final MessageSource messageSource; public GlobalExceptionHandler(MessageSource messageSource) { this.messageSource = messageSource; } @ExceptionHandler({ MethodArgumentNotValidException.class }) public ResponseEntity\u003cErrorResponse\u003e onMethodArgumentNotValidException(MethodArgumentNotValidException e, HttpServletRequest request) { log.error(\"Exception while handling request.\", e); BindingResult bindingResult = e.getBindingResult(); List\u003cString\u003e errorMessages = new ArrayList\u003c\u003e(); for (ObjectError error : bindingResult.getAllErrors()) { String resolvedMessage = messageSource.getMessage(error, Locale.US); if (error instanceof FieldError fieldError) { errorMessages.add(String.format(\"Field '%s' %s but value was '%s'\", fieldError.getField(), resolvedMessage, fieldError.getRejectedValue())); } else { errorMessages.add(re","date":"2022-06-04","objectID":"/posts/bootiful_error_handling_with_controller_advices/:4:0","tags":["Spring Boot"],"title":"Bootiful error handling with @ControllerAdvices","uri":"/posts/bootiful_error_handling_with_controller_advices/"},{"categories":["Spring Boot"],"content":"ConstraintViolationException Let’s get back to our get movie by id endpoint, which uses a query parameter. It is a good idea to validate it as well. For example, let’s say that we expect our movie ids to be always positive. In order to achieve that, we’ll annotate our controller with the @Validated annotation, which will enable us to validate all method parameters. To enforce the rule that movie ids are positive, we can just annotate our id query parameter with the @Min(1) annotation, like shown below: @RestController @RequestMapping(\"/api/v1/movies\") @Validated public class MovieController { private final MovieService movieService; public MovieController(MovieService movieService) { this.movieService = movieService; } @GetMapping public MovieResponse getById(@RequestParam(\"id\") @Min(1) Long id) { return movieService.getById(id); } //... } Let’s try to call the endpoint with an invalid id, and see what kind of error response we get back: GET http://localhost:8081/api/v1/movies?id=0 The error response will look like this: HTTP/1.1 500 Content-Type: application/json Transfer-Encoding: chunked Date: Wed, 29 Jun 2022 20:23:27 GMT Connection: close { \"timestamp\": \"2022-06-29T20:23:27.593+00:00\", \"status\": 500, \"error\": \"Internal Server Error\", \"path\": \"/api/v1/movies\" } We’ve got an HTTP 500 internal server error, and in the logs we can see the following exception: javax.validation.ConstraintViolationException: getById.id: must be greater than or equal to 1 at org.springframework.validation.beanvalidation.MethodValidationInterceptor.invoke(MethodValidationInterceptor.java:120) ~[spring-context-5.3.20.jar:5.3.20] So in order to return a more meaningful response, we’ll need to handle the ConstraintViolationException exception. Let’s adjust our GlobalExceptionHandler, like shown in the code snippet below: @Slf4j @RestControllerAdvice @Order(Ordered.LOWEST_PRECEDENCE) public class GlobalExceptionHandler { //... @ExceptionHandler(ConstraintViolationException.class) public ResponseEntity\u003cErrorResponse\u003e onConstraintViolationException(ConstraintViolationException e, HttpServletRequest request) { log.error(\"Exception while handling request.\", e); Set\u003cConstraintViolation\u003c?\u003e\u003e constraintViolations = e.getConstraintViolations(); List\u003cString\u003e errorMessages = new ArrayList\u003c\u003e(); for (ConstraintViolation\u003c?\u003e violation : constraintViolations) { errorMessages.add(String.format(\"Field '%s' %s but value was '%s'\", getInvalidPropertyName(violation), violation.getMessage(), violation.getInvalidValue())); } ErrorResponse errorResponse = ErrorResponse.builder() .statusCode(HttpStatus.BAD_REQUEST.name()) .messages(errorMessages) .path(request.getServletPath()) .build(); return ResponseEntity.badRequest() .body(errorResponse); } private String getInvalidPropertyName(ConstraintViolation\u003c?\u003e violation) { return StreamSupport.stream(violation.getPropertyPath().spliterator(), false) .map(Path.Node::getName) .reduce((a, b) -\u003e b) .orElse(violation.getPropertyPath().toString()); } //... } This somewhat resembles how we handled the MethodArgumentNotValidException, but since it’s a different exception, the handling has some differences. Let’s see it in action. We’ll call again our endpoint, using an invalid movie id: GET http://localhost:8081/api/v1/movies?id=0 And the new error response should look like this: HTTP/1.1 400 Content-Type: application/json Transfer-Encoding: chunked Date: Wed, 29 Jun 2022 20:29:39 GMT Connection: close { \"statusCode\": \"BAD_REQUEST\", \"path\": \"/api/v1/movies\", \"messages\": [ \"Field 'id' must be greater than or equal to 1 but value was '0'\" ] } Great success, the cause of the error is now obvious, the movie id query parameter has a value less than 1. ","date":"2022-06-04","objectID":"/posts/bootiful_error_handling_with_controller_advices/:5:0","tags":["Spring Boot"],"title":"Bootiful error handling with @ControllerAdvices","uri":"/posts/bootiful_error_handling_with_controller_advices/"},{"categories":["Spring Boot"],"content":"Not found exceptions What will happen when the user will try to get an movie by its id, but the movie won’t be found in the database? If we look at our MovieService.getById() method, we can see that it will throw an EntityNotFoundException when the movie is not found in the database, like shown below: @Service public class MovieService { //... @Transactional(readOnly = true) public MovieResponse getById(Long id) { Movie movie = movieRepository.findById(id) .orElseThrow(() -\u003e new EntityNotFoundException(\"No movie with id:' \" + id + \"' was found.\")); return MovieResponse.from(movie); } //... } The EntityNotFoundException, is a custom exception, and its sole purpose is to signal that a specific entity was not found in the database. It can be seen below: public class EntityNotFoundException extends RuntimeException { public EntityNotFoundException(String message) { super(message); } } It’s interesting to see how the error response will look like when this exception will be thrown. Let’s try it out: GET http://localhost:8081/api/v1/movies?id=10 And we’ll get back the following error response: HTTP/1.1 500 Content-Type: application/json Transfer-Encoding: chunked Date: Thu, 30 Jun 2022 05:52:43 GMT Connection: close { \"timestamp\": \"2022-06-30T05:52:43.464+00:00\", \"status\": 500, \"error\": \"Internal Server Error\", \"path\": \"/api/v1/movies\" } As usual, the error response doesn’t look pretty. Not only it doesn’t describe properly what happened, but this time it doesn’t blame the user but the server (since we got an HTTP 500 internal server error). The fix is simple and obvious, we’ll need to handle the EntityNotFoundException in our GlobalExceptionHandler, something like this: @Slf4j @RestControllerAdvice @Order(Ordered.LOWEST_PRECEDENCE) public class GlobalExceptionHandler { //... @ExceptionHandler(EntityNotFoundException.class) public ResponseEntity\u003cErrorResponse\u003e oEntityNotFoundException(EntityNotFoundException e, HttpServletRequest request) { String message = e.getMessage(); log.error(\"Exception while handling request: \" + message, e); ErrorResponse errorResponse = ErrorResponse.builder() .statusCode(HttpStatus.NOT_FOUND.name()) .messages(List.of(message)) .path(request.getServletPath()) .build(); return ResponseEntity.status(HttpStatus.NOT_FOUND) .body(errorResponse); } //... } This approach relies on the fact that whenever a entity won’t be found in the database, an EntityNotFoundException will be thrown, containing a message stating which entity with which id was not found. But it’s easy to adopt this rule and make all controllers in our application follow it. Now if we try to get a movie which doesn’t exist in the database: GET http://localhost:8081/api/v1/movies?id=10 We will get the following response: HTTP/1.1 404 Content-Type: application/json Transfer-Encoding: chunked Date: Thu, 30 Jun 2022 05:58:19 GMT Keep-Alive: timeout=60 Connection: keep-alive { \"statusCode\": \"NOT_FOUND\", \"path\": \"/api/v1/movies\", \"messages\": [ \"No movie with id:' 10' was found.\" ] } Way better, the error is more concise this time. ","date":"2022-06-04","objectID":"/posts/bootiful_error_handling_with_controller_advices/:6:0","tags":["Spring Boot"],"title":"Bootiful error handling with @ControllerAdvices","uri":"/posts/bootiful_error_handling_with_controller_advices/"},{"categories":["Spring Boot"],"content":"Controller-specific exceptions The GlobalExceptionHandler we saw so far is intended to handle common exceptions, which can be thrown from all controllers. Sometimes though, it is needed to throw an exception, specific for a particular controller. In that case, a controller-specific controller-advice can be used. For example, let’s say that the MovieController can throw a MovieAlreadyExistsException when the user tries to create a movie, but it already exists in the database. If this exception is thrown only from the MovieController, then we’ll create a controller-advice specific to this controller, like shown below: @RestControllerAdvice(assignableTypes = MovieController.class) @Slf4j @Order(Ordered.HIGHEST_PRECEDENCE) public class MovieControllerAdvice { @ExceptionHandler(MovieAlreadyExistsException.class) public ResponseEntity\u003cErrorResponse\u003e onMovieAlreadyExistsException(MovieAlreadyExistsException e, HttpServletRequest request) { String message = e.getMessage(); log.error(\"Exception while handling request: \" + message, e); ErrorResponse errorResponse = ErrorResponse.builder() .statusCode(HttpStatus.CONFLICT.name()) .messages(List.of(message)) .path(request.getServletPath()) .build(); return ResponseEntity.status(HttpStatus.CONFLICT) .body(errorResponse); } } Notice the @RestControllerAdvice(assignableTypes = MovieController.class) annotation. It specifies that this controller-advice handles only exceptions from the MovieController (and it’s subclasses), but since we don’t use the controller inheritance in our application, the MovieController is the only option. Also an important part is that we have to include the @Order(Ordered.HIGHEST_PRECEDENCE) annotation as well, to force the MovieControllerAdvice to be executed before the GlobalExceptionHandler (because the GlobalExceptionHandler can have a generic, “catch-all” @ExceptionHandler). ","date":"2022-06-04","objectID":"/posts/bootiful_error_handling_with_controller_advices/:7:0","tags":["Spring Boot"],"title":"Bootiful error handling with @ControllerAdvices","uri":"/posts/bootiful_error_handling_with_controller_advices/"},{"categories":["Spring Boot"],"content":"Putting it all together The final version of our GlobalExceptionHandler will look something like this: @Slf4j @RestControllerAdvice @Order(Ordered.LOWEST_PRECEDENCE) public class GlobalExceptionHandler { public static final String DEFAULT_ERROR_MESSAGE = \"An unexpected exception occurred while processing the request\"; private final MessageSource messageSource; public GlobalExceptionHandler(MessageSource messageSource) { this.messageSource = messageSource; } @ExceptionHandler(Exception.class) public ResponseEntity\u003cErrorResponse\u003e onException(Exception e, HttpServletRequest request) { log.error(\"Exception while handling request\", e); String errorMessage = e.getMessage() != null ? e.getMessage() : DEFAULT_ERROR_MESSAGE; ErrorResponse errorResponse = ErrorResponse.builder() .statusCode(HttpStatus.INTERNAL_SERVER_ERROR.name()) .messages(List.of(errorMessage)) .path(request.getServletPath()) .build(); return ResponseEntity.internalServerError() .body(errorResponse); } @ExceptionHandler(EntityNotFoundException.class) public ResponseEntity\u003cErrorResponse\u003e oEntityNotFoundException(EntityNotFoundException e, HttpServletRequest request) { String message = e.getMessage(); log.error(\"Exception while handling request: \" + message, e); ErrorResponse errorResponse = ErrorResponse.builder() .statusCode(HttpStatus.NOT_FOUND.name()) .messages(List.of(message)) .path(request.getServletPath()) .build(); return ResponseEntity.status(HttpStatus.NOT_FOUND) .body(errorResponse); } @ExceptionHandler(MissingServletRequestParameterException.class) public ResponseEntity\u003cErrorResponse\u003e onMissingServletRequestParameterException(MissingServletRequestParameterException e, HttpServletRequest request) { String message = \"Parameter: '\" + e.getParameterName() + \"' of type \" + e.getParameterType().toLowerCase(Locale.ROOT) + \" is required but is missing\"; log.error(\"Exception while handling request: \" + message, e); ErrorResponse errorResponse = ErrorResponse.builder() .statusCode(HttpStatus.BAD_REQUEST.name()) .messages(List.of(message)) .path(request.getServletPath()) .build(); return ResponseEntity.badRequest() .body(errorResponse); } @ExceptionHandler({MethodArgumentNotValidException.class }) public ResponseEntity\u003cErrorResponse\u003e onMethodArgumentNotValidException(MethodArgumentNotValidException e, HttpServletRequest request) { log.error(\"Exception while handling request.\", e); BindingResult bindingResult = e.getBindingResult(); List\u003cString\u003e errorMessages = new ArrayList\u003c\u003e(); for (ObjectError error : bindingResult.getAllErrors()) { String resolvedMessage = messageSource.getMessage(error, Locale.US); if (error instanceof FieldError fieldError) { errorMessages.add(String.format(\"Field '%s' %s but value was '%s'\", fieldError.getField(), resolvedMessage, fieldError.getRejectedValue())); } else { errorMessages.add(resolvedMessage); } } ErrorResponse errorResponse = ErrorResponse.builder() .statusCode(HttpStatus.BAD_REQUEST.name()) .messages(errorMessages) .path(request.getServletPath()) .build(); return ResponseEntity.badRequest() .body(errorResponse); } @ExceptionHandler(ConstraintViolationException.class) public ResponseEntity\u003cErrorResponse\u003e onConstraintViolationException(ConstraintViolationException e, HttpServletRequest request) { log.error(\"Exception while handling request.\", e); Set\u003cConstraintViolation\u003c?\u003e\u003e constraintViolations = e.getConstraintViolations(); List\u003cString\u003e errorMessages = new ArrayList\u003c\u003e(); for (ConstraintViolation\u003c?\u003e violation : constraintViolations) { errorMessages.add(String.format(\"Field '%s' %s but value was '%s'\", getInvalidPropertyName(violation), violation.getMessage(), violation.getInvalidValue())); } ErrorResponse errorResponse = ErrorResponse.builder() .statusCode(HttpStatus.BAD_REQUEST.name()) .messages(errorMessages) .path(request.getServletPath()) .build(); return ResponseEntity.badRequest() .body(errorResponse); } private String getInvalidPropertyName(ConstraintViolation\u003c?\u003e violation) { return StreamSupport.stream(violation.getProperty","date":"2022-06-04","objectID":"/posts/bootiful_error_handling_with_controller_advices/:8:0","tags":["Spring Boot"],"title":"Bootiful error handling with @ControllerAdvices","uri":"/posts/bootiful_error_handling_with_controller_advices/"},{"categories":["Spring Boot"],"content":"Conclusion In this blog post we’ve explored some common exceptions which can be thrown from all controllers, like MethodArgumentTypeMismatchException, MissingServletRequestParameterException, MethodArgumentNotValidException and ConstraintViolationException. We also saw that the default error responses Spring Boot generates are not that descriptive and helpful most of the time. But this can be easily fixed using a powerful tool called @RestControllerAdvices. By adding a couple of exception handlers in a controller-advice, we can obtain more readable and descriptive error responses which will help not only the consumers of our REST apis, but will help us - the developers of that api as well. No need to scroll through the mire of logs, if the error response is self-explanatory. The code examples can be found on GitHub ","date":"2022-06-04","objectID":"/posts/bootiful_error_handling_with_controller_advices/:9:0","tags":["Spring Boot"],"title":"Bootiful error handling with @ControllerAdvices","uri":"/posts/bootiful_error_handling_with_controller_advices/"},{"categories":["Spring Framework"],"content":"Introduction The Spring Framework version 6, along with (Spring Boot version 3) will introduce the ability to consume HTTP apis in a declarative way using interfaces. This feature resembles the Spring Data way of writing repositories, where we just create an interface and declare what methods it should have and Spring Data will create a proxy, implementing all SQL queries. It’s worth pointing out that Spring Framework 6 is still in the snapshot state and the current article reflects the state of the things as they are in June 2022. It’s likely that the API will suffer some changes. ","date":"2022-06-04","objectID":"/posts/introduction_to_spring_framework_6_http_interfaces/:1:0","tags":["Spring Framework","HTTP"],"title":"Introduction to Spring Framework 6 HTTP interfaces","uri":"/posts/introduction_to_spring_framework_6_http_interfaces/"},{"categories":["Spring Framework"],"content":"The REST API Let’s look at the REST API we’ll consume. It’s a simple API returning Chuck Norris quotes. To retrieve a random quote, we can call the following endpoint: $ curl https://api.chucknorris.io/jokes/random | jq And the response payload will look like this: { \"categories\": [], \"created_at\": \"2020-01-05 13:42:22.089095\", \"icon_url\": \"https://assets.chucknorris.host/img/avatar/chuck-norris.png\", \"id\": \"b7BKU15BS0OUYSMOwcO9cg\", \"updated_at\": \"2020-01-05 13:42:22.089095\", \"url\": \"https://api.chucknorris.io/jokes/b7BKU15BS0OUYSMOwcO9cg\", \"value\": \"Chuck Norris can create fire by rubbing two ice cubes\" } Let’s create a Spring Boot application which will consume this REST API. ","date":"2022-06-04","objectID":"/posts/introduction_to_spring_framework_6_http_interfaces/:1:1","tags":["Spring Framework","HTTP"],"title":"Introduction to Spring Framework 6 HTTP interfaces","uri":"/posts/introduction_to_spring_framework_6_http_interfaces/"},{"categories":["Spring Framework"],"content":"Creating a Spring Boot 3 project In order to use HTTP interfaces, we need to create a Spring Boot 3 project (which used Spring Framework 6 used the hood). For that, let’s go to the start.spring.io. We’ve selected Spring Boot 3, Spring Web and Spring Reactive Web modules. We need Spring Reactive Web to obtain the WebClient since that’s what HTTP interfaces are based on. RestTemplate is not supported at the moment, and most likely it won’t be supported since the Spring team recommends using WebClient in new projects. ","date":"2022-06-04","objectID":"/posts/introduction_to_spring_framework_6_http_interfaces/:2:0","tags":["Spring Framework","HTTP"],"title":"Introduction to Spring Framework 6 HTTP interfaces","uri":"/posts/introduction_to_spring_framework_6_http_interfaces/"},{"categories":["Spring Framework"],"content":"Consuming the REST API We’ll create the following DTO which will be the Java representation of the JSON response. @Data public class ChuckNorrisQuote { private String value; private String url; private String id; @JsonProperty(\"icon_url\") private String iconUrl; @JsonProperty(\"created_at\") private String createdAt; @JsonProperty(\"updated_at\") private String updatedAt; } Now, let’s create the HTTP interface: interface ChuckNorrisClient { @GetExchange(\"/jokes/random\") ChuckNorrisQuote getRandomQuote(); @GetExchange(\"/jokes/random\") ChuckNorrisQuote getQuoteFromCategory(@RequestParam(\"category\") String category); //passing a query param named 'category' @GetExchange(\"/jokes/categories\") List\u003cString\u003e getCategories(); } When it comes to HTTP interfaces method return types we can use the ResponseEntity if we want access to HTTP headers and status code for example. When also reactive types like Mono and Flux, which are supported as well. Using the @GetExchange(\"/jokes/random\") annotation, we specify that we want an HTTP GET request executed to the /jokes/random endpoint. There are also other annotations, for the rest of HTTP methods like: @PostExchange: for HTTP POST method. The HTTP interface method parameter representing the request payload should be annotated with the @RequestBody annotation @PutExchange: for HTTP PUT method @PatchExchange: for HTTP PATCH method @DelectExchange: for HTTP DELETE method @HttpExchange: the most generic one. All annotations above are meta-annotated with the @HttpExchange annotation. For example @GetExchange(\"/jokes/random\") is equivalent to @HttpExchange(url = \"/jokes/random\", method = \"GET\") We can also use the @HttpExchange annotation to specify attributes common to all HTTP interface methods (like contentType, accept, or url prefix), like shown below: @HttpExchange(url = \"/jokes\") interface ChuckNorrisClient { @HttpExchange(url = \"/random\", method = \"GET\") ChuckNorrisQuote getRandomQuote(); @GetExchange(\"/random\") ChuckNorrisQuote getQuoteFromCategory(@RequestParam(\"category\") String category); @GetExchange(\"/categories\") List\u003cString\u003e getCategories(); } Moving on. In order to obtain an actual HTTP interface instance, we need to define a spring bean. Instantiation is done by HttpServiceProxyFactory, which acts as a factory for HTTP interface instances. The bean definition looks like this: @Configuration public class AppConfig { @Bean public ChuckNorrisClient chuckNorrisClient() throws Exception { WebClient webClient = WebClient.builder() .baseUrl(\"https://api.chucknorris.io/\") .build(); HttpServiceProxyFactory factory = new HttpServiceProxyFactory(new WebClientAdapter(webClient)); factory.afterPropertiesSet(); return factory.createClient(ChuckNorrisClient.class); } } Also notice that we’ve passed the baseUrl to the WebClient builder. We also have the ability to specify default HTTP headers, query parameters, cookies and things like this. See bellow all the available options: Now, let’s try to see the HTTP interfaces in action. Let’s run our application: @SpringBootApplication @Slf4j public class SpringHttpInterfacesApplication { public static void main(String[] args) { SpringApplication.run(SpringHttpInterfacesApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(ChuckNorrisClient client) { return args -\u003e { ChuckNorrisQuote randomQuote = client.getRandomQuote(); log.info(\"Random Chuck Norris quote: {}\", randomQuote); log.info(\"Categories: {}\", client.getCategories()); log.info(\"Joke from money category: {}\", client.getQuoteFromCategory(\"money\")); }; } } Looking at the logs we can see that all 3 HTTP requests executed successfully: 2022-06-04T16:22:17.803+03:00 INFO 1518299 --- [main] .e.s.h.i.SpringHttpInterfacesApplication: Random Chuck Norris quote: ChuckNorrisQuote(value=All science students maybe aware about the fact that picochuck is the unit of manliness in the International System of Units (SI). An average man measures about 0.00073 pc. Chuck Norris measures 39,372 peta","date":"2022-06-04","objectID":"/posts/introduction_to_spring_framework_6_http_interfaces/:3:0","tags":["Spring Framework","HTTP"],"title":"Introduction to Spring Framework 6 HTTP interfaces","uri":"/posts/introduction_to_spring_framework_6_http_interfaces/"},{"categories":["Spring Framework"],"content":"Conclusion In this blog post we’ve looked at Spring 6's HTTP interfaces, which is a declarative way of consuming HTTP APIs, similar to feign. It is still in the snapshot phase, so it’s likely that the api will suffer some changes. One small disadvantage is that HTTP interfaces are based on WebClient and in order to use it, we need to add the whole spring-boot-starter-webflux maven dependency. It’ll be nice if in the future WebClient will be packaged in a separate Spring starter, so that the dependency size is minimized. The example code we used in this article can be found on GitHub. More documentation can be found here. ","date":"2022-06-04","objectID":"/posts/introduction_to_spring_framework_6_http_interfaces/:4:0","tags":["Spring Framework","HTTP"],"title":"Introduction to Spring Framework 6 HTTP interfaces","uri":"/posts/introduction_to_spring_framework_6_http_interfaces/"},{"categories":["Concurrency control","Spring Framework"],"content":"Introduction Today we are going to learn about the difference between optimistic and pessimistic concurrency control using Spring-Data-Jpa. Concurrency control is about managing concurrent access to our data. Let’s say for example that we have a hotel booking system and there’s only one room available in the hotel and 2 users at the same time try to book it. Who will get the room? Well, it’s possible that both of them will succeed, but that will leave the hotel staff with an awkward situation. Concurrency control patterns help to deal with issues like this, either by preventing or detecting them. There are 2 flavours of concurrency control - pessimistic and optimistic locking. Pessimistic locking - prevents conflicts. We’re pessimistic and sure that conflicts will happen, therefore we block concurrent modifications by locking the data for exclusive access. Optimistic locking - detects conflicts. We’re optimistic that conflicts (or concurrent modifications) won’t happen, but if they do happen, we detect and deal with them, usually by issuing retries or returning an error response. Let’s take a closer look at both of these approaches in practice. ","date":"2022-05-19","objectID":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/:1:0","tags":["Spring Framework","Concurrency control","Pessimistic locking","Optimistic locking"],"title":"Optimistic and pessimistic concurrency control with Spring-Data-JPA","uri":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/"},{"categories":["Concurrency control","Spring Framework"],"content":"Real-world example Let’s try to implement a doctor appointment system - a system where patients can create appointments to a doctor (for an annual physical for example). Here’s the domain model: @Entity @Table(name = \"doctors\") public class Doctor extends AbstractEntity { private String firstName; private String lastName; @Column(name = \"email_address\", nullable = false) private String email; @Enumerated(EnumType.STRING) private Specialty specialty; private String telephoneNumber; protected Doctor() { } //Getters, setters, builder, equals \u0026 hashcode were omitted for brevity } We have the Doctor JPA entity, having some simple fields identifying a particular doctor. Next, we’ll need a patient, which can look like this: @Entity @Table(name = \"patients\") public class Patient extends AbstractEntity { private String firstName; private String lastName; private String phoneNumber; private String source; private LocalDate birthDate; protected Patient() { } //Getters, setters, builder, equals \u0026 hashcode were omitted for brevity } Nothing fancy yet, another simple JPA entity representing a patient. Finally, let’s have a look at the Appointment entity, representing an appointment of a patient to a doctor which occurs at a specific date and time. @Entity @Table(name = \"appointments\") public class Appointment extends AbstractEntity { @ManyToOne(fetch = FetchType.LAZY, optional = false) private Doctor doctor; @ManyToOne(fetch = FetchType.LAZY, optional = false) private Patient patient; private LocalDate appointmentDate; private LocalTime startTime; private LocalTime endTime; private String operation; private String details; protected Appointment() { } //Getters, setters, builder, equals \u0026 hashcode were omitted for brevity } Now, let’s implement the REST endpoint for the appointment creation, it can look something like this: @RestController @RequestMapping(\"/api/v1/appointments\") public class AppointmentController { private final AppointmentFacade appointmentFacade; public AppointmentController(AppointmentFacade appointmentFacade) { this.appointmentFacade = appointmentFacade; } @PostMapping public ResponseEntity\u003c?\u003e create(@RequestBody @Validated(ValidationSequence.class) UpsertAppointmentRequest request) { AppointmentResponse createdAppointment = appointmentFacade.create(request); URI location = MvcUriComponentsBuilder.fromMethodCall(MvcUriComponentsBuilder.on(getClass()) .findById(createdAppointment.getId())) .build() .toUri(); return ResponseEntity.created(location) .build(); } } We have just a simple HTTP POST endpoint for creating a new appointment. The controller just delegates the request to the AppointmentFacade, which we’ll see briefly, and then it returns a response containing the Location header pointing to the newly created appointment. The request payload will look like this: POST http://localhost:8080/api/v1/appointments Content-Type: application/json { \"startDate\": \"2021-12-13T17:00\", \"endDate\": \"2021-12-13T18:00\", \"operation\": \"Annual physical\", \"doctorId\": \"f23e4567-e89b-12d3-a456-426614174000\", \"patientId\": \"f44e4567-ef9c-12d3-a45b-52661417400a\", \"details\": \"Just a regular annual physical\" } Moving on, let’s have a look at the AppointmentFacade. The purpose of it is to just convert the web-specific DTO - the UpsertAppointmentRequest into the domain model the service layer understands - the Appointment JPA entity. Also before returning the response, it converts the Appointment entity (which the service layer returned) to another web-specific DTO - the AppointmentResponse in this case. @Component public class AppointmentFacade { private final AppointmentService appointmentService; private final DoctorService doctorService; private final PatientService patientService; public AppointmentFacade(AppointmentService appointmentService, DoctorService doctorService, PatientService patientService) { this.appointmentService = appointmentService; this.doctorService = doctorService; this.patientService = patientService; } public Appointmen","date":"2022-05-19","objectID":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/:2:0","tags":["Spring Framework","Concurrency control","Pessimistic locking","Optimistic locking"],"title":"Optimistic and pessimistic concurrency control with Spring-Data-JPA","uri":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/"},{"categories":["Concurrency control","Spring Framework"],"content":"Testing the solution Let’s try to write an integration test, which spins-up the whole application, executes a real HTTP request which will go through all the layers of the application (though the controller, facade, service, repository and back) and see if it works: @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) public class AppointmentControllerTest extends AbstractWebIntegrationTest { @Test public void shouldBeAbleToCreateAppointments() { String payload = \"\"\" { \"doctorId\": \"620e11c0-7d59-45be-85cc-0dc146532e78\", \"patientId\": \"f44e4567-ef9c-12d3-a45b-52661417400a\", \"startDate\": \"2022-05-23T16:00\", \"endDate\": \"2022-05-23T17:00\", \"operation\": \"Annual physical\", \"details\": \"New patient\" } \"\"\"; RequestEntity\u003cString\u003e request = makeRequestFor(\"/api/v1/appointments/\", HttpMethod.POST, payload); ResponseEntity\u003cString\u003e response = restTemplate.exchange(request, String.class); assertThat(response.getStatusCode().value()).isEqualTo(HttpStatus.CREATED.value()); assertThat(response.getHeaders().getLocation()).isNotNull(); } } If we try to run the test, it’ll pass with flying colors. But is it really working? Well, not really. We haven’t implemented any form of concurrency control in our application. We have the AppointmentRepository.findConflictingAppointment() method, but is it really working? Spoiler alert - it doesn’t. We have a race condition, the check-then-act sequence. When we want to insert a new appointment, we first check if we won’t create overlapping appointments (by calling the AppointmentRepository.findConflictingAppointment()), then if we didn’t spot an overlap, we insert the new appointment. That means that there’s a possibility that 2 different users at the same time will try to create an appointment to the same doctor, on the same day and time rage and both of them will succeed. Both of them checked for overlapping appointments at the same time. They didn’t find anything and proceeded with the insert. Now we have 2 appointments with the same time range which succeeded. The doctor wil definitely be confused. Let’s write a better test to try to simulate this issue. @Slf4j @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) public class AppointmentControllerTest extends AbstractWebIntegrationTest { private static final int NUMBER_OF_CONCURRENT_USERS = 5; private final CountDownLatch startLatch = new CountDownLatch(1); private final CountDownLatch requestLatch = new CountDownLatch(NUMBER_OF_CONCURRENT_USERS); private final ExecutorService requestPool = Executors.newFixedThreadPool(NUMBER_OF_CONCURRENT_USERS); @Test public void shouldBeAbleToCreateAppointments() { IntStream.rangeClosed(1, NUMBER_OF_CONCURRENT_USERS).forEach((item) -\u003e { requestPool.submit(() -\u003e { await(startLatch); log.info(\"Executing create appointment HTTP request\"); String payload = \"\"\" { \"doctorId\": \"620e11c0-7d59-45be-85cc-0dc146532e78\", \"patientId\": \"f44e4567-ef9c-12d3-a45b-52661417400a\", \"startDate\": \"2022-05-23T16:00\", \"endDate\": \"2022-05-23T17:00\", \"operation\": \"Annual physical\", \"details\": \"New patient\" } \"\"\"; RequestEntity\u003cString\u003e request = makeRequestFor(\"/api/v1/appointments/\", HttpMethod.POST, payload); ResponseEntity\u003cString\u003e response = restTemplate.exchange(request, String.class); log.info(\"Received HTTP status code: {}\", response.getStatusCode().value()); requestLatch.countDown(); }); }); startLatch.countDown(); await(requestLatch); RequestEntity\u003cAppointmentResponse[]\u003e allAppointmentsRequest = makeRequestFor(\"/api/v1/appointments/\", HttpMethod.GET); ResponseEntity\u003cAppointmentResponse[]\u003e allAppointmentsResponse = restTemplate.exchange(allAppointmentsRequest, AppointmentResponse[].class); assertThat(allAppointmentsResponse.getStatusCode().value()).isEqualTo(HttpStatus.OK.value()); log.info(\"All appointments: {}\", Arrays.toString(allAppointmentsResponse.getBody())); assertThat(allAppointmentsResponse.getBody().length).isEqualTo(1); } @AfterEach public void tearDown() throws InterruptedException {","date":"2022-05-19","objectID":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/:3:0","tags":["Spring Framework","Concurrency control","Pessimistic locking","Optimistic locking"],"title":"Optimistic and pessimistic concurrency control with Spring-Data-JPA","uri":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/"},{"categories":["Concurrency control","Spring Framework"],"content":"Using pessimistic locking We’ve mentioned that pessimistic locking can help to prevent conflicts - concurrent data modifications. We can use this technique to try to fix our broken AppointmentService.create() method. When using pessimistic locking with Hibernate, a SQL Select for update is used under the hood. Select for update works by placing an exclusive lock on all of the rows returned, so that any other transaction will be blocked from accessing those rows (both for read and update). We can use this trick to obtain mutual exclusion for our AppointmentService.create() method. But what exactly should we lock? Since what we want to prevent is having 2 appointments for the same doctor at the same time, we can execute a Select for update on the doctor, something like this: selectid,first_name...fromdoctorsdwhered.id=\u003c\u003cdoctorIdforwhichweareaddinganappointment\u003e\u003eforupdate effectively gaining exclusive access to the doctor. From the moment the lock was obtained till the transaction will be committed, no other transaction will be able to read (or modify) the doctor. We can add a new method to our DoctorRepository for that: @Repository public interface DoctorRepository extends JpaRepository\u003cDoctor, String\u003e { @Lock(LockModeType.PESSIMISTIC_WRITE) @Query(\"select d from Doctor d where d.id = :id\") Doctor findByIdAndLock(@Param(\"id\") String id); } Notice the @Lock(LockModeType.PESSIMISTIC_WRITE) annotation - it’s the Spring-Data's way of telling that we want to use pessimistic locking for the method. Note There’s also @Lock(LockModeType.PESSIMISTIC_READ) which is translated to Select for share. With this type of lock multiple transactions can read the database table row at the same time, but “writer” transactions (executing updates) will be blocked. And vice versa, when an update is in progress, no “reader” transactions can obtain the shared lock. Now, we can try to use this method to obtain mutual-exclusion in our AppointmentService.create() method: @Service @Slf4j public class AppointmentService { private final AppointmentRepository appointmentRepository; private final DoctorRepository doctorRepository; public AppointmentService(AppointmentRepository appointmentRepository, DoctorRepository doctorRepository) { this.appointmentRepository = appointmentRepository; this.doctorRepository = doctorRepository; } @Transactional public Appointment create(Appointment appointmentToCreate) { checkForConflicts(appointmentToCreate); return appointmentRepository.save(appointmentToCreate); } private void checkForConflicts(Appointment appointmentToCreate) { LocalDate appointmentDate = appointmentToCreate.getAppointmentDate(); LocalTime startTime = appointmentToCreate.getStartTime(); LocalTime endTime = appointmentToCreate.getEndTime(); String doctorId = appointmentToCreate.getDoctor().getId(); Doctor doctor = doctorRepository.findByIdAndLock(doctorId); //here we obtain an exclusive lock for the doctor. From this point onward, //only the current transaction can continue and others will be blocked here //since they can't lock the doctor row Optional\u003cAppointment\u003e conflictingAppointment = appointmentRepository.findConflictingAppointment(doctorId, appointmentDate, startTime, endTime); conflictingAppointment.ifPresent(overlappingAppointment -\u003e { throw new ConflictingAppointmentsException(\"Doctor \" + doctor.getFirstName() + \" \" + doctor.getLastName() + \" has already an appointment, starting from \" + overlappingAppointment.getStartTime() + \" till \" + overlappingAppointment.getEndTime()); }); } } By adding the call to DoctorRepository.findByIdAndLock(doctorId), the first transaction to successfully execute this call will obtain the exclusive lock and therefore, the check-then-act sequence will be executed with mutual-exclusion, eliminating the race condition. Let’s run the test: The test passed, which is very nice. This solution has some drawbacks though. Since during appointment-creation we place an exclusive lock on the doctor, this means that no other transac","date":"2022-05-19","objectID":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/:4:0","tags":["Spring Framework","Concurrency control","Pessimistic locking","Optimistic locking"],"title":"Optimistic and pessimistic concurrency control with Spring-Data-JPA","uri":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/"},{"categories":["Concurrency control","Spring Framework"],"content":"Optimistic locking Let’s look at another form of concurrency control - optimistic locking, which allows us to detect conflicts (or concurrent modifications). With this approach, we no longer lock anything and don’t prevent concurrent access, so the throughput (ideally) should not suffer. Instead we let all transactions do their work concurrently, and then at the end decide to commit or rollback them, depending upon whether concurrent modifications we’re spotted or not. In order to use optimistic locking, we’ll need to change our JPA entities and add a new field annotation with the @Version annotation, like shown below: @Entity @Table(name = \"doctors\") public class Doctor extends AbstractEntity { @Column(name = \"first_name\", nullable = false) private String firstName; @Column(name = \"last_name\", nullable = false) private String lastName; @Column(name = \"email_address\", nullable = false) private String email; private String telephoneNumber; @Enumerated(EnumType.STRING) private Specialty specialty; @Version private long version; //In order to use optimistic locking, we add this field } ","date":"2022-05-19","objectID":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/:5:0","tags":["Spring Framework","Concurrency control","Pessimistic locking","Optimistic locking"],"title":"Optimistic and pessimistic concurrency control with Spring-Data-JPA","uri":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/"},{"categories":["Concurrency control","Spring Framework"],"content":"How it works Whenever you have a JPA entity which could be updated by concurrent transactions, most likely you should have optimistic locking in place. Without any locking mechanism, there is potential for silent data loss, a phenomenon known as lost updates. Let’s look at the lost update anomaly more closely. Let’s say that 2 transactions simultaneously try to update the doctor’s name: As we can see, all the work done by Transaction-2 was lost. Imagine that the above flow was something more serious, like booking the last available room in a hotel. We need a way to prevent that. Optimistic locking to the rescue! Now if we implement optimistic locking, the flow will look like this: What’s changed is that now the doctor table has a new column called version. Every time the doctor's database row is changed, Hibernate will increment that version and if during increment it will spot a version mismatch, it will throw a OptimisticLockException. In that case, the Transaction-1 should be re-executed since it was using stale data. The version field will be incremented by Hibernate every time the entity changes its state. Note Hibernate supports the following @Version field types: short or Short int or Integer long or Long java.sql.Timestamp Java 8 Date/Time such as java.time.Instant Using a numeric type which is large-enough (like Long) is the safest approach. Using time-based values, acting as “last modified time” is a bit more risky since theoretically it’s possible to have 2 threads using the same timestamp. Since our Doctor entity now has a @Version field, Hibernate will automatically prevent lost updates whenever the Doctor entity changes its state. But we have a completely different problem. We want to prevent appointments with overlapping time ranges, and during the creation of an appointment, the Doctor entity does not change its state. The idea is that we can force Hibernate to update the Doctor's version, thus preventing concurrent insertions of appointments. Let’s update our DoctorRepository.findByIdAndLock() method to make it use optimistic locking. For that we’ll add the @Lock(LockModeType.OPTIMISTIC_FORCE_INCREMENT) annotation. @Repository public interface DoctorRepository extends JpaRepository\u003cDoctor, String\u003e { @Lock(LockModeType.OPTIMISTIC_FORCE_INCREMENT) @Query(\"select d from Doctor d where d.id = :id\") Doctor findByIdAndLock(@Param(\"id\") String id); } Our AppointmentService didn’t suffer any changes, it still calls the DoctorRepository.findByIdAndLock() method, but this time using optimistic-locking (see below): @Service @Slf4j public class AppointmentService { private final AppointmentRepository appointmentRepository; private final DoctorRepository doctorRepository; public AppointmentService(AppointmentRepository appointmentRepository, DoctorRepository doctorRepository) { this.appointmentRepository = appointmentRepository; this.doctorRepository = doctorRepository; } @Transactional public Appointment create(Appointment appointmentToCreate) { checkForConflicts(appointmentToCreate); return appointmentRepository.save(appointmentToCreate); } private void checkForConflicts(Appointment appointmentToCreate) { LocalDate appointmentDate = appointmentToCreate.getAppointmentDate(); LocalTime startTime = appointmentToCreate.getStartTime(); LocalTime endTime = appointmentToCreate.getEndTime(); String doctorId = appointmentToCreate.getDoctor().getId(); Doctor doctor = doctorRepository.findByIdAndLock(doctorId); //here we use a LockModeType.OPTIMISTIC_FORCE_INCREMENT //which means that at flush-time, Hibernate will try //to detect if a concurrent modification happened and rollback the //transaction if so Optional\u003cAppointment\u003e conflictingAppointment = appointmentRepository.findConflictingAppointment(doctorId, appointmentDate, startTime, endTime); conflictingAppointment.ifPresent(overlappingAppointment -\u003e { throw new ConflictingAppointmentsException(\"Doctor \" + doctor.getFirstName() + \" \" + doctor.getLastName() + \" has already an appo","date":"2022-05-19","objectID":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/:5:1","tags":["Spring Framework","Concurrency control","Pessimistic locking","Optimistic locking"],"title":"Optimistic and pessimistic concurrency control with Spring-Data-JPA","uri":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/"},{"categories":["Concurrency control","Spring Framework"],"content":"Pessimistic vs Optimistic locking At the first glance, we’ve achieved the same thing with both pessimistic and optimistic locking. What are the subtle differences? Let’s write a test to find out. We are going to try to create 3 appointments at the same time, for the same doctor, something like this: Appointment A with start time 2022-05-23T16:00 and end time 2022-05-23T17:00 Appointment B with start time 2022-05-23T16:00 and end time 2022-05-23T17:00 (the same as above) Appointment C with start time 2022-05-23T11:00 and end time 2022-05-23T14:00 Appointment A and B have overlapping times, so only one of them should succeed (depending on which one will be first). Appointment C does not create any overlaps, so it should succeed in our case. Thus, we expect that only 2 appointments should be created. Either A and C or B and C. Now let’s write our test, which will be a bit complicated. We’ll be using pessimistic locking first. Let’s update the DoctorRepository to use pessimistic locking: @Repository public interface DoctorRepository extends JpaRepository\u003cDoctor, String\u003e { @Lock(LockModeType.PESSIMISTIC_WRITE) @Query(\"select d from Doctor d where d.id = :id\") Doctor findByIdAndLock(@Param(\"id\") String id); } The test will look like this: @Slf4j @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) public class PessimisticVsOptimisticAppointmentControllerTest extends AbstractWebIntegrationTest { private static final int NUMBER_OF_CONCURRENT_USERS = 3; private final CountDownLatch startLatch = new CountDownLatch(1); private final CountDownLatch requestLatch = new CountDownLatch(NUMBER_OF_CONCURRENT_USERS); private final ExecutorService requestPool = Executors.newFixedThreadPool(NUMBER_OF_CONCURRENT_USERS); @Test public void shouldBeAbleToCreateTwoAppointments() { IntStream.rangeClosed(1, 2).forEach((item) -\u003e { //Execute simultaneously 2 overlapping appointments: A and B requestPool.submit(() -\u003e { await(startLatch); log.info(\"Executing create appointment HTTP request\"); String payload = \"\"\" { \"doctorId\": \"620e11c0-7d59-45be-85cc-0dc146532e78\", \"patientId\": \"f44e4567-ef9c-12d3-a45b-52661417400a\", \"startDate\": \"2022-05-23T16:00\", \"endDate\": \"2022-05-23T17:00\", \"operation\": \"Annual physical\", \"details\": \"New patient\" } \"\"\"; RequestEntity\u003cString\u003e request = makeRequestFor(\"/api/v1/appointments/\", HttpMethod.POST, payload); ResponseEntity\u003cString\u003e response = restTemplate.exchange(request, String.class); log.info(\"Received HTTP status code: {}\", response.getStatusCode().value()); requestLatch.countDown(); }); }); requestPool.submit(() -\u003e { //Execute appointment C, which doesn't have any overlaps await(startLatch); log.info(\"Executing create appointment HTTP request\"); String payload = \"\"\" { \"doctorId\": \"620e11c0-7d59-45be-85cc-0dc146532e78\", \"patientId\": \"f44e4567-ef9c-12d3-a45b-52661417400a\", \"startDate\": \"2022-05-23T11:00\", \"endDate\": \"2022-05-23T14:00\", \"operation\": \"Annual physical\", \"details\": \"New patient\" } \"\"\"; RequestEntity\u003cString\u003e request = makeRequestFor(\"/api/v1/appointments/\", HttpMethod.POST, payload); ResponseEntity\u003cString\u003e response = restTemplate.exchange(request, String.class); log.info(\"Received HTTP status code: {}\", response.getStatusCode().value()); requestLatch.countDown(); }); startLatch.countDown(); await(requestLatch); RequestEntity\u003cAppointmentResponse[]\u003e allAppointmentsRequest = makeRequestFor(\"/api/v1/appointments/\", HttpMethod.GET); ResponseEntity\u003cAppointmentResponse[]\u003e allAppointmentsResponse = restTemplate.exchange(allAppointmentsRequest, AppointmentResponse[].class); assertThat(allAppointmentsResponse.getStatusCode().value()).isEqualTo(HttpStatus.OK.value()); log.info(\"All appointments: {}\", Arrays.toString(allAppointmentsResponse.getBody())); assertThat(allAppointmentsResponse.getBody()).contains(makeExpectedAppointments()); //We expect 2 appointments to be created } private AppointmentResponse[] makeExpectedAppointments() { return new AppointmentResponse[]{ AppointmentResponse.builder() .","date":"2022-05-19","objectID":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/:6:0","tags":["Spring Framework","Concurrency control","Pessimistic locking","Optimistic locking"],"title":"Optimistic and pessimistic concurrency control with Spring-Data-JPA","uri":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/"},{"categories":["Concurrency control","Spring Framework"],"content":"Implementing retries on the server-side with Spring Retry In order to implement retries on the server side, we can use Spring Retry. For that, we’ll add the following Maven dependency: \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.retry\u003c/groupId\u003e \u003cartifactId\u003espring-retry\u003c/artifactId\u003e \u003cversion\u003e1.3.3\u003c/version\u003e \u003c/dependency\u003e After that, we’ll need to add a small piece of Java configuration, to enable the retries, like this: @Configuration(proxyBeanMethods = false) @EnableRetry public class RetryConfig { } Almost done. Now we can use the @Retryable annotation to specify what method should be re-executed in case of optimistic lock failures. Spring-Data-Jpa will throw the ObjectOptimisticLockingFailureException whenever we have concurrent modifications of a versioned JPA entity. A good candidate for retries it the AppointmentFacade.create() method (which is shown below), since it is the one starting the transaction: @Component public class AppointmentFacade { //... @Retryable(ObjectOptimisticLockingFailureException.class) //Retry 3 times in case of ObjectOptimisticLockingFailureException public AppointmentResponse create(UpsertAppointmentRequest request) { Appointment appointmentToCreate = toAppointment(request); Appointment createdAppointment = appointmentService.create(appointmentToCreate); return AppointmentResponse.from(createdAppointment); } //... } Let’s re-run our test to see if using retries helped: Looking good, the test passed. The gist is that whenever we have optimistic locking in place, sometimes we should also implement server-side retries. ","date":"2022-05-19","objectID":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/:6:1","tags":["Spring Framework","Concurrency control","Pessimistic locking","Optimistic locking"],"title":"Optimistic and pessimistic concurrency control with Spring-Data-JPA","uri":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/"},{"categories":["Concurrency control","Spring Framework"],"content":"Using synchronized keyword Since our application can’t perform well under concurrent requests, one attempt to solve the issue could be to prevent concurrent executions of the AppointmentService.create() method (since it’s the one having the race-condition with the check-then-act sequence). We can obtain mutual-exclusion for the save method by adding the synchronized keyword. Will it solve the issue? Well, almost. Let’s try it out: @Service @Slf4j public class AppointmentService { private final AppointmentRepository appointmentRepository; private final DoctorRepository doctorRepository; public AppointmentService(AppointmentRepository appointmentRepository, DoctorRepository doctorRepository) { this.appointmentRepository = appointmentRepository; this.doctorRepository = doctorRepository; } @Transactional public synchronized Appointment create(Appointment appointmentToCreate) { //synchronized keyword was added checkForConflicts(appointmentToCreate); return appointmentRepository.save(appointmentToCreate); } } The test still fails. Very strange isn’t it. Here’s the explanation: Explanation Since the AppointmentService class has @Transactional methods, Spring will create a proxy for the AppointmentService. The original AppointmentService.create() method is synchronized, but the same method from the proxy isn’t. Also, the proxy is the one performing the EntityManager flush before the commit. That effectively means that at the time we’ve exited the synchronized method, the SQL inserts were not executed yet. That leaves time for another thread to grab the lock and start executing the create() method. This means that the second thread might not see the previously inserted appointment so it will come to the conclusion that no overlapp is present and insert successfully the conflicting appointment. What we need to do is to ensure that lock is released only after the proxy flushed the persistence context and committed the transaction. We can achieve this by placing a synchronized block in the facade, like this: @Component public class AppointmentFacade { private final AppointmentService appointmentService; private final DoctorService doctorService; private final PatientService patientService; public AppointmentFacade(AppointmentService appointmentService, DoctorService doctorService, PatientService patientService) { this.appointmentService = appointmentService; this.doctorService = doctorService; this.patientService = patientService; } public AppointmentResponse create(UpsertAppointmentRequest request) { Appointment appointmentToCreate = toAppointment(request); Appointment createdAppointment = null; synchronized (this) { //We need to add the synchronized block here createdAppointment = appointmentService.create(appointmentToCreate); } return AppointmentResponse.from(createdAppointment); } private Appointment toAppointment(final UpsertAppointmentRequest request) { //... } } Let’s try it out: It appears to be working at the first glance, but it’s the worst solution (it can hardly can be called a solution). This solution will limit our ability to scale the application not only because the throughput will be reduced significantly but also we are unable to run another instance of our application. If we run the second instance of our application, we’ll have another JVM with a brand-new heap so we lose mutual exclusion. With the synchronized keyword we obtain mutual-exclusion per JVM so a second JVM will bring back our problem with the race condition. ","date":"2022-05-19","objectID":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/:7:0","tags":["Spring Framework","Concurrency control","Pessimistic locking","Optimistic locking"],"title":"Optimistic and pessimistic concurrency control with Spring-Data-JPA","uri":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/"},{"categories":["Concurrency control","Spring Framework"],"content":"Using ShedLock Instead of using the synchronized keyword, we can use a library like ShedLock. Though this library was designed for preventing @Scheduled methods executing concurrently when we start multiple instances of our application, we can safely use it as a distributed lock as well. We’ll need to add the following Maven dependencies: \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003enet.javacrumbs.shedlock\u003c/groupId\u003e \u003cartifactId\u003eshedlock-spring\u003c/artifactId\u003e \u003cversion\u003e${shedlock.version}\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003enet.javacrumbs.shedlock\u003c/groupId\u003e \u003cartifactId\u003eshedlock-provider-jdbc-template\u003c/artifactId\u003e \u003cversion\u003e${shedlock.version}\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e After that we’ll add the following Java configuration, where we specify the DataSource (since the lock metadata is sored in the database) and we also configure 2 parameters: database table name which holds the locks and the default lock timeout, like this: @Configuration(proxyBeanMethods = false) @EnableSchedulerLock(defaultLockAtMostFor = \"${shedlock.default-lock-at-most-for:10s}\") public class ShedLockConfig { @Bean public LockProvider lockProvider(DataSource dataSource, @Value(\"${shedlock.lock-table-name:shedlock}\") String lockTableName) { return new JdbcTemplateLockProvider(JdbcTemplateLockProvider.Configuration.builder() .withJdbcTemplate(new JdbcTemplate(dataSource)) .withTableName(lockTableName) .usingDbTime() .build()); } } We also need to add a new Flyway migration, which looks like this: createtableshedlock(namevarchar(64)notnull,lock_untiltimestampnotnull,locked_attimestampnotnull,locked_byvarchar(255)notnull,primarykey(name)); Almost ready. Now we can annotate the method for which we want to obtain mutual-exclusion across multiple application instances with the @SchedulerLock annotation, (see below): @Service @Slf4j public class AppointmentService { private static final String CREATE_APPOINTMENT_LOCK_NAME = \"createAppointmentLock\"; private final AppointmentRepository appointmentRepository; public AppointmentService(AppointmentRepository appointmentRepository) { this.appointmentRepository = appointmentRepository; } @Transactional @SchedulerLock(name = CREATE_APPOINTMENT_LOCK_NAME) public Appointment create(Appointment appointmentToCreate) { checkForConflicts(appointmentToCreate); return appointmentRepository.save(appointmentToCreate); } private void checkForConflicts(Appointment appointmentToCreate) { LocalDate appointmentDate = appointmentToCreate.getAppointmentDate(); LocalTime startTime = appointmentToCreate.getStartTime(); LocalTime endTime = appointmentToCreate.getEndTime(); String doctorId = appointmentToCreate.getDoctor().getId(); Doctor doctor = appointmentToCreate.getDoctor(); Optional\u003cAppointment\u003e conflictingAppointment = appointmentRepository.findConflictingAppointment(doctorId, appointmentDate, startTime, endTime); conflictingAppointment.ifPresent(overlappingAppointment -\u003e { throw new ConflictingAppointmentsException(\"Doctor \" + doctor.getFirstName() + \" \" + doctor.getLastName() + \" has already an appointment, starting from \" + overlappingAppointment.getStartTime() + \" till \" + overlappingAppointment.getEndTime()); }); } } That’s it. Now we can start multiple instances of our application and still have the desired behavior - no overlapping appointments. The downside being that we’ve added a new dependency. Let’s run the test: And it passes as well. ","date":"2022-05-19","objectID":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/:8:0","tags":["Spring Framework","Concurrency control","Pessimistic locking","Optimistic locking"],"title":"Optimistic and pessimistic concurrency control with Spring-Data-JPA","uri":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/"},{"categories":["Concurrency control","Spring Framework"],"content":"Conclusion In this blog post we’ve looked at 2 forms of concurrency control - optimistic and pessimistic locking. We looked at a real-world example where we actually need a form of concurrency control and explored various ways to fix the problem, like using pessimistic locking (which is backed by select for update), optimistic locking which uses version checks. We saw that when using optimistic locking, sometimes server-side retries are needed. We’ve also looked at the synchronized keyword and saw that it’s applicable only for the cases where we have only one instance of our application and don’t plan to add new ones. And finally, the last solution we explored was using the ShedLock library, which basically is a distributed lock. The code can be found on GitHub. ","date":"2022-05-19","objectID":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/:9:0","tags":["Spring Framework","Concurrency control","Pessimistic locking","Optimistic locking"],"title":"Optimistic and pessimistic concurrency control with Spring-Data-JPA","uri":"/posts/optimistic_and_pessimistic_locking_with_spring_data_jpa/"},{"categories":["Spring Framework"],"content":"Introduction Today we’re going to take a look at a new Spring @Transactional puzzler involving the @TransactionalEventListener. It’s an old quirk of Spring related to transaction-bound events (both declarative and programmatic ones) and though not commonly experienced, encountering it can leave you confused for hours. Let’s have a look. ","date":"2022-05-16","objectID":"/posts/spring_puzzler_transactional_event_listener/:1:0","tags":["Spring Framework","Declarative transaction management","@TransactionalEventListener"],"title":"Spring puzzler: the @TransactionalEventListener","uri":"/posts/spring_puzzler_transactional_event_listener/"},{"categories":["Spring Framework"],"content":"The puzzler Suppose we have the following code: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { Movie movie = Movie.builder() .name(\"Joker\") .build(); movieService.save(movie); }; } } @Service @Slf4j class MovieService { private final MovieRepository movieRepository; public MovieService(MovieRepository movieRepository) { this.movieRepository = movieRepository; } @Transactional public Movie save(Movie movie) { Movie savedMovie = movieRepository.save(movie); log.debug(\"Saved movie: {}\", savedMovie); return savedMovie; } } Nothing fancy so far. We have a CommandLineRunner which calls the MovieService.save() method which saves to the database a Movie JPA entity using Spring-Data-JPA. The Movie entity looks like this btw: @Entity @Table(name = \"movies\") public class Movie extends AbstractEntity { private String name; //Getters, setters, toString and the builder are omitted for brevity Now let’s say we want to implement some form of auditing. Every time a Movie entity is saved, we want to save also a MovieAudit entity, just for inspection purposes. The MovieAudit entity looks like this: @Entity @Table(name = \"movie_audit\") public class MovieAudit extends AbstractEntity { private String name; private String movieId; public static MovieAudit from(Movie movie) { return MovieAudit.builder() .movieId(movie.getId()) .name(movie.getName()) .build(); } //Getters, setters, toString and the builder are omitted for brevity Now in order to implement the required behavior, we can inject the repository for the MovieAudit entity directly into our MovieService and save our MovieAudit along with the Movie entity in the same transaction, like this: @Service @Slf4j class MovieService { private final MovieRepository movieRepository; private final MovieAuditRepository movieAuditRepository; public MovieService(MovieRepository movieRepository, MovieAuditRepository movieAuditRepository) { this.movieRepository = movieRepository; this.movieAuditRepository = movieAuditRepository; } @Transactional public Movie save(Movie movie) { Movie savedMovie = movieRepository.save(movie); log.debug(\"Saved movie: {}\", savedMovie); movieAuditRepository.save(MovieAudit.from(savedMovie)); return savedMovie; } } This approach doesn’t look that good since our MovieService looks a bit messier. Let’s try to move MovieAudit logic our of the MovieService. But how? Spring events to the rescue! ","date":"2022-05-16","objectID":"/posts/spring_puzzler_transactional_event_listener/:2:0","tags":["Spring Framework","Declarative transaction management","@TransactionalEventListener"],"title":"Spring puzzler: the @TransactionalEventListener","uri":"/posts/spring_puzzler_transactional_event_listener/"},{"categories":["Spring Framework"],"content":"Using Spring events Instead of saving the MovieAudit from the MovieService, we can adjust the MovieService to publish a Spring event. Just like this: @Service @Slf4j class MovieService { private final MovieRepository movieRepository; private final ApplicationEventPublisher eventPublisher; public MovieService(MovieRepository movieRepository, ApplicationEventPublisher eventPublisher) { this.movieRepository = movieRepository; this.eventPublisher = eventPublisher; } @Transactional public Movie save(Movie movie) { Movie savedMovie = movieRepository.save(movie); log.debug(\"Saved movie: {}\", savedMovie); eventPublisher.publishEvent(new MovieSavedEvent(savedMovie)); return savedMovie; } } On one hand, our MovieService didn’t become simpler but this approach is more flexible since we can plug-in as many event listeners as we want. For example if in the future we’ll be required to do some other action every time a Movie entity is saved, we can just add a new event-listener. Our event-listener which persists the MovieAudit can look like this: @Slf4j @Component class MovieAuditEventListener { private final MovieAuditRepository movieAuditRepository; public MovieAuditEventListener(MovieAuditRepository movieAuditRepository) { this.movieAuditRepository = movieAuditRepository; } @EventListener(MovieSavedEvent.class) @Transactional public void on(MovieSavedEvent event) { log.debug(\"Received event: {}\", event); MovieAudit movieAudit = MovieAudit.from(event.getMovie()); movieAuditRepository.save(movieAudit); log.debug(\"Saved movie audit: {}\", movieAudit); } } Let’s run the example and check the logs: 2022-05-16 23:51:14.100 DEBUG 1641040 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.save]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-16 23:51:14.100 DEBUG 1641040 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(1483155688\u003copen\u003e)] for JPA transaction 2022-05-16 23:51:14.102 DEBUG 1641040 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@f4f843f] 2022-05-16 23:51:14.106 DEBUG 1641040 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(1483155688\u003copen\u003e)] for JPA transaction 2022-05-16 23:51:14.106 DEBUG 1641040 --- [main] o.s.orm.jpa.JpaTransactionManager : Participating in existing transaction 2022-05-16 23:51:14.114 DEBUG 1641040 --- [main] i.e.spring.tx.management.MovieService: Saved movie: Movie{name='Joker', id='e4d96c77-fbe4-4407-af35-e11176a79da5'} 2022-05-16 23:51:14.115 DEBUG 1641040 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(1483155688\u003copen\u003e)] for JPA transaction 2022-05-16 23:51:14.115 DEBUG 1641040 --- [main] o.s.orm.jpa.JpaTransactionManager : Participating in existing transaction 2022-05-16 23:51:14.117 DEBUG 1641040 --- [main] i.e.s.t.m.MovieAuditEventListener : Received event: MovieSavedEvent{movie=Movie{name='Joker', id='e4d96c77-fbe4-4407-af35-e11176a79da5'}} 2022-05-16 23:51:14.117 DEBUG 1641040 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(1483155688\u003copen\u003e)] for JPA transaction 2022-05-16 23:51:14.117 DEBUG 1641040 --- [main] o.s.orm.jpa.JpaTransactionManager : Participating in existing transaction 2022-05-16 23:51:14.118 DEBUG 1641040 --- [main] i.e.s.t.m.MovieAuditEventListener : Saved movie audit: MovieAudit{name='Joker', id='b73e3f40-7cad-4821-91ca-c867bd1e79da', movieId='e4d96c77-fbe4-4407-af35-e11176a79da5'} 2022-05-16 23:51:14.119 DEBUG 1641040 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit 2022-05-16 23:51:14.119 DEBUG 1641040 --- [main] o.s.orm.jpa.JpaTransactionManager : Committing JPA transaction on EntityManager [SessionImpl(1483155688\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) Hibernate: insert into movie_a","date":"2022-05-16","objectID":"/posts/spring_puzzler_transactional_event_listener/:3:0","tags":["Spring Framework","Declarative transaction management","@TransactionalEventListener"],"title":"Spring puzzler: the @TransactionalEventListener","uri":"/posts/spring_puzzler_transactional_event_listener/"},{"categories":["Spring Framework"],"content":"The @TransactionalEventListener annotation A @TransactionalEventListener is a similar to a regular @EventListener, the difference being that the events are transaction-bounded. This means that the event listeners in this case are not immediately-invoked, but are called when the transaction from which they were thrown changes its phase. Here are the possible phases: @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT): the default. The listeners are invoked after the transaction commit has completed successfully. @TransactionalEventListener(phase = TransactionPhase.AFTER_ROLLBACK):the listeners are invoked after the transaction has been rolled-back. @TransactionalEventListener(phase = TransactionPhase.BEFORE_COMMIT): the listeners are invoked before the transaction will be committed. @TransactionalEventListener(phase = TransactionPhase.AFTER_COMPLETION): the listeners are invoked after the transaction will be completed, so both after commit and rollback. In our example we’ll use @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT) since we want our MovieAudit entity saved after the transaction of the MovieService.save() method will be committed. Our listener will look something like this: @Slf4j @Component class MovieAuditEventListener { private final MovieAuditRepository movieAuditRepository; public MovieAuditEventListener(MovieAuditRepository movieAuditRepository) { this.movieAuditRepository = movieAuditRepository; } @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT) @Transactional public void on(MovieSavedEvent event) { log.debug(\"Received event: {}\", event); MovieAudit movieAudit = MovieAudit.from(event.getMovie()); movieAuditRepository.save(movieAudit); log.debug(\"Saved movie audit: {}\", movieAudit); } } Now let’s check the logs: 2022-05-16 23:53:07.427 DEBUG 1641223 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.save]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-16 23:53:07.427 DEBUG 1641223 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(1305564302\u003copen\u003e)] for JPA transaction 2022-05-16 23:53:07.428 DEBUG 1641223 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@3b362f1] 2022-05-16 23:53:07.432 DEBUG 1641223 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(1305564302\u003copen\u003e)] for JPA transaction 2022-05-16 23:53:07.432 DEBUG 1641223 --- [main] o.s.orm.jpa.JpaTransactionManager : Participating in existing transaction 2022-05-16 23:53:07.442 DEBUG 1641223 --- [main] i.e.spring.tx.management.MovieService: Saved movie: Movie{name='Joker', id='dc766b33-2ba7-4989-bea2-99734243f0c9'} 2022-05-16 23:53:07.443 DEBUG 1641223 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit 2022-05-16 23:53:07.443 DEBUG 1641223 --- [main] o.s.orm.jpa.JpaTransactionManager : Committing JPA transaction on EntityManager [SessionImpl(1305564302\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) 2022-05-16 23:53:07.454 DEBUG 1641223 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(1305564302\u003copen\u003e)] for JPA transaction 2022-05-16 23:53:07.454 DEBUG 1641223 --- [main] o.s.orm.jpa.JpaTransactionManager : Participating in existing transaction 2022-05-16 23:53:07.456 DEBUG 1641223 --- [main] i.e.s.t.m.MovieAuditEventListener : Received event: MovieSavedEvent{movie=Movie{name='Joker', id='dc766b33-2ba7-4989-bea2-99734243f0c9'}} 2022-05-16 23:53:07.457 DEBUG 1641223 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(1305564302\u003copen\u003e)] for JPA transaction 2022-05-16 23:53:07.457 DEBUG 1641223 --- [main] o.s.orm.jpa.JpaTransactionManager : Participating in existing transaction 2022-05-16 23:53:07.458 DEBUG 1641223 --- [main] i","date":"2022-05-16","objectID":"/posts/spring_puzzler_transactional_event_listener/:4:0","tags":["Spring Framework","Declarative transaction management","@TransactionalEventListener"],"title":"Spring puzzler: the @TransactionalEventListener","uri":"/posts/spring_puzzler_transactional_event_listener/"},{"categories":["Spring Framework"],"content":"Explanation The short version is that the MovieService has created a transaction and has bound it to the current thread. Then the MovieService's proxy commits the transaction and invokes the @TransactionalEventListener. The thing is that at this point, the initial transaction is already committed but it wasn’t yet cleaned-up (or unbound from the current thread). Because of that, when the MovieAuditEventListener is called, it thinks that there’s an existing transaction and it tries to join it. The listener thinks that there’s an existing transaction because it can find the thread-local data of the previously committed transaction. This way Spring is fooled and it joins a committed transaction. Now, the SQL insert for the MovieAudit was lost since Hibernate usually executes inserts at flush-time (which happens at the transaction commit), but since the transaction was committed a long time ago, nothing happens. We can’t commit a transaction twice. In-depth explanation The TransactionSynchronizationManager class is the place where all of the thread-bounded transaction data is stored, like this: package org.springframework.transaction.support; public abstract class TransactionSynchronizationManager { private static final ThreadLocal\u003cMap\u003cObject, Object\u003e\u003e resources = new NamedThreadLocal\u003c\u003e(\"Transactional resources\"); private static final ThreadLocal\u003cSet\u003cTransactionSynchronization\u003e\u003e synchronizations = new NamedThreadLocal\u003c\u003e(\"Transaction synchronizations\"); private static final ThreadLocal\u003cString\u003e currentTransactionName = new NamedThreadLocal\u003c\u003e(\"Current transaction name\"); private static final ThreadLocal\u003cBoolean\u003e currentTransactionReadOnly = new NamedThreadLocal\u003c\u003e(\"Current transaction read-only status\"); private static final ThreadLocal\u003cInteger\u003e currentTransactionIsolationLevel = new NamedThreadLocal\u003c\u003e(\"Current transaction isolation level\"); private static final ThreadLocal\u003cBoolean\u003e actualTransactionActive = new NamedThreadLocal\u003c\u003e(\"Actual transaction active\"); //... When the PlatformTransactionManager (in our case it’s the JpaTransactionManager) needs to see if there’s an active transaction, it checks the TransactionSynchronizationManager to see if we have any thread-bounded resources, like this: package org.springframework.orm.jpa; public class JpaTransactionManager extends AbstractPlatformTransactionManager implements ResourceTransactionManager, BeanFactoryAware, InitializingBean { //... @Override protected Object doGetTransaction() { JpaTransactionObject txObject = new JpaTransactionObject(); txObject.setSavepointAllowed(isNestedTransactionAllowed()); EntityManagerHolder emHolder = (EntityManagerHolder) TransactionSynchronizationManager.getResource(obtainEntityManagerFactory()); //Do we have already an EntityManger? if (emHolder != null) { if (logger.isDebugEnabled()) { logger.debug(\"Found thread-bound EntityManager [\" + emHolder.getEntityManager() + \"] for JPA transaction\"); } txObject.setEntityManagerHolder(emHolder, false); //If found an existing EntityManager, set it on the new transaction object } if (getDataSource() != null) { ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(getDataSource()); //Find the JDBC Connection holder txObject.setConnectionHolder(conHolder); //Set it on the new transaction object } return txObject; } At this point, nothing fancy happened. We’ve just collected the data about the existing transaction (if any). Spring has instantiated a JpaTransactionObject instance and has populated it with the thread-bound EntityManagerHolder (which has an EntityManager) and a ConnectionHolder (which has a JDBC Connection). But these 2 values can have the value of null if there isn’t an existing transaction. Now Spring checks if we do have an active transaction, like this: package org.springframework.transaction.support; public abstract class AbstractPlatformTransactionManager implements PlatformTransactionManager, Serializable { //... @Override public final TransactionStatu","date":"2022-05-16","objectID":"/posts/spring_puzzler_transactional_event_listener/:5:0","tags":["Spring Framework","Declarative transaction management","@TransactionalEventListener"],"title":"Spring puzzler: the @TransactionalEventListener","uri":"/posts/spring_puzzler_transactional_event_listener/"},{"categories":["Spring Framework"],"content":"How to fix it? In order to fix it, we’ll need to change the propagation level for the MovieAuditEventListener and use propagation = Propagation.REQUIRES_NEW so that we force it to create a new transaction, like this: @Slf4j @Component class MovieAuditEventListener { private final MovieAuditRepository movieAuditRepository; public MovieAuditEventListener(MovieAuditRepository movieAuditRepository) { this.movieAuditRepository = movieAuditRepository; } @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT) @Transactional(propagation = Propagation.REQUIRES_NEW) public void on(MovieSavedEvent event) { log.debug(\"Received event: {}\", event); MovieAudit movieAudit = MovieAudit.from(event.getMovie()); movieAuditRepository.save(movieAudit); log.debug(\"Saved movie audit: {}\", movieAudit); } } Let’s run it and check the logs to see if it actually works: 2022-05-17 09:05:21.798 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.save]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-17 09:05:21.799 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(1187406578\u003copen\u003e)] for JPA transaction 2022-05-17 09:05:21.800 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@18b40fe6] 2022-05-17 09:05:21.804 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(1187406578\u003copen\u003e)] for JPA transaction 2022-05-17 09:05:21.804 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Participating in existing transaction 2022-05-17 09:05:21.812 DEBUG 1666084 --- [main] i.e.spring.tx.management.MovieService: Saved movie: Movie{name='Joker', id='c2322370-471e-4512-96a5-d04941ecff4f'} 2022-05-17 09:05:21.813 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit 2022-05-17 09:05:21.813 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Committing JPA transaction on EntityManager [SessionImpl(1187406578\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) 2022-05-17 09:05:21.824 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(1187406578\u003copen\u003e)] for JPA transaction 2022-05-17 09:05:21.824 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Suspending current transaction, creating new transaction with name [inc.evil.spring.tx.management.MovieAuditEventListener.on] 2022-05-17 09:05:21.824 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(2117195067\u003copen\u003e)] for JPA transaction 2022-05-17 09:05:21.825 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@68d8eb4f] 2022-05-17 09:05:21.828 DEBUG 1666084 --- [main] i.e.s.t.m.MovieAuditEventListener : Received event: MovieSavedEvent{movie=Movie{name='Joker', id='c2322370-471e-4512-96a5-d04941ecff4f'}} 2022-05-17 09:05:21.828 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(2117195067\u003copen\u003e)] for JPA transaction 2022-05-17 09:05:21.828 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Participating in existing transaction 2022-05-17 09:05:21.829 DEBUG 1666084 --- [main] i.e.s.t.m.MovieAuditEventListener : Saved movie audit: MovieAudit{name='Joker', id='5125bd9f-e854-496d-822f-d3a441c02f22', movieId='c2322370-471e-4512-96a5-d04941ecff4f'} 2022-05-17 09:05:21.830 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit 2022-05-17 09:05:21.830 DEBUG 1666084 --- [main] o.s.orm.jpa.JpaTransactionManager : Committing JPA transaction on EntityManager [SessionImpl(2117195067\u003copen\u003e)] Hibernate: insert into movie_audit (","date":"2022-05-16","objectID":"/posts/spring_puzzler_transactional_event_listener/:6:0","tags":["Spring Framework","Declarative transaction management","@TransactionalEventListener"],"title":"Spring puzzler: the @TransactionalEventListener","uri":"/posts/spring_puzzler_transactional_event_listener/"},{"categories":["Spring Framework"],"content":"Conclusion In this blog post we’ve looked at an odd quirk of Spring regarding the @TransactionalEventListener and we saw that these listeners have to use @Transactional(propagation = Propagation.REQUIRES_NEW) if they want to use transactions, otherwise it won’t work and they will join a dead, committed transaction and this will make them lose all of their work related to the database. We also saw that the programmatic approach - using the TransactionSynchronizationManager.registerSynchronization() does not help. See you later, in another blog post. The code is available on GitHub. ","date":"2022-05-16","objectID":"/posts/spring_puzzler_transactional_event_listener/:7:0","tags":["Spring Framework","Declarative transaction management","@TransactionalEventListener"],"title":"Spring puzzler: the @TransactionalEventListener","uri":"/posts/spring_puzzler_transactional_event_listener/"},{"categories":["Spring Framework"],"content":"Introduction Today we’ll be looking at a Spring puzzler - transactional @PostContruct methods. Though it’s not a commonly used thing, it can be useful to know some limitations of the Spring’s declarative transaction management approach. ","date":"2022-05-15","objectID":"/posts/spring_puzzler_transactional_poostconstruct_methods/:1:0","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Spring puzzler: transactional @PostConstruct methods","uri":"/posts/spring_puzzler_transactional_poostconstruct_methods/"},{"categories":["Spring Framework"],"content":"@PostConstruct methods The @PostConstruct are called automatically by Spring after all of the bean’s dependencies were injected. Let’s look at an example: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } } @Service @Slf4j class MovieService { @Autowired private EntityManager entityManager; public MovieService() { log.debug(\"entityManager: {}\", entityManager); } @PostConstruct public void init() { log.debug(\"entityManager: {}\", entityManager); } } We have a MovieService which is a Spring bean, and it used field-injection to get a dependency - the EntityManager. The question is, when is our spring bean fully-initialized and ready to be used? Usually we consider that after calling the constructor, the instantiated object is in the right state so it can be safely used. Let’s look at the logs to see if that’s the case: 2022-05-15 16:49:36.432 DEBUG 1451865 --- [main] i.e.spring.tx.management.MovieService: entityManager: null 2022-05-15 16:49:36.447 DEBUG 1451865 --- [main] i.e.spring.tx.management.MovieService: entityManager: Shared EntityManager proxy for target factory [org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean@79ab97fd] As we can see from the logs, when the MovieService constructor is executing, the entityManager field still has the value of null. The @PostConstruct methods come to the rescue. They’re invoked after all of the bean’s dependencies were set, no matter the injection type used: constructor, field or setter. Our logs prove that that’s the case, the field entityManager is no longer null when the @PostConstruct method was called. Tip It’s considered a best practice to use constructor injection and steer clear of field injection since field-injection makes unit-testing way harder than it needs to be and it also prevents us from having immutable beans. ","date":"2022-05-15","objectID":"/posts/spring_puzzler_transactional_poostconstruct_methods/:2:0","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Spring puzzler: transactional @PostConstruct methods","uri":"/posts/spring_puzzler_transactional_poostconstruct_methods/"},{"categories":["Spring Framework"],"content":"The puzzler What will happen if we’ll slightly modify our previous example and try to persist a JPA entity? Here are the options: The movie entity will be successfully persisted to the database The init method won’t be called BeanCreationException will be thrown TransactionRequiredException will be thrown Take a wild guess :) @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } } @Service @Slf4j class MovieService { @Autowired private EntityManager entityManager; public MovieService() { log.debug(\"entityManager: {}\", entityManager); } @PostConstruct @Transactional public void init() { log.debug(\"entityManager: {}\", entityManager); Movie movie = Movie.builder() .name(\"Joker\") .build(); entityManager.persist(movie); } } Answer The right answer is: The movie entity will be successfully persisted to the database The init method won’t be called BeanCreationException will be thrown TransactionRequiredException will be thrown Actually an exception will be thrown, specifically BeanCreationException with a cause of TransactionRequiredException. The BeanCreationException exception is thrown when a @PostConstruct method throws an exception. Here are the logs: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'movieService': Invocation of init method failed; nested exception is javax.persistence.TransactionRequiredException: No EntityManager with actual transaction available for current thread - cannot reliably process 'persist' call at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeInitialization(InitDestroyAnnotationBeanPostProcessor.java:160) ~[spring-beans-5.3.19.jar:5.3.19] It’s worth stating that we deliberately used directly the EntityManager, since it doesn’t create any transactions but its persist method expects to be called with an active transaction. Using Spring-data-jpa here will help, since Spring-data-jpa creates transactions as a last-resort, so using Spring-data-jpa will fix the puzzler. ","date":"2022-05-15","objectID":"/posts/spring_puzzler_transactional_poostconstruct_methods/:3:0","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Spring puzzler: transactional @PostConstruct methods","uri":"/posts/spring_puzzler_transactional_poostconstruct_methods/"},{"categories":["Spring Framework"],"content":"Explanation But what really happened? In one of our previous blog posts we mentioned that Spring’s declarative transaction management approach (using the @Transactional annotation) is based-on proxies by default. Here’s a little refresher on how a proxy looks like: Well, it turns out that at the time when the @PostConstruct method is invoked, the proxy for our MovieService was not created yet, so we can’t use the @Transactional annotation since there’s no proxy to intercept the init method call and create a transaction for us. Very unfortunate, isn’t it? ","date":"2022-05-15","objectID":"/posts/spring_puzzler_transactional_poostconstruct_methods/:3:1","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Spring puzzler: transactional @PostConstruct methods","uri":"/posts/spring_puzzler_transactional_poostconstruct_methods/"},{"categories":["Spring Framework"],"content":"How to fix it? There are a couple of ways to fix this problem, let’s explore the one by one. ","date":"2022-05-15","objectID":"/posts/spring_puzzler_transactional_poostconstruct_methods/:4:0","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Spring puzzler: transactional @PostConstruct methods","uri":"/posts/spring_puzzler_transactional_poostconstruct_methods/"},{"categories":["Spring Framework"],"content":"Using programmatic transaction management Well, if during the @PostConstruct method call the proxy is not ready, one option would be to get rid of declarative transaction management and use the programmatic one, since it doesn’t rely on proxies, like this: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } } @Service @Slf4j class MovieService { @Autowired private EntityManager entityManager; private final PlatformTransactionManager transactionManager; public MovieService(PlatformTransactionManager transactionManager) { this.transactionManager = transactionManager; log.debug(\"entityManager: {}\", entityManager); } @PostConstruct public void init() { TransactionTemplate transactionTemplate = new TransactionTemplate(transactionManager); transactionTemplate.execute(new TransactionCallbackWithoutResult() { @Override protected void doInTransactionWithoutResult(TransactionStatus status) { log.debug(\"entityManager: {}\", entityManager); Movie movie = Movie.builder() .name(\"Joker\") .build(); entityManager.persist(movie); } }); } } This approach is certainly more verbose, but it allows us to fix the issue. Let’s check the logs: 2022-05-16 07:02:29.688 DEBUG 1494469 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [null]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-16 07:02:29.702 DEBUG 1494469 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(541713794\u003copen\u003e)] for JPA transaction 2022-05-16 07:02:29.704 DEBUG 1494469 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@45b7c97f] 2022-05-16 07:02:29.704 DEBUG 1494469 --- [main] i.e.spring.tx.management.MovieService: entityManager: Shared EntityManager proxy for target factory [org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean@74123110] 2022-05-16 07:02:29.715 DEBUG 1494469 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit 2022-05-16 07:02:29.715 DEBUG 1494469 --- [main] o.s.orm.jpa.JpaTransactionManager : Committing JPA transaction on EntityManager [SessionImpl(541713794\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) 2022-05-16 07:02:29.728 DEBUG 1494469 --- [main] o.s.orm.jpa.JpaTransactionManager : Closing JPA EntityManager [SessionImpl(541713794\u003copen\u003e)] after transaction As we can see, we do have a transaction and the JPA entity was successfully inserted. ","date":"2022-05-15","objectID":"/posts/spring_puzzler_transactional_poostconstruct_methods/:4:1","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Spring puzzler: transactional @PostConstruct methods","uri":"/posts/spring_puzzler_transactional_poostconstruct_methods/"},{"categories":["Spring Framework"],"content":"Listening to the ContextRefreshedEvent event Another option would be to not use the @PostConstruct annotation, but listening to the ContextRefreshedEvent event, which is a spring event which is published after the Spring’s ApplicationContext is refreshed. At this stage, the proxies for our spring beans are guaranteed to be ready. It looks something like this: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } } @Service @Slf4j class MovieService { @Autowired private EntityManager entityManager; public MovieService() { log.debug(\"entityManager: {}\", entityManager); } @EventListener(ContextRefreshedEvent.class) @Transactional public void init() { log.debug(\"entityManager: {}\", entityManager); Movie movie = Movie.builder() .name(\"Joker\") .build(); entityManager.persist(movie); } } In the example above, instead of the @PostConstruct annotation, we’re using the @EventListener(ContextRefreshedEvent.class) annotation. Let’s check the logs to see if our JPA entity was inserted properly: 2022-05-16 07:13:27.686 DEBUG 1495276 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.init]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-16 07:13:27.687 DEBUG 1495276 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(235386075\u003copen\u003e)] for JPA transaction 2022-05-16 07:13:27.688 DEBUG 1495276 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@6f2d3391] 2022-05-16 07:13:27.693 DEBUG 1495276 --- [main] i.e.spring.tx.management.MovieService: entityManager: Shared EntityManager proxy for target factory [org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean@69d103f0] 2022-05-16 07:13:27.698 DEBUG 1495276 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit 2022-05-16 07:13:27.698 DEBUG 1495276 --- [main] o.s.orm.jpa.JpaTransactionManager : Committing JPA transaction on EntityManager [SessionImpl(235386075\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) 2022-05-16 07:13:27.705 DEBUG 1495276 --- [main] o.s.orm.jpa.JpaTransactionManager : Closing JPA EntityManager [SessionImpl(235386075\u003copen\u003e)] after transaction As we can see, we do have a transaction this time and the JPA entity was successfully inserted. ","date":"2022-05-15","objectID":"/posts/spring_puzzler_transactional_poostconstruct_methods/:4:2","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Spring puzzler: transactional @PostConstruct methods","uri":"/posts/spring_puzzler_transactional_poostconstruct_methods/"},{"categories":["Spring Framework"],"content":"Proxy self-injection This is the messiest and odd-looking solution that actually works. Let’s have a look: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } } @Service @Slf4j class MovieService { @Autowired private EntityManager entityManager; @Autowired private MovieService proxy; public MovieService() { log.debug(\"entityManager: {}\", entityManager); } @PostConstruct public void init() { log.debug(\"entityManager: {}\", entityManager); proxy.doInit(); } @Transactional public void doInit() { Movie movie = Movie.builder() .name(\"Joker\") .build(); entityManager.persist(movie); } } In the example above, the MovieService tries to @Autowire itself. There are versions of the Spring framework (below 4.3) in which this trick doesn’t work. Starting with Spring Framework 4.3, support for self-injection with the @Autowired annotation was added, see release notes here. To make it work, we need to add in the application.properties file the following property (otherwise an UnsatisfiedDependencyException will be thrown): spring.main.allow-circular-references=true When we do a “self-injection” with the @Autowired annotation, what we actually get is our proxy! In this case, we can try to call a @Transactional method though the proxy and in this way we’ll get a transaction. For that we’ve added a new public method annotated with the @Transactional annotation. Let’s check the logs to see if it actually works: 2022-05-16 07:31:05.159 DEBUG 1526158 --- [main] i.e.spring.tx.management.MovieService: entityManager: null 2022-05-16 07:31:05.183 DEBUG 1526158 --- [main] i.e.spring.tx.management.MovieService: entityManager: Shared EntityManager proxy for target factory [org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean@27c53c32] 2022-05-16 07:31:05.195 DEBUG 1526158 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.doInit]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-16 07:31:05.208 DEBUG 1526158 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(266906347\u003copen\u003e)] for JPA transaction 2022-05-16 07:31:05.210 DEBUG 1526158 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@42107318] 2022-05-16 07:31:05.228 DEBUG 1526158 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit 2022-05-16 07:31:05.228 DEBUG 1526158 --- [main] o.s.orm.jpa.JpaTransactionManager : Committing JPA transaction on EntityManager [SessionImpl(266906347\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) 2022-05-16 07:31:05.240 DEBUG 1526158 --- [main] o.s.orm.jpa.JpaTransactionManager : Closing JPA EntityManager [SessionImpl(266906347\u003copen\u003e)] after transaction Indeed, our JPA entity was successfully inserted into the database. Note When doing the proxy self-injection, at the moment when the @PostConstruct method is invoked, it is obvious that the proxy for our MovieService is ready (since @PostConstruct methods are called after all of the bean’s dependencies we’re set). What if we try to rewrite our example like this?: @Service @Slf4j class MovieService { @Autowired private EntityManager entityManager; @Autowired private MovieService proxy; public MovieService() { log.debug(\"entityManager: {}\", entityManager); } @PostConstruct @Transactional public void init() { log.debug(\"entityManager: {}\", entityManager); Movie movie = Movie.builder() .name(\"Joker\") .build(); entityManager.persist(movie); } } Unfortunately it still won’t work because of the way the CommonAnnotationBeanPostProcessor was implemented (well, to be more precise its superclass - the InitDestroyAnnotationBeanPostProcessor), and it is the one which is calling the @PostConstruct methods. This BeanPostPro","date":"2022-05-15","objectID":"/posts/spring_puzzler_transactional_poostconstruct_methods/:4:3","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Spring puzzler: transactional @PostConstruct methods","uri":"/posts/spring_puzzler_transactional_poostconstruct_methods/"},{"categories":["Spring Framework"],"content":"Other pitfalls like this When the @PostConstruct methods are called, any proxy-based mechanisms (like @Async, @Secured, @Cacheable) do not work, but the fixes we’ve discussed in this blog post can be applicable. For example, if we try to make the @PostConstruct method asynchronous, like this: @Slf4j @SpringBootApplication @EnableAsync public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } } @Service @Slf4j class MovieService { @PostConstruct @Async public void init() { log.debug(\"Initializing MovieService\"); } } It won’t work the way we expect it to. The MovieService.init() will be called from the main thread, not in a different one. See the logs below: 2022-05-16 08:36:36.779 DEBUG 1532607 --- [main] i.e.spring.tx.management.MovieService : Initializing MovieService But if we try to apply the trick Listening to the ContextRefreshedEvent event, everything works as expected: @Slf4j @SpringBootApplication @EnableAsync public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } } @Service @Slf4j class MovieService { @EventListener(ContextRefreshedEvent.class) @Async public void init() { log.debug(\"Initializing MovieService\"); } } By looking at the logs we can see that this time, the MovieService.init() method was called from the task-1 thread. 2022-05-16 08:38:55.242 DEBUG 1532809 --- [task-1] i.e.spring.tx.management.MovieService : Initializing MovieService ","date":"2022-05-15","objectID":"/posts/spring_puzzler_transactional_poostconstruct_methods/:5:0","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Spring puzzler: transactional @PostConstruct methods","uri":"/posts/spring_puzzler_transactional_poostconstruct_methods/"},{"categories":["Spring Framework"],"content":"Conclusion In this blog post we’ve looked at one limitation of Spring’s declarative transaction management - the fact that it can’t be used in @PostConstruct methods, since the proxy is not ready yet at that point in time. We also looked at a couple of possible fixes to this problem, like using the programmatic approach, doing proxy self-injection or listening to the ContextRefreshedEvent. Finally, we’ve discussed that this problem can be encountered when using other proxy-based mechanisms like @Async, @Secured or even @Cacheable. There are also a couple of more puzzlers regarding the @Transactional annotation, we’ll take a look at them in another blog post. The code can be found on GitHub ","date":"2022-05-15","objectID":"/posts/spring_puzzler_transactional_poostconstruct_methods/:6:0","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Spring puzzler: transactional @PostConstruct methods","uri":"/posts/spring_puzzler_transactional_poostconstruct_methods/"},{"categories":["Spring Framework"],"content":"Introduction In this blog post we are going to explore the internals of Spring’s declarative transaction management. We’ll start with the basics, and then we’ll dive deeper, looking at the internals and some potential pitfalls which we can run into. We’ll be using: Spring Boot 2.6.7 Java 17 Postgresql Spring Data JPA But first, let’s discuss a bit why do we even bother with transactions in the first place? ","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:1:0","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"Why do we need transactions? The most common reason for using transactions in an application is to maintain a high degree of data integrity and consistency. If we’re unconcerned about the quality of our data, we don’t need to concern ourselves with transactions. Transaction management is ubiquitous, it is present in every Java application which uses a database. The Spring Framework out of the box provides a lot of mechanisms to manage transactions and though it makes our lives easier, it is quite important to understand how it works and what happens under the hood since there are some pitfalls which can lead to undesired results. Let’s take a closer look at what transaction management mechanism Spring provides and how we can use them. Transactions ensure data integrity trough ACID guarantees, which can be recapped as: Atomicity Each transaction is “all or nothing”. All SQL statements in a transaction (select, insert, update, merge or delete) is treated as a single unit. Either all statements are executed, or none of it is executed. Consistency After a transaction, the database is guaranteed to be in a consistent state (all the integrity constraints will be satisfied) Isolation Concurrent transactions don’t interfere with or affect one another. Well, almost. It is possible to have some interference, depending on the used transaction isolation level. Durability Ensures that changes to your data made by successfully executed transactions will be saved, even in the event of system failure Let’s take a look at a practical example. Let’s try to insert into the database the following JPA entity 3 times: @MappedSuperclass public class AbstractEntity { @Id @GenericGenerator(name = \"uuid-generator\", strategy = \"org.hibernate.id.UUIDGenerator\") @GeneratedValue(generator = \"uuid-generator\") protected String id; protected AbstractEntity() { } public String getId() { return id; } public boolean equals(Object other) { if (!(other instanceof AbstractEntity otherEntity)) return false; return Objects.equals(id, otherEntity.getId()); } public int hashCode() { return getClass().hashCode(); } } @Entity @Table(name = \"movies\") public class Movie extends AbstractEntity { private String name; protected Movie() { } private Movie(MovieBuilder builder) { this.name = builder.name; } public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public String toString() { return \"Movie{\" + \"name='\" + name + '\\'' + \", id='\" + id + '\\'' + '}'; } public static MovieBuilder builder() { return new MovieBuilder(); } public static class MovieBuilder { private String name; public MovieBuilder name(String name) { this.name = name; return this; } public Movie build() { return new Movie(this); } } } In order to do that, we can create the following Spring Data JPA repository: @Repository public interface MovieRepository extends JpaRepository\u003cMovie, String\u003e { } We can use the MovieRepository presented above and try to insert 3 movies into the database, like shown below: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { List\u003cString\u003e movieNames = List.of( \"Pulp fiction\", \"Joker\", \"Snatch\" ); List\u003cMovie\u003e savedMovies = movieService.saveMovies(movieNames); log.debug(\"Saved movies: {}\", savedMovies); }; } } @Service class MovieService { private final MovieRepository movieRepository; public MovieService(MovieRepository movieRepository) { this.movieRepository = movieRepository; } public List\u003cMovie\u003e saveMovies(List\u003cString\u003e movieNames) { return movieNames.stream() .map(movieName -\u003e Movie.builder() .name(movieName) .build() ) .map(movieRepository::save) .toList(); } } The question is, how many database transactions are executed by the MovieService.saveMovies() method? The answer is 3, becau","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:2:0","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"How to fix it? To make the MovieService.saveMovies() method atomic and obtain the “all or nothing” behavior, we can just annotate the method with @Transactional annotation. This time the org.springframework.data.jpa.repository.support.SimpleJpaRepository.save() won’t create a new transaction every time it is called but it will notice that with the current thread an active transaction is associated and it will join it. It will look like this: @Service class MovieService { private final MovieRepository movieRepository; public MovieService(MovieRepository movieRepository) { this.movieRepository = movieRepository; } @Transactional public List\u003cMovie\u003e saveMovies(List\u003cString\u003e movieNames) { return movieNames.stream() .map(movieName -\u003e Movie.builder() .name(movieName) .build() ) .map(movieRepository::save) .toList(); } } If we try to run the example this time, we should see the following in the logs: 2022-05-10 19:00:25.049 DEBUG 350995 --- [main] o.s.orm.jpa.JpaTransactionManager: Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovies]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-10 19:00:25.049 DEBUG 350995 --- [main] o.s.orm.jpa.JpaTransactionManager: Opened new EntityManager [SessionImpl(2139895366\u003copen\u003e)] for JPA transaction 2022-05-10 19:00:25.050 DEBUG 350995 --- [main] o.s.orm.jpa.JpaTransactionManager: Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@376b5cb2] 2022-05-10 19:00:25.056 DEBUG 350995 --- [main] o.s.orm.jpa.JpaTransactionManager: Found thread-bound EntityManager [SessionImpl(2139895366\u003copen\u003e)] for JPA transaction 2022-05-10 19:00:25.056 DEBUG 350995 --- [main] o.s.orm.jpa.JpaTransactionManager: Participating in existing transaction 2022-05-10 19:00:25.064 DEBUG 350995 --- [main] o.s.orm.jpa.JpaTransactionManager: Found thread-bound EntityManager [SessionImpl(2139895366\u003copen\u003e)] for JPA transaction 2022-05-10 19:00:25.064 DEBUG 350995 --- [main] o.s.orm.jpa.JpaTransactionManager: Participating in existing transaction 2022-05-10 19:00:25.065 DEBUG 350995 --- [main] o.s.orm.jpa.JpaTransactionManager: Found thread-bound EntityManager [SessionImpl(2139895366\u003copen\u003e)] for JPA transaction 2022-05-10 19:00:25.065 DEBUG 350995 --- [main] o.s.orm.jpa.JpaTransactionManager: Participating in existing transaction 2022-05-10 19:00:25.065 DEBUG 350995 --- [main] o.s.orm.jpa.JpaTransactionManager: Initiating transaction commit 2022-05-10 19:00:25.065 DEBUG 350995 --- [main] o.s.orm.jpa.JpaTransactionManager: Committing JPA transaction on EntityManager [SessionImpl(2139895366\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) Hibernate: insert into movies (name, id) values (?, ?) Hibernate: insert into movies (name, id) values (?, ?) 2022-05-10 19:00:25.079 DEBUG 350995 --- [main] o.s.orm.jpa.JpaTransactionManager: Closing JPA EntityManager [SessionImpl(2139895366\u003copen\u003e)] after transaction Notice that the Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovies]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT sequence is present only once this time, meaning we have a single transaction, as we expected. It’s also interesting that the transaction name has changed. Not it’s inc.evil.spring.tx.management.MovieService.saveMovies which is precisely the fully qualified method name which was annotated with the @Transactional annotation. Also in the logs we can see Participating in existing transaction 3 times, meaning that the org.springframework.data.jpa.repository.support.SimpleJpaRepository.save() method has joined the transaction created by the inc.evil.spring.tx.management.MovieService.saveMovies() method 3 times. Since Spring Data Jpa as a last resort creates transactions for us, during the following examples we are going to use Hibernate’s EntityManager directly because it doesn’t create any transactions and at the same time some of its methods throw exceptions if they’re called without an active","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:2:1","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"Types of transaction management The Spring Framework provides us with 2 types of transaction management: Programmatic transaction management With this approach we manually create, commit and roll-back transactions Declarative transaction management With this approach, we just declare that we want a transaction, via an annotation and Spring will take care of the rest Let’s take a look at how both of these approaches look like in practice. ","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:3:0","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"Programmatic transaction management As we mentioned, by using the programmatic transaction management approach, we will have to manually create and commit transactions. This is not the preferred approach nowadays, but it does have its use-cases. Before showing any code examples, it’s worth mentioning that when it comes to transaction management (doesn’t matter declarative or programmatic), the entry-point is a spring bean of type PlatformTransactionManager with the name transactionManager. There are different implementations of the PlatformTransactionManager interface, depending on the environment we’re using. Some noteworthy implementations are: org.springframework.orm.jpa.JpaTransactionManager: if we intend to use Hibernate (with or without Spring Data Jpa) org.springframework.jdbc.datasource.DataSourceTransactionManager: if we intend to use sping-jdbc (with the JdbcTemplate) or Springh Data Jdbc org.springframework.transaction.jta.JtaTransactionManager: if we intend to use distributed (or XA) transactions (meaning transactions spanning more than one transactional resource, like a database and a message queue). Although XA transactions look nice, it’s considered a relic of the past and it’s best to be avoided since it has some problems and is not supported by many modern technologies (like Apache Kafka for example). Using the programmatic transaction management involves using directly the PlatformTransactionManager. As we can see below, it’s rather cumbersome to use. The first thing we need to do is to instantiate a DefaultTransactionDefinition which we can use to specify the desired propagation behavior, transaction name, the isolation level, the transaction timeout and the transaction read-only flag. After that by calling the PlatformTransactionManager.getTransaction(TransactionDefinition) method we effectively start the transaction with the desired attributes, execute the unit of work, and then we can try to commit it. If at some point the transaction was marked as rollback-only, it cannot be committed and the only possible outcome is a transaction rollback. @Service class ProgrammaticTxMovieService { private final EntityManager entityManager; private final PlatformTransactionManager transactionManager; public ProgrammaticTxMovieService(EntityManager entityManager, PlatformTransactionManager transactionManager) { this.entityManager = entityManager; this.transactionManager = transactionManager; } public Movie saveMovie(String movieName) { DefaultTransactionDefinition definition = new DefaultTransactionDefinition(); definition.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRED); definition.setName(\"saveMovie\"); TransactionStatus transaction = transactionManager.getTransaction(definition); try { Movie movie = Movie.builder() .name(movieName) .build(); entityManager.persist(movie); return movie; } catch (Exception e) { transaction.setRollbackOnly(); throw e; } finally { transactionManager.commit(transaction); } } } It’s worth mentioning that injecting the EntityManager directly into a service is kind of an unorthodox approach since services shouldn’t directly talk to the database but should delegate to a DAO instead. The rule was broken for the sake of brevity. A slightly simpler approach is to use the TransactionTemplate class which basically abstracts away the commit and rollback logic. Instead or writing this logic ourselves, we pass a callback. If the callback will not throw any exceptions, the transaction will be committed, otherwise a rollback will happen. @Service class TransactionTemplateProgrammaticTxMovieService { private final EntityManager entityManager; private final PlatformTransactionManager transactionManager; public TransactionTemplateProgrammaticTxMovieService(EntityManager entityManager, PlatformTransactionManager transactionManager) { this.entityManager = entityManager; this.transactionManager = transactionManager; } public Movie saveMovie(String movieName) { DefaultTransactionDefinition def","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:3:1","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"Declarative transaction management With declarative transaction management, we just specify for what methods we want transactional behavior by annotating them with the @Transactional annotation and Spring will take care of the rest. It works something like this: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { List\u003cString\u003e movieNames = List.of( \"Pulp fiction\", \"Joker\", \"Snatch\" ); List\u003cMovie\u003e savedMovies = movieService.saveMovies(movieNames); log.debug(\"Saved movies: {}\", savedMovies); }; } } @Service class MovieService { private final MovieRepository movieRepository; public MovieService(MovieRepository movieRepository) { this.movieRepository = movieRepository; } @Transactional public List\u003cMovie\u003e saveMovies(List\u003cString\u003e movieNames) { return movieNames.stream() .map(movieName -\u003e Movie.builder() .name(movieName) .build() ) .map(movieRepository::save) .toList(); } } But how exactly does it work? We just annotated a method with an annotation and somehow that method now executes within a transaction. But who starts the transaction? Who commits or rolls-back it? The answer is simple, it’s a proxy! Just as a refresher, the proxy pattern looks like this: We have the Subject interface with the implementation Real Subject. We also have a Proxy which implements the Subject interface, so the proxy looks like a real Subject but it adds additional behavior like caching, logging, security or even transactions. The proxy also has a reference to the real implementation. The client, though unaware of this, will use the Proxy thinking it’s “the real thing”. Let’s try to log the actual class name of the MovieService, and see what’s really going on. @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { log.debug(\"MovieService actual class name: {}\", movieService.getClass().getName()); }; } then, in the logs we will see something like this: 2022-05-11 09:01:10.367 DEBUG 498664 --- [main] SpringDeclarativeTxManagementApplication: MovieService actual class name: inc.evil.spring.tx.management.MovieService$$EnhancerBySpringCGLIB$$38b14d5 We can observe that the actual class name is inc.evil.spring.tx.management.MovieService$$EnhancerBySpringCGLIB$$38b14d5, but in our codebase we have a simple MovieService. Because our MovieService has methods annotated with @Transactional annotation, Spring has created a CGLib proxy for our service and all the logic regarding transaction creation, commit or roll-back is executed precisely by that proxy. So, whenever we have a service which has methods annotated with the @Transactional annotation, Spring will create a proxy for that service and put it in the ApplicationContext. Wherever we want to inject that service, a proxy will be injected instead. The proxy will intercept all the public method calls, check if the method needs a transaction and if so, it will create it and then it will delegate to the original MovieService. After the original method from the MovieService was executed, the proxy will then commit or rollback the transaction, depending on what (if any) exceptions were thrown. As a sequence diagram, the flow looks like this: We can summarize the flow like this: The CommandLineRunner calls MovieService.saveMovies() method. What the CommandLineRunner doesn’t know is that it actually has a reference to a proxy. So in reality the CommandLineRunner is invoking a proxy (a class generated by CGLib in runtime, which looks like a MovieService but it’s a completely different class called MovieService$$EnhancerBySpringCGLIB$$38b14d5) The proxy (the MovieService$$EnhancerBySpringCGLIB$$38b14d5 class) sees that the invoked method (the saveMovies method) is annotated with the @Transactional annotation, so we need a transaction mos","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:3:2","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"@Transactional method visibility By default, only public methods can be annotated with the @Transactional annotation. What will happen if we try to make a @Transactional method package-private or protected? Let’s have a look (notice that the MovieService.saveMovie method is package-private): @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.saveMovie(\"Pulp fiction\"); }; } } @Service @Slf4j class MovieService { private final EntityManager entityManager; public MovieService(EntityManager entityManager) { this.entityManager = entityManager; } @Transactional Movie saveMovie(String movieName) { Movie movie = Movie.builder() .name(movieName) .build(); entityManager.persist(movie); return movie; } } We’ll get a TransactionRequiredException thrown by the EntityManager.persist() method because we don’t have an active transaction (see logs below): 2022-05-12 12:51:40.418 INFO 1079474 --- [main] SpringDeclarativeTxManagementApplication : Started SpringDeclarativeTxManagementApplication in 1.079 seconds (JVM running for 1.355) 2022-05-12 12:51:40.420 INFO 1079474 --- [main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2022-05-12 12:51:40.428 ERROR 1079474 --- [main] o.s.boot.SpringApplication : Application run failed java.lang.IllegalStateException: Failed to execute CommandLineRunner at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:780) ~[spring-boot-2.6.7.jar:2.6.7] at org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:761) ~[spring-boot-2.6.7.jar:2.6.7] at org.springframework.boot.SpringApplication.run(SpringApplication.java:310) ~[spring-boot-2.6.7.jar:2.6.7] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1312) ~[spring-boot-2.6.7.jar:2.6.7] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1301) ~[spring-boot-2.6.7.jar:2.6.7] at inc.evil.spring.tx.management.SpringDeclarativeTxManagementApplication.main(SpringDeclarativeTxManagementApplication.java:35) ~[classes/:na] Caused by: javax.persistence.TransactionRequiredException: No EntityManager with actual transaction available for current thread - cannot reliably process 'persist' call at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:295) ~[spring-orm-5.3.19.jar:5.3.19] at jdk.proxy2/jdk.proxy2.$Proxy80.persist(Unknown Source) ~[na:na] at inc.evil.spring.tx.management.MovieService.saveMovie(SpringDeclarativeTxManagementApplication.java:162) ~[classes/:na] at inc.evil.spring.tx.management.SpringDeclarativeTxManagementApplication.lambda$commandLineRunner$0(SpringDeclarativeTxManagementApplication.java:41) ~[classes/:na] at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:777) ~[spring-boot-2.6.7.jar:2.6.7] ... 5 common frames omitted It turns out that we can enable the transactional behavior for package-private and protected methods (private is the exception) by adding a bit of configuration. To do this, we should add in our Java configuration the @EnableTransactionManagement(proxyTargetClass = true) and add in the application context the following spring bean: @Bean public TransactionAttributeSource transactionAttributeSource() { return new AnnotationTransactionAttributeSource(false); } The TransactionAttributeSource constructor has a parameter called publicMethodsOnly (and by default it is set to true) which specifies if only public methods should have the transactional behavior. By setting this flag to false, we obtain transactional behavior for package-private and protected methods as well. Also sin","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:3:3","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"Commit and roll-back rules By default (though this can be configured) the transaction will be committed if: No exceptions were thrown Checked exceptions were thrown In other cases (if unchecked exceptions were thrown, meaning instances or subclasses of RuntimeException), the transaction will be rolled-back. It is surprising that the transaction is committed in case of checked exceptions. The rationale is that checked exceptions are considered business exceptions and we should check the business rules to see if we do need a rollback or not. Let’s try to test it! What do you think will happen when we’ll call the MovieService.saveMovies() method shown below? @Service class MovieService { @Transactional public List\u003cMovie\u003e saveMovies(List\u003cString\u003e movieNames) { throw new IllegalArgumentException(); } } Since IllegalArgumentException extends RuntimeException, it is considered an unchecked exception and the transaction will be rolled-back. Let’s look at the logs: 2022-05-11 09:22:17.287 DEBUG 505977 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovies]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-11 09:22:17.287 DEBUG 505977 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(1159911315\u003copen\u003e)] for JPA transaction 2022-05-11 09:22:17.288 DEBUG 505977 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@37fef327] 2022-05-11 09:22:17.292 DEBUG 505977 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction rollback 2022-05-11 09:22:17.292 DEBUG 505977 --- [main] o.s.orm.jpa.JpaTransactionManager : Rolling back JPA transaction on EntityManager [SessionImpl(1159911315\u003copen\u003e)] 2022-05-11 09:22:17.293 DEBUG 505977 --- [main] o.s.orm.jpa.JpaTransactionManager : Closing JPA EntityManager [SessionImpl(1159911315\u003copen\u003e)] after transaction 2022-05-11 09:22:17.294 INFO 505977 --- [main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2022-05-11 09:22:17.303 ERROR 505977 --- [main] o.s.boot.SpringApplication : Application run failed java.lang.IllegalStateException: Failed to execute CommandLineRunner The transaction was indeed rolled-back. Now let’s see what happens if we will use a checked-exception: @Service class MovieService { @Transactional public List\u003cMovie\u003e saveMovies(List\u003cString\u003e movieNames) throws IOException { throw new IOException(); } } This time we throw a IOException which extends from Exception which makes it a checked-exception. In this case, even though an exception was thrown out of the @Transactional method, we will have a commit, as seen in the logs below: 2022-05-11 09:26:23.561 DEBUG 507376 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovies]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-11 09:26:23.562 DEBUG 507376 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(347691330\u003copen\u003e)] for JPA transaction 2022-05-11 09:26:23.563 DEBUG 507376 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@775f15fd] 2022-05-11 09:26:23.566 DEBUG 507376 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit 2022-05-11 09:26:23.566 DEBUG 507376 --- [main] o.s.orm.jpa.JpaTransactionManager : Committing JPA transaction on EntityManager [SessionImpl(347691330\u003copen\u003e)] 2022-05-11 09:26:23.567 DEBUG 507376 --- [main] o.s.orm.jpa.JpaTransactionManager : Closing JPA EntityManager [SessionImpl(347691330\u003copen\u003e)] after transaction 2022-05-11 09:26:23.567 INFO 507376 --- [main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To displ","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:3:4","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"How to configure the commit-rollback behavior? It is possible to specify the desired transaction outcome by using the following attributes of the @Transactional annotation: @Transactional(rollbackFor = ...): an array of exception classes for which we want the transaction rolled-back. If we use for example @Transactional(rollbackFor = Exception.class), then we’ll have a rollback if the @Transactional method throws an Exception or any of its subclasses @Transactional(rollbackForClassName = \"...\"): same as above but this time the exception class name is specified as a string. Wildcards are not supported, but we can omit the package and use only the class name, like this: @Transactional(noRollbackForClassName = \"IOException\") or like this @Transactional(noRollbackForClassName = \"java.io.IOException\") it’s the same thing @Transactional(noRollbackFor = ...): an array of exception classes for which we want the transaction committed. @Transactional(noRollbackForClassName = \"...\"): same as above but this time the exception class name is specified as a string. Let’s try to test it. What do you think will happen when we’ll call the MovieService.saveMovies() method shown below? @Service class MovieService { @Transactional(rollbackFor = IOException.class) public List\u003cMovie\u003e saveMovies(List\u003cString\u003e movieNames) throws IOException { throw new IOException(); } } The transaction will be rolled-back. Even though a checked-exception was thrown, we specified that we want a rollback in case of an IOException is thrown, and that’s exactly what we’ve got (see the logs below): 2022-05-11 10:02:49.324 DEBUG 519567 --- [main] o.s.orm.jpa.JpaTransactionManager: Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovies]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT,-java.io.IOException 2022-05-11 10:02:49.324 DEBUG 519567 --- [main] o.s.orm.jpa.JpaTransactionManager: Opened new EntityManager [SessionImpl(1207093026\u003copen\u003e)] for JPA transaction 2022-05-11 10:02:49.326 DEBUG 519567 --- [main] o.s.orm.jpa.JpaTransactionManager: Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@7608a838] 2022-05-11 10:02:49.330 DEBUG 519567 --- [main] o.s.orm.jpa.JpaTransactionManager: Initiating transaction rollback 2022-05-11 10:02:49.330 DEBUG 519567 --- [main] o.s.orm.jpa.JpaTransactionManager: Rolling back JPA transaction on EntityManager [SessionImpl(1207093026\u003copen\u003e)] 2022-05-11 10:02:49.331 DEBUG 519567 --- [main] o.s.orm.jpa.JpaTransactionManager: Closing JPA EntityManager [SessionImpl(1207093026\u003copen\u003e)] after transaction Now let’s do the opposite with an unchecked-exception. What do you think will happen when we’ll call the method shown below? @Service class MovieService { @Transactional(noRollbackFor = IllegalArgumentException.class) public List\u003cMovie\u003e saveMovies(List\u003cString\u003e movieNames) { throw new IllegalArgumentException(); } } The transaction will be committed since we’ve specified that we don’t want to rollback in case an IllegalArgumentException exception is thrown (see the logs below): 2022-05-11 10:06:57.206 DEBUG 520985 --- [main] o.s.orm.jpa.JpaTransactionManager: Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovies]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT,+java.lang.IllegalArgumentException 2022-05-11 10:06:57.206 DEBUG 520985 --- [main] o.s.orm.jpa.JpaTransactionManager: Opened new EntityManager [SessionImpl(1692381981\u003copen\u003e)] for JPA transaction 2022-05-11 10:06:57.207 DEBUG 520985 --- [main] o.s.orm.jpa.JpaTransactionManager: Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@2cd3fc29] 2022-05-11 10:06:57.210 DEBUG 520985 --- [main] o.s.orm.jpa.JpaTransactionManager: Initiating transaction commit 2022-05-11 10:06:57.211 DEBUG 520985 --- [main] o.s.orm.jpa.JpaTransactionManager: Committing JPA transaction on EntityManager [SessionImpl(1692381981\u003copen\u003e)] 2022-05-11 ","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:3:5","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"Is programmatic transaction management equivalent to the declarative one? What if we take a method which uses the declarative transaction management approach and try to rewrite it to use the programmatic approach? Do we get the same behavior? Let’s have a look: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.saveMovie(\"Pulp fiction\"); }; } } @Service @Slf4j class MovieService { private final EntityManager entityManager; public MovieService(EntityManager entityManager) { this.entityManager = entityManager; } @Transactional(propagation = Propagation.REQUIRED) public Movie saveMovie(String movieName) throws IOException { Movie movie = Movie.builder() .name(movieName) .build(); entityManager.persist(movie); offendingMethod(); return movie; } private void offendingMethod() throws IOException { throw new IOException(); } } The method throws an IOException, which is a checked-exception so that means that the transaction will be committed, even though the method thew an exception (see the logs below): 2022-05-12 10:26:06.788 DEBUG 1024681 --- [main] o.s.orm.jpa.JpaTransactionManager: Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovie]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-12 10:26:06.788 DEBUG 1024681 --- [main] o.s.orm.jpa.JpaTransactionManager: Opened new EntityManager [SessionImpl(1871084300\u003copen\u003e)] for JPA transaction 2022-05-12 10:26:06.790 DEBUG 1024681 --- [main] o.s.orm.jpa.JpaTransactionManager: Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@be6d228] 2022-05-12 10:26:06.797 DEBUG 1024681 --- [main] o.s.orm.jpa.JpaTransactionManager: Initiating transaction commit 2022-05-12 10:26:06.798 DEBUG 1024681 --- [main] o.s.orm.jpa.JpaTransactionManager: Committing JPA transaction on EntityManager [SessionImpl(1871084300\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) 2022-05-12 10:26:06.810 DEBUG 1024681 --- [main] o.s.orm.jpa.JpaTransactionManager : Closing JPA EntityManager [SessionImpl(1871084300\u003copen\u003e)] after transaction 2022-05-12 10:26:06.811 INFO 1024681 --- [main] ConditionEvaluationReportLoggingListener : Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled. 2022-05-12 10:26:06.819 ERROR 1024681 --- [main] o.s.boot.SpringApplication : Application run failed java.lang.IllegalStateException: Failed to execute CommandLineRunner Now let’s rewrite the method to use the programmatic transaction management approach using the TransactionTemplate, as shown below: @Service @Slf4j class MovieService { private final EntityManager entityManager; private final PlatformTransactionManager transactionManager; public MovieService(EntityManager entityManager, PlatformTransactionManager transactionManager) { this.entityManager = entityManager; this.transactionManager = transactionManager; } public Movie saveMovie(String movieName) throws IOException { DefaultTransactionDefinition definition = new DefaultTransactionDefinition(); definition.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRED); definition.setName(\"saveMovie\"); TransactionTemplate transactionTemplate = new TransactionTemplate(transactionManager, definition); return transactionTemplate.execute(status -\u003e { Movie movie = Movie.builder() .name(movieName) .build(); entityManager.persist(movie); offendingMethod(); //does not compile return movie; }); } private void offendingMethod() throws IOException { throw new IOException(); } } Well, the code above does not compile since the TransactionTemplate.execute(TransactionCallback callback) method have a parameter of type TransactionCallback, which is a functional interface which d","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:3:6","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"Transaction propagation What will happen if we’ll call one @Transactional method from another? Will we have 2 transactions or just one? Let’s run the example below and look at the logs. We have 2 services: MovieService and MovieServiceTwo. First we call the transactional MovieService.saveMovie() method and then it tries to invoke the MovieServiceTwo.save() which is also transactional. @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.saveMovie(\"Pulp fiction\"); }; } } @Service @Slf4j class MovieService { private final MovieServiceTwo movieServiceTwo; public MovieService(MovieServiceTwo movieServiceTwo) { this.movieServiceTwo = movieServiceTwo; } @Transactional public Movie saveMovie(String movieName) { log.debug(\"Inside MovieService\"); Movie movie = Movie.builder() .name(movieName) .build(); return movieServiceTwo.save(movie); } } @Service @Slf4j class MovieServiceTwo { private final EntityManager entityManager; public MovieServiceTwo(EntityManager entityManager) { this.entityManager = entityManager; } @Transactional public Movie save(Movie movie) { log.debug(\"Inside MovieServiceTwo\"); entityManager.persist(movie); return movie; } } If we look at the logs, we can see that we have a single transaction: 2022-05-11 15:34:42.455 DEBUG 690207 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovie]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-11 15:34:42.455 DEBUG 690207 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(2020226167\u003copen\u003e)] for JPA transaction 2022-05-11 15:34:42.457 DEBUG 690207 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@46b6701e] 2022-05-11 15:34:42.460 DEBUG 690207 --- [main] i.e.s.tx.management.MovieService : Inside MovieService 2022-05-11 15:34:42.460 DEBUG 690207 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(2020226167\u003copen\u003e)] for JPA transaction 2022-05-11 15:34:42.460 DEBUG 690207 --- [main] o.s.orm.jpa.JpaTransactionManager : Participating in existing transaction 2022-05-11 15:34:42.463 DEBUG 690207 --- [main] i.e.s.tx.management.MovieServiceTwo : Inside MovieServiceTwo 2022-05-11 15:34:42.468 DEBUG 690207 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit 2022-05-11 15:34:42.468 DEBUG 690207 --- [main] o.s.orm.jpa.JpaTransactionManager : Committing JPA transaction on EntityManager [SessionImpl(2020226167\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) 2022-05-11 15:34:42.481 DEBUG 690207 --- [main] o.s.orm.jpa.JpaTransactionManager : Closing JPA EntityManager [SessionImpl(2020226167\u003copen\u003e)] after transaction What happened is that the proxy for MovieServiceTwo has found an existing transaction for the current thread and it joined it. Basically transactions are like a viral disease, they can infect other methods. The @Transactional annotation has an attribute called propagation and it specifies the desired behavior when a transactional method is called with or without an active transaction. Here are the possible propagation levels: @Transactional(propagation = Propagation.REQUIRED): the default. Starts a transaction if we don’t have one, otherwise join the existing one @Transactional(propagation = Propagation.REQUIRES_NEW): Starts a transaction if we don’t have one, otherwise suspend the existing one and create a new one @Transactional(propagation = Propagation.SUPPORTS): Join the existing transaction. If we don’t have a transaction execute without it @Transactional(propagation = Propagation.MANDATORY): Join the existing transaction","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:4:0","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"@Transactional(propagation = Propagation.REQUIRED) When calling a method annotated with @Transactional(propagation = Propagation.REQUIRED), if the current thread is not associated with a transaction, a new transaction will be created. If a transaction exists, the method will just join it. But what will happen if one @Transactional method calls another @Transactional method from a different service, with propagation = Propagation.REQUIRED and the second service throws an exception? Do we lose all the work done by the first service as well or only the work done by the second service? Let’s have a look: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.saveMovie(\"Pulp fiction\"); }; } } @Service @Slf4j class MovieService { private final ActorService actorService; private final EntityManager entityManager; public MovieService(ActorService actorService, EntityManager entityManager) { this.actorService = actorService; this.entityManager = entityManager; } @Transactional(propagation = Propagation.REQUIRED) public Movie saveMovie(String movieName) { try { Movie movie = Movie.builder() .name(movieName) .build(); entityManager.persist(movie); log.debug(\"Calling ActorService\"); actorService.saveActor(\"John Travolta\"); return movie; } catch (Exception e) { log.error(\"Caught an exception\"); return null; } } } @Service @Slf4j class ActorService { private final EntityManager entityManager; public ActorService(EntityManager entityManager) { this.entityManager = entityManager; } @Transactional(propagation = Propagation.REQUIRED) public Actor saveActor(String name) { Actor actor = Actor.builder() .name(name) .build(); entityManager.persist(actor); throw new NullPointerException(); } } If we look at the logs, we can see that the ActorService.saveActor() method has joined the existing transaction (the Participating in existing transaction) and because it threw an exception, the transaction was marked as rollback-only by the proxy. Because the transaction was marked as rollback-only, it cannot be committed, even though it tried to (see Initiating transaction commit in the logs). Also we can notice that trying to catch the exception didn’t help at all, since the exception “passed though” the proxy and because of that , it has set the rollback-only flag. We can also observe that all of the database work done by both services was lost (or rolled-back) since we don’t have any SQL statements logged (we’ve configured Hibernate to do so). 2022-05-11 17:02:05.767 DEBUG 716638 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovie]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-11 17:02:05.767 DEBUG 716638 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(1478683866\u003copen\u003e)] for JPA transaction 2022-05-11 17:02:05.769 DEBUG 716638 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@3ee6dc82] 2022-05-11 17:02:05.777 DEBUG 716638 --- [main] i.e.s.tx.management.MovieService: Calling ActorService 2022-05-11 17:02:05.778 DEBUG 716638 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(1478683866\u003copen\u003e)] for JPA transaction 2022-05-11 17:02:05.778 DEBUG 716638 --- [main] o.s.orm.jpa.JpaTransactionManager : Participating in existing transaction 2022-05-11 17:02:05.781 DEBUG 716638 --- [main] o.s.orm.jpa.JpaTransactionManager : Participating transaction failed - marking existing transaction as rollback-only 2022-05-11 17:02:05.781 DEBUG 716638 --- [main] o.s.orm.jpa.JpaTransactionManager : Setting JPA transaction on EntityManager [SessionImpl(1","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:4:1","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"@Transactional(propagation = Propagation.REQUIRES_NEW) When calling a method annotated with @Transactional(propagation = Propagation.REQUIRES_NEW), if the current thread is not associated with a transaction, a new transaction will be created. If a transaction exists, the existing transaction will be suspended and we’ll create a new one, execute it and then finally we’ll resume the initial one. But what will happen if one @Transactional method calls another @Transactional(propagation = Propagation.REQUIRES_NEW) method from a different service, and the second service throws an exception? In this case we have 2 transactions and we expect a rollback only for the second transaction. Let’s have a look: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.saveMovie(\"Pulp fiction\"); }; } } @Service @Slf4j class MovieService { private final ActorService actorService; private final EntityManager entityManager; public MovieService(ActorService actorService, EntityManager entityManager) { this.actorService = actorService; this.entityManager = entityManager; } @Transactional(propagation = Propagation.REQUIRED) public Movie saveMovie(String movieName) { try { Movie movie = Movie.builder() .name(movieName) .build(); entityManager.persist(movie); log.debug(\"Calling ActorService\"); actorService.saveActor(\"John Travolta\"); return movie; } catch (Exception e) { log.error(\"Caught an exception\"); return null; } } } @Service @Slf4j class ActorService { private final EntityManager entityManager; public ActorService(EntityManager entityManager) { this.entityManager = entityManager; } @Transactional(propagation = Propagation.REQUIRES_NEW) public Actor saveActor(String name) { Actor actor = Actor.builder() .name(name) .build(); entityManager.persist(actor); throw new NullPointerException(); } } Looking at the logs we can observe that when the ActorService.saveActor() method is called, the existing transaction is indeed suspended (Suspending current transaction, creating new transaction with name [inc.evil.spring.tx.management.ActorService.saveActor]). When the ActorService.saveActor() throws an exception, the new transaction is rollbacked (Rolling back JPA transaction on EntityManager [SessionImpl(1959219756\u003copen\u003e)]) and then the initial transaction is resumed (Resuming suspended transaction after completion of inner transaction). Since the MovieService.saveMovie() catches the exception thrown by the ActorService.saveActor(), no exceptions will “pass though” the proxy of the MovieService class and that means that the initial transaction will be committed (see the logs below). If we were to remove the try-catch block from the MovieService.saveMovie() method, both transactions will be rolled-back. We can also observe that the work done by the MovieService.saveMovie() is preserved, we have an insert SQL statement in the logs. 2022-05-11 17:19:29.308 DEBUG 721804 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovie]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-11 17:19:29.308 DEBUG 721804 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(1598068850\u003copen\u003e)] for JPA transaction 2022-05-11 17:19:29.310 DEBUG 721804 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@506aa618] 2022-05-11 17:19:29.318 DEBUG 721804 --- [main] i.e.s.tx.management.MovieService: Calling ActorService 2022-05-11 17:19:29.318 DEBUG 721804 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(1598068850\u003copen\u003e)] for JPA transaction 2022-05-11 17:19:29.319 DEBUG 7218","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:4:2","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"@Transactional(propagation = Propagation.NESTED) The propagation = Propagation.NESTED works pretty much the same way as propagation = Propagation.REQUIRES_NEW, if the current thread is not associated with a transaction, a new transaction will be created. If a transaction exists, we’ll create a JDBC Savepoint before entering the new transactional method and in case of failure we will rollback to the jdbc savepoint. Basically if one @Transactional method calls another @Transactional(propagation = Propagation.NESTED) method from a different service, and the second service throws an exception, we will rollback to the jdbc savepoint and in this way we’ll preserve the work done by the first service. Let’s have a look: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.saveMovie(\"Pulp fiction\"); }; } } @Service @Slf4j class MovieService { private final ActorService actorService; private final EntityManager entityManager; public MovieService(ActorService actorService, EntityManager entityManager) { this.actorService = actorService; this.entityManager = entityManager; } @Transactional(propagation = Propagation.REQUIRED) public Movie saveMovie(String movieName) { try { Movie movie = Movie.builder() .name(movieName) .build(); entityManager.persist(movie); log.debug(\"Calling ActorService\"); actorService.saveActor(\"John Travolta\"); return movie; } catch (Exception e) { log.error(\"Caught an exception\"); return null; } } } @Service @Slf4j class ActorService { private final EntityManager entityManager; public ActorService(EntityManager entityManager) { this.entityManager = entityManager; } @Transactional(propagation = Propagation.NESTED) public Actor saveActor(String name) { Actor actor = Actor.builder() .name(name) .build(); entityManager.persist(actor); throw new NullPointerException(); } } 2022-05-11 17:43:55.526 DEBUG 729067 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovie]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-11 17:43:55.527 DEBUG 729067 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(711964207\u003copen\u003e)] for JPA transaction 2022-05-11 17:43:55.528 DEBUG 729067 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@7e2bd5e6] 2022-05-11 17:43:55.536 DEBUG 729067 --- [main] i.e.s.tx.management.MovieService: Calling ActorService 2022-05-11 17:43:55.537 DEBUG 729067 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(711964207\u003copen\u003e)] for JPA transaction 2022-05-11 17:43:55.537 DEBUG 729067 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating nested transaction with name [inc.evil.spring.tx.management.ActorService.saveActor] 2022-05-11 17:43:55.537 ERROR 729067 --- [main] i.e.s.tx.management.MovieService: Caught an exception 2022-05-11 17:43:55.537 DEBUG 729067 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit 2022-05-11 17:43:55.537 DEBUG 729067 --- [main] o.s.orm.jpa.JpaTransactionManager : Committing JPA transaction on EntityManager [SessionImpl(711964207\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) 2022-05-11 17:43:55.545 DEBUG 729067 --- [main] o.s.orm.jpa.JpaTransactionManager : Closing JPA EntityManager [SessionImpl(711964207\u003copen\u003e)] after transaction Looking at the logs we can see that only the work done by the MovieService.saveMovie() method was successfully inserted into the database. ","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:4:3","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"@Transactional(propagation = Propagation.SUPPORTS) This is an easy one, it works as if the @Transactional annotation is not present. If we have an active transaction, we join it. If we don’t, execute without a transaction. Let’s take a look at the example below: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.saveMovie(\"Pulp fiction\"); }; } } @Service @Slf4j class MovieService { private final ActorService actorService; private final EntityManager entityManager; public MovieService(ActorService actorService, EntityManager entityManager) { this.actorService = actorService; this.entityManager = entityManager; } @Transactional(propagation = Propagation.REQUIRED) public Movie saveMovie(String movieName) { try { Movie movie = Movie.builder() .name(movieName) .build(); entityManager.persist(movie); log.debug(\"Calling ActorService\"); actorService.saveActor(\"John Travolta\"); return movie; } catch (Exception e) { log.error(\"Caught an exception\"); return null; } } } @Service @Slf4j class ActorService { private final EntityManager entityManager; public ActorService(EntityManager entityManager) { this.entityManager = entityManager; } @Transactional(propagation = Propagation.SUPPORTS) public Actor saveActor(String name) { Actor actor = Actor.builder() .name(name) .build(); entityManager.persist(actor); return actor; } } We can see that the ActorService.saveActor which has @Transactional(propagation = Propagation.SUPPORTS) has joined the existing transaction, but if the @Transactional annotation wasn’t present, the same thing would happen. 2022-05-12 10:01:38.812 DEBUG 1017539 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovie]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-12 10:01:38.812 DEBUG 1017539 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(1185631996\u003copen\u003e)] for JPA transaction 2022-05-12 10:01:38.814 DEBUG 1017539 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@40016ce1] 2022-05-12 10:01:38.822 DEBUG 1017539 --- [main] i.e.s.tx.management.MovieService: Calling ActorService 2022-05-12 10:01:38.822 DEBUG 1017539 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(1185631996\u003copen\u003e)] for JPA transaction 2022-05-12 10:01:38.822 DEBUG 1017539 --- [main] o.s.orm.jpa.JpaTransactionManager : Participating in existing transaction 2022-05-12 10:01:38.824 DEBUG 1017539 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit 2022-05-12 10:01:38.824 DEBUG 1017539 --- [main] o.s.orm.jpa.JpaTransactionManager : Committing JPA transaction on EntityManager [SessionImpl(1185631996\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) Hibernate: insert into actors (name, id) values (?, ?) 2022-05-12 10:01:38.832 DEBUG 1017539 --- [main] o.s.orm.jpa.JpaTransactionManager : Closing JPA EntityManager [SessionImpl(1185631996\u003copen\u003e)] after transaction What will happen if both methods have the @Transactional(propagation = Propagation.SUPPORTS) annotation? Let’s have a look: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.saveMovie(\"Pulp fiction\"); }; } } @Service @Slf4j class MovieService { private final ActorService actorService; private final EntityManager entityManager; public MovieService(ActorService actorService, EntityManage","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:4:4","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"@Transactional(propagation = Propagation.NOT_SUPPORTED) The @Transactional(propagation = Propagation.NOT_SUPPORTED) propagation works in the following way: if we don’t have a transaction, no problem, execute without it. If we do have one, suspend it, execute the method with the propagation = Propagation.NOT_SUPPORTED and then resume the transaction. Basically it is useful when we want to call a method from a different service which doesn’t need a transaction and at the same time we want to prevent that method from marking the transaction as rollback-only in case of exceptions. Let’s have a look: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.saveMovie(\"Pulp fiction\"); }; } } @Service @Slf4j class MovieService { private final ActorService actorService; private final EntityManager entityManager; public MovieService(ActorService actorService, EntityManager entityManager) { this.actorService = actorService; this.entityManager = entityManager; } @Transactional(propagation = Propagation.REQUIRED) public Movie saveMovie(String movieName) { Movie movie = Movie.builder() .name(movieName) .build(); entityManager.persist(movie); log.debug(\"Calling ActorService\"); try { actorService.saveActor(\"John Travolta\"); } catch (Exception e) { log.error(\"Caught an exception\"); } return movie; } } @Service @Slf4j class ActorService { @Transactional(propagation = Propagation.NOT_SUPPORTED) public Actor saveActor(String name) { throw new RuntimeException(); } } If we analyze the logs we can see that the ActorService.saveActor() suspends the transaction (Suspending current transaction) and then it resumes it (Resuming suspended transaction after completion of inner transaction). Even though the ActorService.saveActor() threw a RuntimeException which triggers a rollback usually, we successfully committed the transaction since the exception was thrown when the transaction was suspended (see logs below): 2022-05-12 11:18:46.933 DEBUG 1040575 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovie]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-12 11:18:46.933 DEBUG 1040575 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(1421763091\u003copen\u003e)] for JPA transaction 2022-05-12 11:18:46.936 DEBUG 1040575 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@7eee6c13] 2022-05-12 11:18:46.947 DEBUG 1040575 --- [main] i.e.s.tx.management.MovieService: Calling ActorService 2022-05-12 11:18:46.948 DEBUG 1040575 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(1421763091\u003copen\u003e)] for JPA transaction 2022-05-12 11:18:46.948 DEBUG 1040575 --- [main] o.s.orm.jpa.JpaTransactionManager : Suspending current transaction 2022-05-12 11:18:46.951 DEBUG 1040575 --- [main] o.s.orm.jpa.JpaTransactionManager : Should roll back transaction but cannot - no transaction available 2022-05-12 11:18:46.951 DEBUG 1040575 --- [main] o.s.orm.jpa.JpaTransactionManager : Resuming suspended transaction after completion of inner transaction 2022-05-12 11:18:46.951 ERROR 1040575 --- [main] i.e.s.tx.management.MovieService: Caught an exception 2022-05-12 11:18:46.951 DEBUG 1040575 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit 2022-05-12 11:18:46.951 DEBUG 1040575 --- [main] o.s.orm.jpa.JpaTransactionManager : Committing JPA transaction on EntityManager [SessionImpl(1421763091\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) 2022-05-12 11:18:46.964 DEBUG 1040575 --- [main] o.s.orm.jpa.JpaTransactionManager : Closing JPA EntityMana","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:4:5","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"@Transactional(propagation = Propagation.NEVER) This transaction propagation level does not support transactions. If we’ll call a method annotated with @Transactional(propagation = Propagation.NEVER) without a transaction, everything will work fine. If we do have a transaction, we’ll get an exception since the method doesn’t support transactions. This propagation level is useful for scenarios where we have a method which doesn’t need a transaction and we want to prevent others from calling the method when there’s an active transaction. It is considered that transactions should be as small as possible and we can use this propagation level to prevent a long-running method being called from a transaction, since that will increase significantly the transaction lifespan. Let’s have a look: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.saveMovie(\"Pulp fiction\"); }; } } @Service @Slf4j class MovieService { private final ActorService actorService; private final EntityManager entityManager; public MovieService(ActorService actorService, EntityManager entityManager) { this.actorService = actorService; this.entityManager = entityManager; } @Transactional(propagation = Propagation.NEVER) public Movie saveMovie(String movieName) { return Movie.builder() .name(movieName) .build(); } } If we look at the logs, we can see that no transaction was created: 2022-05-12 11:41:01.254 INFO 1047157 --- [main] SpringDeclarativeTxManagementApplication : Started SpringDeclarativeTxManagementApplication in 1.045 seconds (JVM running for 1.338) 2022-05-12 11:41:01.260 INFO 1047157 --- [ionShutdownHook] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default' Let’s try out a different example. What will happen if we call a @Transactional(propagation = Propagation.NEVER) with an active transaction, like shown below? @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.saveMovie(\"Pulp fiction\"); }; } } @Service @Slf4j class MovieService { private final ActorService actorService; private final EntityManager entityManager; public MovieService(ActorService actorService, EntityManager entityManager) { this.actorService = actorService; this.entityManager = entityManager; } @Transactional(propagation = Propagation.REQUIRED) public Movie saveMovie(String movieName) { Movie movie = Movie.builder() .name(movieName) .build(); entityManager.persist(movie); log.debug(\"Calling ActorService\"); actorService.saveActor(\"John Travolta\"); return movie; } } @Service @Slf4j class ActorService { @Transactional(propagation = Propagation.NEVER) public Actor saveActor(String name) { return Actor.builder() .name(name) .build(); } } In this case a IllegalTransactionStateException will be thrown since the ActorService.saveActor() method does not support transactions (see logs below): 2022-05-12 11:43:01.090 DEBUG 1047930 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovie]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-12 11:43:01.090 DEBUG 1047930 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(711964207\u003copen\u003e)] for JPA transaction 2022-05-12 11:43:01.091 DEBUG 1047930 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@7e2bd5e6] 2022-05-12 11:43:01.100 DEBUG 1047930 --- [main] i.e.s.tx.man","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:4:6","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"@Transactional(propagation = Propagation.MANDATORY) The @Transactional(propagation = Propagation.MANDATORY) is the opposite of Propagation.NEVER. In order to call a method with the @Transactional(propagation = Propagation.MANDATORY) we need to have an active transaction, otherwise we’ll get an exception. Let’s have a closer look: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.saveMovie(\"Pulp fiction\"); }; } } @Service @Slf4j class MovieService { private final ActorService actorService; private final EntityManager entityManager; public MovieService(ActorService actorService, EntityManager entityManager) { this.actorService = actorService; this.entityManager = entityManager; } @Transactional(propagation = Propagation.REQUIRED) public Movie saveMovie(String movieName) { Movie movie = Movie.builder() .name(movieName) .build(); entityManager.persist(movie); log.debug(\"Calling ActorService\"); actorService.saveActor(\"John Travolta\"); return movie; } } @Service @Slf4j class ActorService { private final EntityManager entityManager; public ActorService(EntityManager entityManager) { this.entityManager = entityManager; } @Transactional(propagation = Propagation.MANDATORY) public Actor saveActor(String name) { Actor actor = Actor.builder() .name(name) .build(); entityManager.persist(actor); return actor; } } We can see from the logs that everything worked fine, we have a single transaction (started by MovieService.saveMovie()) and the ActorService.saveActor() has joined it: 2022-05-12 11:52:22.465 DEBUG 1050965 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovie]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-12 11:52:22.465 DEBUG 1050965 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(1186328673\u003copen\u003e)] for JPA transaction 2022-05-12 11:52:22.466 DEBUG 1050965 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@376af784] 2022-05-12 11:52:22.475 DEBUG 1050965 --- [main] i.e.s.tx.management.MovieService : Calling ActorService 2022-05-12 11:52:22.475 DEBUG 1050965 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(1186328673\u003copen\u003e)] for JPA transaction 2022-05-12 11:52:22.475 DEBUG 1050965 --- [main] o.s.orm.jpa.JpaTransactionManager : Participating in existing transaction 2022-05-12 11:52:22.477 DEBUG 1050965 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit 2022-05-12 11:52:22.478 DEBUG 1050965 --- [main] o.s.orm.jpa.JpaTransactionManager : Committing JPA transaction on EntityManager [SessionImpl(1186328673\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) Hibernate: insert into actors (name, id) values (?, ?) 2022-05-12 11:52:22.491 DEBUG 1050965 --- [main] o.s.orm.jpa.JpaTransactionManager : Closing JPA EntityManager [SessionImpl(1186328673\u003copen\u003e)] after transaction 2022-05-12 11:52:22.494 INFO 1050965 --- [ionShutdownHook] j.LocalContainerEntityManagerFactoryBean : Closing JPA EntityManagerFactory for persistence unit 'default' 2022-05-12 11:52:22.495 INFO 1050965 --- [ionShutdownHook] com.zaxxer.hikari.HikariDataSource : HikariPool-1 - Shutdown initiated... 2022-05-12 11:52:22.497 INFO 1050965 --- [ionShutdownHook] com.zaxxer.hikari.HikariDataSource : HikariPool-1 - Shutdown completed. Process finished with exit code 0 If we try to call a method annotated with @Transactional(propagation = Propagation.MANDATORY) without a transaction, we’ll get an exception: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:4:7","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"Transaction timeouts The @Transactional annotation has an attribute called timeout which specifies the transaction timeout in seconds. If the transaction won’t be committed in the given number of seconds, it will be automatically rolled-back. The timeout attribute along with propagation = Propagation.REQUIRED sometimes has interesting behavior. When a method with propagation = Propagation.REQUIRED is joining an existing transaction, it inherits the transaction attributes like isolation, readOnly and timeout from the existing transaction. This could lead to unexpected results sometimes. Let’s look at an example. The MovieService.saveMovie() method is the one starting the transaction and it declares the transaction timeout as one second. The ActorService.saveActor() method will join the existing transaction, but it wants a timeout of 10 seconds. Also the ActorService.saveActor() has an artificial delay of 2 seconds. In this case, what do you think will happen? @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.saveMovie(\"Pulp fiction\"); }; } } @Service @Slf4j class MovieService { private final ActorService actorService; private final EntityManager entityManager; public MovieService(ActorService actorService, EntityManager entityManager) { this.actorService = actorService; this.entityManager = entityManager; } @Transactional(propagation = Propagation.REQUIRED, timeout = 1) public Movie saveMovie(String movieName) { Movie movie = Movie.builder() .name(movieName) .build(); entityManager.persist(movie); actorService.saveActor(\"John Travolta\"); return movie; } } @Service @Slf4j class ActorService { @Transactional(propagation = Propagation.REQUIRED, timeout = 10) public Actor saveActor(String name) { try { TimeUnit.SECONDS.sleep(2); return null; } catch (InterruptedException e) { return null; } } } Well, if we look at the logs we can see that the transaction timed-out and was rolled-back, which basically means that ActorService.saveActor() method has inherited the timeout attribute from the existing transaction it has joined. The transaction was rolled-back since the transaction timeout was one second but the ActorService.saveActor() method executed for 2 seconds. 2022-05-12 15:18:16.374 DEBUG 1135044 --- [main] o.s.orm.jpa.JpaTransactionManager : Creating new transaction with name [inc.evil.spring.tx.management.MovieService.saveMovie]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT,timeout_1 2022-05-12 15:18:16.374 DEBUG 1135044 --- [main] o.s.orm.jpa.JpaTransactionManager : Opened new EntityManager [SessionImpl(337295973\u003copen\u003e)] for JPA transaction 2022-05-12 15:18:16.376 DEBUG 1135044 --- [main] o.s.orm.jpa.JpaTransactionManager : Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@d504137] 2022-05-12 15:18:16.384 DEBUG 1135044 --- [main] o.s.orm.jpa.JpaTransactionManager : Found thread-bound EntityManager [SessionImpl(337295973\u003copen\u003e)] for JPA transaction 2022-05-12 15:18:16.385 DEBUG 1135044 --- [main] o.s.orm.jpa.JpaTransactionManager : Participating in existing transaction 2022-05-12 15:18:18.391 DEBUG 1135044 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit 2022-05-12 15:18:18.392 DEBUG 1135044 --- [main] o.s.orm.jpa.JpaTransactionManager : Committing JPA transaction on EntityManager [SessionImpl(337295973\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) 2022-05-12 15:18:18.405 DEBUG 1135044 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction rollback after commit exception org.springframework.orm.jpa.JpaSystemException: transaction timeout expired; nested exception is org.hibernate.TransactionException: transaction timeout expired at org.springframework.o","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:5:0","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"Read-only transactions When using the JpaTransactionManager (configured by default when using spring-data-jpa), every transaction which is created also creates an EntityManager which represents the so-called “unit of work” in Hibernate. Though the EntityManager is not thread-safe, it’s not a problem since transactions are thread-local (or bound to a specific thread). We can easily verify that when creating a new transaction an EntityManager is created as well by looking at the following example: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.saveMovie(\"Pulp fiction\"); }; } } @Service @Slf4j class MovieService { private final EntityManager entityManager; public MovieServiceOne(EntityManager entityManager) { this.entityManager = entityManager; } @Transactional protected Movie saveMovie(String movieName) { Movie movie = Movie.builder() .name(movieName) .build(); entityManager.persist(movie); return movie; } } In the logs we can observe the sequence: Opened new EntityManager [SessionImpl(1982072255\u003copen\u003e)] for JPA transaction and Closing JPA EntityManager [SessionImpl(1982072255\u003copen\u003e)] after transaction. 2022-05-13 08:42:02.640 DEBUG 1250340 --- [main] o.s.orm.jpa.JpaTransactionManager: Creating new transaction with name [inc.evil.spring.tx.management.MovieServiceOne.saveMovie]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT 2022-05-13 08:42:02.641 DEBUG 1250340 --- [main] o.s.orm.jpa.JpaTransactionManager: Opened new EntityManager [SessionImpl(1982072255\u003copen\u003e)] for JPA transaction 2022-05-13 08:42:02.642 DEBUG 1250340 --- [main] o.s.orm.jpa.JpaTransactionManager: Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@37a67cf] 2022-05-13 08:42:02.652 DEBUG 1250340 --- [main] o.s.orm.jpa.JpaTransactionManager: Initiating transaction commit 2022-05-13 08:42:02.653 DEBUG 1250340 --- [main] o.s.orm.jpa.JpaTransactionManager: Committing JPA transaction on EntityManager [SessionImpl(1982072255\u003copen\u003e)] Hibernate: insert into movies (name, id) values (?, ?) 2022-05-13 08:42:02.665 DEBUG 1250340 --- [main] o.s.orm.jpa.JpaTransactionManager: Closing JPA EntityManager [SessionImpl(1982072255\u003copen\u003e)] after transaction It is known that the EntityManager acts as a first-level cache (in different sources there’s different nomenclature for this, sometimes this is called that the EntityManager has a persistence context or that the EntityManager represents the persistence context), which basically is a cache for entities in the persistent state. The question which arrives at this point is: when a transactional method from one service joins an existing transaction (created by another service), is the EntityManager reused? Let’s have a look at an example: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieServiceOne movieService) { return args -\u003e { movieService.findMovie(\"aa3e4567-e89b-12d3-b457-5267141750aa\"); }; } } @Service @Slf4j class MovieServiceOne { private final EntityManager entityManager; private final MovieServiceTwo movieServiceTwo; public MovieServiceOne(EntityManager entityManager, MovieServiceTwo movieServiceTwo) { this.entityManager = entityManager; this.movieServiceTwo = movieServiceTwo; } @Transactional protected Movie findMovie(String id) { Movie movie = entityManager.find(Movie.class, id); log.debug(\"Found movie: {}\", movie); movieServiceTwo.findMovie(id); return movie; } } @Service @Slf4j class MovieServiceTwo { private final EntityManager entityManager; public MovieServiceTwo(EntityManager entityManager) { t","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:6:0","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"The readOnly attribute We can mark the transaction as being read-only by specifying the readOnly attribute, like this: @Transactional(readOnly = true). Read-only transactions are considered to be more performant and another effect of this attribute is that Hibernate's dirty-checking mechanisms would be disabled. When fetching an entity, Hibernate apart from the fact that it maps the ResultSet to a Java object, it creates a snapshot of the ResultSet so that it can use it later, at flush-time to determine if the entity is dirty (meaning we need to update the entity). With read-only transactions, this actions doesn’t take place and this is precisely the reason of performance improvement. Let’s check it. Take a look at the example below: @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.findMovie(\"aa3e4567-e89b-12d3-b457-5267141750aa\"); }; } } @Service @Slf4j class MovieService { private final EntityManager entityManager; public MovieService(EntityManager entityManager) { this.entityManager = entityManager; } @Transactional(readOnly = true) protected Movie findMovie(String id) { Movie movie = entityManager.find(Movie.class, id); log.debug(\"Found movie: {}\", movie); movie.setName(movie.getName() + \"!\"); return movie; } } In the example above, in a read-only transaction we fetch a Movie entity and change its name (making the entity dirty). If we had a regular “write” transaction, this will trigger an SQL update on the movie table. Let’s check the logs to see what happened in our case: 2022-05-13 19:22:55.713 DEBUG 1353141 --- [main] o.s.orm.jpa.JpaTransactionManager: Creating new transaction with name [inc.evil.spring.tx.management.MovieService.findMovie]: PROPAGATION_REQUIRED,ISOLATION_DEFAULT,readOnly 2022-05-13 19:22:55.713 DEBUG 1353141 --- [main] o.s.orm.jpa.JpaTransactionManager: Opened new EntityManager [SessionImpl(196161345\u003copen\u003e)] for JPA transaction 2022-05-13 19:22:55.715 DEBUG 1353141 --- [main] o.s.orm.jpa.JpaTransactionManager: Exposing JPA transaction as JDBC [org.springframework.orm.jpa.vendor.HibernateJpaDialect$HibernateConnectionHandle@75dd0f94] Hibernate: select movie0_.id as id1_1_0_, movie0_.name as name2_1_0_ from movies movie0_ where movie0_.id=? 2022-05-13 19:22:55.724 DEBUG 1353141 --- [main] i.e.s.tx.management.MovieService : Found movie: Movie{name='Pulp Fiction!', id='aa3e4567-e89b-12d3-b457-5267141750aa'} 2022-05-13 19:22:55.725 DEBUG 1353141 --- [main] o.s.orm.jpa.JpaTransactionManager : Initiating transaction commit No SQL updates spotted, signifying that the dirty-checking mechanism was indeed disabled. Good idea If the transaction only reads data, mark it as read-only. This wil not only improve the performance, but also serve as a form of documentation. Now, what will happen if in a readOnly transaction we’ll try to persist an entity, as shown in the example below? @Slf4j @SpringBootApplication public class SpringDeclarativeTxManagementApplication { public static void main(String[] args) { SpringApplication.run(SpringDeclarativeTxManagementApplication.class, args); } @Bean public CommandLineRunner commandLineRunner(MovieService movieService) { return args -\u003e { movieService.findMovie(\"aa3e4567-e89b-12d3-b457-5267141750aa\"); }; } } @Service @Slf4j class MovieService { private final EntityManager entityManager; public MovieService(EntityManager entityManager) { this.entityManager = entityManager; } @Transactional(readOnly = true) protected Movie findMovie(String id) { Movie movie = entityManager.find(Movie.class, id); log.debug(\"Found movie: {}\", movie); Movie newMovie = Movie.builder() .name(\"Joker\") .build(); entityManager.persist(newMovie); return movie; } } Well, the EntityManager.persist() will be silently ignored (without throwing any e","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:6:1","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":["Spring Framework"],"content":"Conclusion In this blog post we made a gentle introduction on Spring's declarative and programmatic transaction management approaches, looked at all the propagation levels, what’s the default commit and rollback behavior (and how to configure it), discussed that by default only public methods can be transactional, but with a bit of configuration we can enable the transactional behavior for package-private and protected methods as well. We also compared a bit the programmatic and declarative approaches and saw that they aren’t 100% equivalent, and we also saw that read-only transactions disable the dirty-checking mechanism. We’ll dive deeper in another blog post where we’ll look at some puzzlers and limitations of declarative transaction management. ","date":"2022-05-10","objectID":"/posts/introduction_to_declarative_tx_management/:7:0","tags":["Spring Framework","Declarative transaction management","Programmatic transaction management"],"title":"Introduction to declarative transaction management in Spring Framework","uri":"/posts/introduction_to_declarative_tx_management/"},{"categories":null,"content":"I am a software developer, working primarily with Java and the Spring framework. I’m very passionate about the Java platform and its ecosystem, and my plan is to post here things I find interesting. ","date":"2019-08-02","objectID":"/about/:0:0","tags":null,"title":"About me","uri":"/about/"},{"categories":null,"content":"Certifications Though it’s debatable if the certifications are worth doing or not, it does certainly help to double-check how well one knows a specific technology. I passed following certifications: VMware Spring Professional AWS Certified Solutions Architect Associate AWS Certified cloud practitioner Oracle Certified Professional, Java SE 8 Programmer Oracle Certified Associate, Java SE 8 Programmer ","date":"2019-08-02","objectID":"/about/:0:1","tags":null,"title":"About me","uri":"/about/"}]